{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionReasoning\")\n",
    "from tensorboard_utils import extract_all_runs, extract_tensorboard_data_from_run, extract_last_step_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3737493/464873755.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange, tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule_new_utils import infer_rule_from_sample_batch, compute_rule_statistics, infer_rule_statistics_from_sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabdir = \"/n/home12/binxuwang/Github/DiffusionReasoning/Tables\"\n",
    "# figdir = \"/n/home12/binxuwang/Github/DiffusionReasoning/Figures_newrule\"\n",
    "\n",
    "GPT_exproot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/GPT2_raven\"\n",
    "DiT_exproot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiT/results\"\n",
    "SiT_exproot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/SiT/results\"\n",
    "SSM_exproot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Mamba_raven\"\n",
    "EDM_exproot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/mini_edm/exps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "figroot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning\"\n",
    "GPTfigdir = join(figroot, \"GPT2_raven\")\n",
    "EDMfigdir = join(figroot, \"EDM_raven\")\n",
    "DiTfigdir = join(figroot, \"DiT_raven\")\n",
    "SSMfigdir = join(figroot, \"SSM_raven\")\n",
    "SiTfigdir = join(figroot, \"SiT_raven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Set the maximum column width to 100 characters\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/GPT2_raven’: File exists\n",
      "mkdir: cannot create directory ‘/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/EDM_raven’: File exists\n",
      "mkdir: cannot create directory ‘/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/DiT_raven’: File exists\n",
      "mkdir: cannot create directory ‘/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/SSM_raven’: File exists\n",
      "mkdir: cannot create directory ‘/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/SiT_raven’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/GPT2_raven\n",
    "!mkdir  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/EDM_raven\n",
    "!mkdir  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/DiT_raven\n",
    "!mkdir  /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/SSM_raven\n",
    "!mkdir  {SiTfigdir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/Figure_memorization_inspection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions for Rule learning dynamics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to parse the experiment string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_and_convert(string):\n",
    "    \"\"\"Simple function to extract pattern like stream0_16 or stream16M and convert to float 0.16 or integer 16\"\"\"\n",
    "    # Pattern to match the \"0_16\" part and convert to float 0.16\n",
    "    match1 = re.search(r'stream(\\d+)_(\\d+)', string)\n",
    "    if match1:\n",
    "        num1 = str(match1.group(1))\n",
    "        num2 = str(match1.group(2))\n",
    "        result = float(f\"{num1}.{num2}\")\n",
    "        return result\n",
    "    \n",
    "    # Pattern to match the \"16M\" part and convert to integer 16\n",
    "    match2 = re.search(r'stream(\\d+)M', string)\n",
    "    if match2:\n",
    "        result = int(match2.group(1))\n",
    "        return result\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to load the samples and eval stats, plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_collect_sample(expname, exproot, prefix=None):\n",
    "    assert os.path.exists(join(exproot, expname, \"samples\")), expname  \n",
    "    # print(sorted(os.listdir(join(exproot, expname, \"samples\"))))\n",
    "    print(f\"Extracted data from {join(exproot, expname, 'samples')}\")\n",
    "    print(f\"example file:\", os.listdir(join(exproot, expname, 'samples'))[0:10])\n",
    "    # raise NotImplementedError(\"This function is not implemented yet\")\n",
    "    # for files with names like 'sample_rule_eval_995000.pt' find the one with largest number\n",
    "    epoch_nums = sorted([int(f.split(prefix)[-1].split(\".pt\")[0]) for f in os.listdir(join(exproot, expname,'samples')) if not (prefix in f)])\n",
    "    eval_col = {}\n",
    "    for epoch_num in tqdm(epoch_nums):\n",
    "        samples_eval = torch.load(join(exproot, expname, 'samples', f\"{epoch_num:07d}.pt\"))\n",
    "        eval_col[epoch_num] = samples_eval\n",
    "    return eval_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_collect_eval_data(expname, exproot, prefix=None):\n",
    "    assert os.path.exists(join(exproot, expname, \"samples\")), expname  \n",
    "    # print(sorted(os.listdir(join(exproot, expname, \"samples\"))))\n",
    "    print(f\"Extracted data from {join(exproot, expname, 'samples')}\")\n",
    "    print(f\"example file:\", os.listdir(join(exproot, expname, 'samples'))[0])\n",
    "    # for files with names like 'sample_rule_eval_995000.pt' find the one with largest number\n",
    "    epoch_nums = sorted([int(f.split(prefix)[-1].split(\".pt\")[0]) for f in os.listdir(join(exproot, expname,'samples')) if prefix in f])\n",
    "    eval_col = {}\n",
    "    for epoch_num in tqdm(epoch_nums):\n",
    "        samples_eval = torch.load(join(exproot, expname, 'samples', f\"{prefix}{epoch_num}.pt\"))\n",
    "        eval_col[epoch_num] = samples_eval\n",
    "    return eval_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rule_list_from_eval_col(eval_col, is_abinit = False):\n",
    "    epoch_list = sorted(list(eval_col.keys()))\n",
    "    rule_list_all = []\n",
    "    consistency_all = []\n",
    "    for epoch in eval_col.keys():\n",
    "        if is_abinit:\n",
    "            rule_list_all.append(eval_col[epoch]['rule_col_list_abinit'])\n",
    "            consistency_all.append((eval_col[epoch]['C3_list_abinit'], eval_col[epoch]['C2_list_abinit']))\n",
    "        else:\n",
    "            rule_list_all.append(eval_col[epoch]['rule_col_list'])\n",
    "            consistency_all.append((eval_col[epoch]['C3_list'], eval_col[epoch]['C2_list']))\n",
    "    rule_list_all = np.array(rule_list_all, dtype=object)\n",
    "    consistency_all = np.array(consistency_all, dtype=object)\n",
    "    print(rule_list_all.shape, consistency_all.shape)\n",
    "    return epoch_list, rule_list_all, consistency_all\n",
    "\n",
    "\n",
    "def extract_rule_list_from_eval_col_Diffusion(eval_col, ):\n",
    "    print(\"diffusion model, just fetch ab init generation\")\n",
    "    epoch_list = sorted(list(eval_col.keys()))\n",
    "    rule_list_all = []\n",
    "    consistency_all = []\n",
    "    for epoch in eval_col.keys():\n",
    "        rule_list_all.append(eval_col[epoch]['rule_col'])\n",
    "        consistency_all.append((eval_col[epoch]['c3_list'], eval_col[epoch]['c2_list']))\n",
    "\n",
    "    rule_list_all = np.array(rule_list_all, dtype=object)\n",
    "    consistency_all = np.array(consistency_all, dtype=object)\n",
    "    print(rule_list_all.shape, consistency_all.shape)\n",
    "    return epoch_list, rule_list_all, consistency_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rule_list_to_mat(rule_list_all, consistency_all):\n",
    "    \"\"\"Format the collected rule_list_all and consistency_all into rule_cnt_mat, cons3_rule_cnt_mat, cons2_rule_cnt_mat.\n",
    "    for plotting purposes.\n",
    "\n",
    "    Args:\n",
    "        rule_list_all: np.array, dtype object, shape=(num_epoch, num_sample, 3). \n",
    "        consistency_all: np.array, dtype object, shape=(num_epoch, 2, num_sample). \n",
    "                    where the 2nd dimension is the consistency of C3 and C2 rules corrspondingly. \n",
    "\n",
    "    Returns:\n",
    "        rule_cnt_mat: np.array, shape=(num_epoch, 40). \n",
    "        cons3_rule_cnt_mat: np.array, shape=(num_epoch, 40). \n",
    "        cons2_rule_cnt_mat: np.array, shape=(num_epoch, 40).\n",
    "    \"\"\"\n",
    "    epoch_num = rule_list_all.shape[0]\n",
    "    rule_pool_all = []\n",
    "    for i in range(epoch_num): # trange\n",
    "        rule_pool = np.concatenate(list(rule_list_all[i,:,:].flatten())).astype(int)\n",
    "        rule_pool_all.append(rule_pool)\n",
    "    # plot the number of rules == rule_i for each generation\n",
    "    rule_cnt_mat = np.zeros((epoch_num, 40))\n",
    "    for i in range(epoch_num): # trange\n",
    "        rule_pool = rule_pool_all[i]\n",
    "        rule_uniq, counts = np.unique(rule_pool, return_counts=True)\n",
    "        rule_cnt_mat[i, rule_uniq] = counts\n",
    "\n",
    "    cons3_rule_pool_all = []\n",
    "    cons2_rule_pool_all = []\n",
    "    for i in range(epoch_num): # trange\n",
    "        rule_pool = np.concatenate(list(consistency_all[i,0,:].flatten())).astype(int)\n",
    "        cons3_rule_pool_all.append(rule_pool)\n",
    "        rule_pool = np.concatenate(list(consistency_all[i,1,:].flatten())).astype(int)\n",
    "        cons2_rule_pool_all.append(rule_pool)\n",
    "\n",
    "    cons3_rule_cnt_mat = np.zeros((epoch_num, 40))\n",
    "    cons2_rule_cnt_mat = np.zeros((epoch_num, 40))\n",
    "    for i in range(epoch_num): # trange\n",
    "        rule_pool = cons3_rule_pool_all[i]\n",
    "        rule_uniq, counts = np.unique(rule_pool, return_counts=True)\n",
    "        cons3_rule_cnt_mat[i, rule_uniq] = counts\n",
    "        rule_pool = cons2_rule_pool_all[i]\n",
    "        rule_uniq, counts = np.unique(rule_pool, return_counts=True)\n",
    "        cons2_rule_cnt_mat[i, rule_uniq] = counts\n",
    "    return rule_cnt_mat, cons3_rule_cnt_mat, cons2_rule_cnt_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "from rule_new_utils import rule_table, relation_dict, attribute_dict\n",
    "from circuit_toolkit.plot_utils import saveallforms\n",
    "def visualize_indiv_rule_dynam(epoch_list, rule_mat, conv_wid=10, heldout_id=[1, 16, 20, 34, 37],\n",
    "                               titlestr=\"Valid rule count separated by rule type\", ylabel=\"Count\", axs=None):\n",
    "    # remove top and right spines from plot with plt\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    if axs is None:\n",
    "        figh, axs = plt.subplots(4, 10, figsize=(30, 12.5), sharex=True, sharey=True)\n",
    "    else:\n",
    "        figh = axs[0,0].get_figure()\n",
    "    axs_f = axs.flatten()\n",
    "    for i in range(40):\n",
    "        ax = axs_f[i]\n",
    "        # smooth the curve\n",
    "        smooth_rule_cnt = np.convolve(rule_mat[:,i], np.ones(conv_wid)/conv_wid, mode='same')\n",
    "        ax.plot(epoch_list, smooth_rule_cnt, alpha=0.7, )\n",
    "        ax.set_title(f\"R{i}: {rule_table[i]}\")\n",
    "        # change the font color of title to red\n",
    "        if i in heldout_id:\n",
    "            ax.title.set_color('red')\n",
    "        if i >= 30:\n",
    "            ax.set_xlabel(\"generation\")\n",
    "        if i % 10 == 0:\n",
    "            ax.set_ylabel(ylabel)\n",
    "    figh.suptitle(titlestr, fontsize=20)\n",
    "    figh.tight_layout()\n",
    "    figh.show()\n",
    "    return figh, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_heldout_rule(epoch_list, plot_mat, heldout_id, \n",
    "                                 normalizer=None, titlestr=\"\", \n",
    "                                 reflevel=None):#conv_wid=10, axs=None):\n",
    "    heldout_mask = np.zeros((40,)).astype(bool)\n",
    "    heldout_mask[heldout_id] = True\n",
    "    if normalizer is not None:\n",
    "        plot_mat = plot_mat / normalizer\n",
    "    figh, axs = plt.subplots(1, 2, figsize=(11, 5), sharey=True)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epoch_list, plot_mat[:, ~heldout_mask], alpha=0.4)\n",
    "    plt.plot(epoch_list, plot_mat[:, ~heldout_mask].mean(axis=1), color='black', linewidth=2)\n",
    "    if reflevel is not None:\n",
    "        plt.axhline(y=reflevel, color='r', linestyle='--')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epoch_list, plot_mat[:, heldout_mask], alpha=0.4)\n",
    "    plt.plot(epoch_list, plot_mat[:, heldout_mask].mean(axis=1), color='black', linewidth=2)\n",
    "    if reflevel is not None:\n",
    "        plt.axhline(y=reflevel, color='r', linestyle='--')\n",
    "    plt.suptitle(titlestr) # \"Accuracy of C3 for each rule type\"\n",
    "    plt.show()\n",
    "    return figh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndf_SiT = pd.read_csv(join(tabdir, \"SiT_raven_tensorboard_data.csv\"), index_col=0)\n",
    "tb_data_col_SiT = pkl.load(open(join(tabdir, \"SiT_raven_tensorboard_raw_data.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_name\n",
       "004-SiT_S_1-stream0_16M_pilot-Linear-velocity-None            004-SiT_S_1-stream0_16M_pilot-Linear-velocity-None/tensorboard_logs\n",
       "005-SiT_B_1-stream0_16M_pilot-Linear-velocity-None            005-SiT_B_1-stream0_16M_pilot-Linear-velocity-None/tensorboard_logs\n",
       "006-SiT_S_1-stream0_016M_all-Linear-velocity-None              006-SiT_S_1-stream0_016M_all-Linear-velocity-None/tensorboard_logs\n",
       "007-SiT_S_1-stream0_16M_all-Linear-velocity-None                007-SiT_S_1-stream0_16M_all-Linear-velocity-None/tensorboard_logs\n",
       "008-SiT_S_1-stream1_6M_all-Linear-velocity-None                  008-SiT_S_1-stream1_6M_all-Linear-velocity-None/tensorboard_logs\n",
       "010-SiT_S_1-stream16M_all-Linear-velocity-None                    010-SiT_S_1-stream16M_all-Linear-velocity-None/tensorboard_logs\n",
       "011-SiT_B_1-stream0_16M_all-Linear-velocity-None                011-SiT_B_1-stream0_16M_all-Linear-velocity-None/tensorboard_logs\n",
       "011-SiT_S_1-stream16M_heldout0-Linear-velocity-None          011-SiT_S_1-stream16M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "012-SiT_B_1-stream0_016M_all-Linear-velocity-None              012-SiT_B_1-stream0_016M_all-Linear-velocity-None/tensorboard_logs\n",
       "012-SiT_S_1-stream1_6M_heldout0-Linear-velocity-None        012-SiT_S_1-stream1_6M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "013-SiT_B_1-stream16M_all-Linear-velocity-None                    013-SiT_B_1-stream16M_all-Linear-velocity-None/tensorboard_logs\n",
       "013-SiT_S_1-stream0_016M_heldout0-Linear-velocity-None    013-SiT_S_1-stream0_016M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "014-SiT_B_1-stream1_6M_all-Linear-velocity-None                  014-SiT_B_1-stream1_6M_all-Linear-velocity-None/tensorboard_logs\n",
       "014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None      014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "015-SiT_B_1-stream0_016M_heldout0-Linear-velocity-None    015-SiT_B_1-stream0_016M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "016-SiT_B_1-stream16M_heldout0-Linear-velocity-None          016-SiT_B_1-stream16M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None      017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "018-SiT_B_1-stream1_6M_heldout0-Linear-velocity-None        018-SiT_B_1-stream1_6M_heldout0-Linear-velocity-None/tensorboard_logs\n",
       "Name: full_name, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syndf_SiT.full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data from /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/SiT/results/014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None/samples\n",
      "example file: ['0155000.pt', '0422500.pt', '0432500.pt', '0715000.pt', '0787500.pt', '0072500.pt', '0277500.pt', 'sample_rule_eval_465000.pt', 'sample_rule_eval_602500.pt', '0707500.pt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b9e9d094c5408ca0e77878d70bcdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for expfullname in [\"014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None/tensorboard_logs\",]:\n",
    "                    # \"017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None/tensorboard_logs\"\n",
    "    tb_record = tb_data_col_SiT[expfullname]\n",
    "    expname = expfullname.split(\"/tensorboard_logs\")[0]\n",
    "    prefix = \"sample_rule_eval_\" #\"eval_step\" if \"stream\" in expname else \"eval_epoch\"\n",
    "    # eval_col = sweep_collect_eval_data(expname, SiT_exproot, prefix=prefix)\n",
    "    sample_col = sweep_collect_sample(expname, SiT_exproot, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sample_col.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3 fraction: 0.7119140625 C2 fraction: 0.12548828125 valid fraction: 0.8453776041666666\n"
     ]
    }
   ],
   "source": [
    "C3_cnt, C2_cnt, valid_cnt, total_cnt = infer_rule_statistics_from_sample_batch(sample_col[1000000])\n",
    "print(\"C3 fraction:\", C3_cnt / total_cnt, \"C2 fraction:\", C2_cnt / total_cnt, \"valid fraction:\", valid_cnt / total_cnt / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146632936265733"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_cnt/total_cnt/3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6041603429518915"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_cnt/total_cnt/3)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7119140625"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1458 / 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Datasets/RPM_dataset/RPM1000k\n"
     ]
    }
   ],
   "source": [
    "!echo $STORE_DIR/Datasets/RPM_dataset/RPM1000k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "train_attr_fn = \"attr_all_1000k.pt\" \n",
    "data_root = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Datasets/RPM_dataset/RPM1000k\"\n",
    "def get_dataset(data_root, train_attr_fn, n_classes=40, cmb_per_class=4000, heldout_ids=()):\n",
    "    train_attrs = torch.load(f'{data_root}/{train_attr_fn}') # [35, 10000, 3, 9, 3]\n",
    "    attr_img_tsr = einops.rearrange(train_attrs,  'cls (B R) p (H W) attr -> cls B attr (R H) (p W)', H=3,W=3,p=3,R=3,attr=3,)\n",
    "    max_default_cmb = attr_img_tsr.shape[1]\n",
    "    if cmb_per_class > max_default_cmb:\n",
    "        raise ValueError(f'cmb_per_class should be less than {max_default_cmb}')\n",
    "    train_cls_msk = torch.ones(n_classes, dtype=bool)\n",
    "    for heldout_id in heldout_ids:\n",
    "        train_cls_msk[heldout_id] = False\n",
    "    X = attr_img_tsr[:, :cmb_per_class]\n",
    "    y = torch.arange(0, n_classes).unsqueeze(1).expand(n_classes, cmb_per_class).to(int)\n",
    "    X = einops.rearrange(X[train_cls_msk, :], 'cls B attr H W -> (cls B) attr H W')\n",
    "    y = einops.rearrange(y[train_cls_msk, :], 'cls B -> (cls B)')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tsr_X, train_tsr_y = get_dataset(data_root, train_attr_fn, n_classes=40, cmb_per_class=4000, heldout_ids=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160000, 3, 9, 9])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tsr_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 81)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tsr_X_rows = einops.rearrange(train_tsr_X, 'B attr (R h) W -> (B R) (attr h W)', R=3, h=3, W=9).numpy().astype(int)\n",
    "train_tsr_X_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_row_set = set([tuple(train_tsr_X_rows[i]) for i in range(train_tsr_X_rows.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sample_rows = einops.rearrange(sample_col[1000000].round().int(), 'B attr (R h) W -> (B R) (attr h W)', R=3, h=3, W=9).numpy().astype(int)\n",
    "gen_sample_rows_list = [tuple(gen_sample_rows[i]) for i in range(gen_sample_rows.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fraction_train_set(gen_sample_rows_list, train_X_row_set):\n",
    "    cnt = 0\n",
    "    for i, row in enumerate(gen_sample_rows_list):\n",
    "        if row in train_X_row_set:\n",
    "            cnt += 1\n",
    "            # print(i, row)\n",
    "    return cnt, cnt / len(gen_sample_rows_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2837cbaba8ab485599facae1f14ace1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0\n",
      "1 0 0.0\n",
      "2500 0 0.0\n",
      "5000 0 0.0\n",
      "7500 0 0.0\n",
      "10000 0 0.0\n",
      "12500 0 0.0\n",
      "15000 0 0.0\n",
      "17500 0 0.0\n",
      "20000 0 0.0\n",
      "22500 0 0.0\n",
      "25000 0 0.0\n",
      "27500 0 0.0\n",
      "30000 0 0.0\n",
      "32500 0 0.0\n",
      "35000 0 0.0\n",
      "37500 0 0.0\n",
      "40000 0 0.0\n",
      "42500 0 0.0\n",
      "45000 0 0.0\n",
      "47500 0 0.0\n",
      "50000 0 0.0\n",
      "52500 0 0.0\n",
      "55000 0 0.0\n",
      "57500 0 0.0\n",
      "60000 0 0.0\n",
      "62500 0 0.0\n",
      "65000 0 0.0\n",
      "67500 0 0.0\n",
      "70000 0 0.0\n",
      "72500 0 0.0\n",
      "75000 0 0.0\n",
      "77500 0 0.0\n",
      "80000 0 0.0\n",
      "82500 0 0.0\n",
      "85000 0 0.0\n",
      "87500 0 0.0\n",
      "90000 0 0.0\n",
      "92500 0 0.0\n",
      "95000 0 0.0\n",
      "97500 0 0.0\n",
      "100000 0 0.0\n",
      "102500 0 0.0\n",
      "105000 0 0.0\n",
      "107500 0 0.0\n",
      "110000 0 0.0\n",
      "112500 0 0.0\n",
      "115000 0 0.0\n",
      "117500 0 0.0\n",
      "120000 0 0.0\n",
      "122500 0 0.0\n",
      "125000 0 0.0\n",
      "127500 0 0.0\n",
      "130000 0 0.0\n",
      "132500 0 0.0\n",
      "135000 0 0.0\n",
      "137500 0 0.0\n",
      "140000 0 0.0\n",
      "142500 0 0.0\n",
      "145000 0 0.0\n",
      "147500 0 0.0\n",
      "150000 0 0.0\n",
      "152500 0 0.0\n",
      "155000 0 0.0\n",
      "157500 0 0.0\n",
      "160000 0 0.0\n",
      "162500 0 0.0\n",
      "165000 0 0.0\n",
      "167500 0 0.0\n",
      "170000 0 0.0\n",
      "172500 0 0.0\n",
      "175000 0 0.0\n",
      "177500 0 0.0\n",
      "180000 0 0.0\n",
      "182500 0 0.0\n",
      "185000 0 0.0\n",
      "187500 0 0.0\n",
      "190000 0 0.0\n",
      "192500 0 0.0\n",
      "195000 0 0.0\n",
      "197500 0 0.0\n",
      "200000 0 0.0\n",
      "202500 0 0.0\n",
      "205000 0 0.0\n",
      "207500 0 0.0\n",
      "210000 0 0.0\n",
      "212500 0 0.0\n",
      "215000 0 0.0\n",
      "217500 0 0.0\n",
      "220000 0 0.0\n",
      "222500 0 0.0\n",
      "225000 0 0.0\n",
      "227500 0 0.0\n",
      "230000 0 0.0\n",
      "232500 0 0.0\n",
      "235000 0 0.0\n",
      "237500 0 0.0\n",
      "240000 0 0.0\n",
      "242500 0 0.0\n",
      "245000 0 0.0\n",
      "247500 0 0.0\n",
      "250000 0 0.0\n",
      "252500 0 0.0\n",
      "255000 0 0.0\n",
      "257500 0 0.0\n",
      "260000 0 0.0\n",
      "262500 0 0.0\n",
      "265000 0 0.0\n",
      "267500 0 0.0\n",
      "270000 0 0.0\n",
      "272500 0 0.0\n",
      "275000 0 0.0\n",
      "277500 0 0.0\n",
      "280000 0 0.0\n",
      "282500 0 0.0\n",
      "285000 0 0.0\n",
      "287500 0 0.0\n",
      "290000 0 0.0\n",
      "292500 0 0.0\n",
      "295000 0 0.0\n",
      "297500 0 0.0\n",
      "300000 0 0.0\n",
      "302500 0 0.0\n",
      "305000 0 0.0\n",
      "307500 0 0.0\n",
      "310000 0 0.0\n",
      "312500 0 0.0\n",
      "315000 0 0.0\n",
      "317500 0 0.0\n",
      "320000 0 0.0\n",
      "322500 0 0.0\n",
      "325000 0 0.0\n",
      "327500 0 0.0\n",
      "330000 0 0.0\n",
      "332500 0 0.0\n",
      "335000 0 0.0\n",
      "337500 0 0.0\n",
      "340000 0 0.0\n",
      "342500 0 0.0\n",
      "345000 0 0.0\n",
      "347500 0 0.0\n",
      "350000 0 0.0\n",
      "352500 0 0.0\n",
      "355000 0 0.0\n",
      "357500 0 0.0\n",
      "360000 0 0.0\n",
      "362500 0 0.0\n",
      "365000 0 0.0\n",
      "367500 0 0.0\n",
      "370000 0 0.0\n",
      "372500 0 0.0\n",
      "375000 0 0.0\n",
      "377500 0 0.0\n",
      "380000 0 0.0\n",
      "382500 0 0.0\n",
      "385000 0 0.0\n",
      "387500 0 0.0\n",
      "390000 0 0.0\n",
      "392500 0 0.0\n",
      "395000 0 0.0\n",
      "397500 0 0.0\n",
      "400000 0 0.0\n",
      "402500 0 0.0\n",
      "405000 0 0.0\n",
      "407500 0 0.0\n",
      "410000 0 0.0\n",
      "412500 0 0.0\n",
      "415000 0 0.0\n",
      "417500 0 0.0\n",
      "420000 0 0.0\n",
      "422500 0 0.0\n",
      "425000 0 0.0\n",
      "427500 0 0.0\n",
      "430000 0 0.0\n",
      "432500 0 0.0\n",
      "435000 0 0.0\n",
      "437500 0 0.0\n",
      "440000 0 0.0\n",
      "442500 0 0.0\n",
      "445000 0 0.0\n",
      "447500 0 0.0\n",
      "450000 0 0.0\n",
      "452500 0 0.0\n",
      "455000 0 0.0\n",
      "457500 0 0.0\n",
      "460000 0 0.0\n",
      "462500 0 0.0\n",
      "465000 0 0.0\n",
      "467500 0 0.0\n",
      "470000 0 0.0\n",
      "472500 0 0.0\n",
      "475000 0 0.0\n",
      "477500 0 0.0\n",
      "480000 0 0.0\n",
      "482500 0 0.0\n",
      "485000 0 0.0\n",
      "487500 0 0.0\n",
      "490000 0 0.0\n",
      "492500 0 0.0\n",
      "495000 0 0.0\n",
      "497500 0 0.0\n",
      "500000 0 0.0\n",
      "502500 0 0.0\n",
      "505000 0 0.0\n",
      "507500 0 0.0\n",
      "510000 0 0.0\n",
      "512500 0 0.0\n",
      "515000 0 0.0\n",
      "517500 0 0.0\n",
      "520000 0 0.0\n",
      "522500 0 0.0\n",
      "525000 0 0.0\n",
      "527500 0 0.0\n",
      "530000 0 0.0\n",
      "532500 0 0.0\n",
      "535000 0 0.0\n",
      "537500 0 0.0\n",
      "540000 0 0.0\n",
      "542500 0 0.0\n",
      "545000 0 0.0\n",
      "547500 0 0.0\n",
      "550000 0 0.0\n",
      "552500 0 0.0\n",
      "555000 0 0.0\n",
      "557500 0 0.0\n",
      "560000 0 0.0\n",
      "562500 0 0.0\n",
      "565000 0 0.0\n",
      "567500 0 0.0\n",
      "570000 0 0.0\n",
      "572500 0 0.0\n",
      "575000 0 0.0\n",
      "577500 0 0.0\n",
      "580000 0 0.0\n",
      "582500 0 0.0\n",
      "585000 0 0.0\n",
      "587500 0 0.0\n",
      "590000 0 0.0\n",
      "592500 0 0.0\n",
      "595000 0 0.0\n",
      "597500 0 0.0\n",
      "600000 0 0.0\n",
      "602500 0 0.0\n",
      "605000 0 0.0\n",
      "607500 0 0.0\n",
      "610000 0 0.0\n",
      "612500 0 0.0\n",
      "615000 0 0.0\n",
      "617500 0 0.0\n",
      "620000 0 0.0\n",
      "622500 0 0.0\n",
      "625000 0 0.0\n",
      "627500 0 0.0\n",
      "630000 0 0.0\n",
      "632500 0 0.0\n",
      "635000 0 0.0\n",
      "637500 0 0.0\n",
      "640000 0 0.0\n",
      "642500 0 0.0\n",
      "645000 0 0.0\n",
      "647500 0 0.0\n",
      "650000 0 0.0\n",
      "652500 0 0.0\n",
      "655000 0 0.0\n",
      "657500 0 0.0\n",
      "660000 0 0.0\n",
      "662500 0 0.0\n",
      "665000 0 0.0\n",
      "667500 0 0.0\n",
      "670000 0 0.0\n",
      "672500 0 0.0\n",
      "675000 0 0.0\n",
      "677500 0 0.0\n",
      "680000 0 0.0\n",
      "682500 0 0.0\n",
      "685000 0 0.0\n",
      "687500 0 0.0\n",
      "690000 0 0.0\n",
      "692500 0 0.0\n",
      "695000 0 0.0\n",
      "697500 0 0.0\n",
      "700000 0 0.0\n",
      "702500 0 0.0\n",
      "705000 0 0.0\n",
      "707500 0 0.0\n",
      "710000 0 0.0\n",
      "712500 0 0.0\n",
      "715000 0 0.0\n",
      "717500 0 0.0\n",
      "720000 0 0.0\n",
      "722500 0 0.0\n",
      "725000 0 0.0\n",
      "727500 0 0.0\n",
      "730000 0 0.0\n",
      "732500 0 0.0\n",
      "735000 0 0.0\n",
      "737500 0 0.0\n",
      "740000 0 0.0\n",
      "742500 0 0.0\n",
      "745000 0 0.0\n",
      "747500 0 0.0\n",
      "750000 0 0.0\n",
      "752500 0 0.0\n",
      "755000 0 0.0\n",
      "757500 0 0.0\n",
      "760000 0 0.0\n",
      "762500 0 0.0\n",
      "765000 0 0.0\n",
      "767500 0 0.0\n",
      "770000 0 0.0\n",
      "772500 0 0.0\n",
      "775000 0 0.0\n",
      "777500 0 0.0\n",
      "780000 0 0.0\n",
      "782500 0 0.0\n",
      "785000 0 0.0\n",
      "787500 0 0.0\n",
      "790000 0 0.0\n",
      "792500 0 0.0\n",
      "795000 0 0.0\n",
      "797500 0 0.0\n",
      "800000 0 0.0\n",
      "802500 0 0.0\n",
      "805000 0 0.0\n",
      "807500 0 0.0\n",
      "810000 0 0.0\n",
      "812500 0 0.0\n",
      "815000 0 0.0\n",
      "817500 0 0.0\n",
      "820000 0 0.0\n",
      "822500 0 0.0\n",
      "825000 0 0.0\n",
      "827500 0 0.0\n",
      "830000 0 0.0\n",
      "832500 0 0.0\n",
      "835000 0 0.0\n",
      "837500 0 0.0\n",
      "840000 0 0.0\n",
      "842500 0 0.0\n",
      "845000 0 0.0\n",
      "847500 0 0.0\n",
      "850000 0 0.0\n",
      "852500 0 0.0\n",
      "855000 0 0.0\n",
      "857500 0 0.0\n",
      "860000 0 0.0\n",
      "862500 0 0.0\n",
      "865000 0 0.0\n",
      "867500 0 0.0\n",
      "870000 0 0.0\n",
      "872500 0 0.0\n",
      "875000 0 0.0\n",
      "877500 0 0.0\n",
      "880000 0 0.0\n",
      "882500 0 0.0\n",
      "885000 0 0.0\n",
      "887500 0 0.0\n",
      "890000 0 0.0\n",
      "892500 0 0.0\n",
      "895000 0 0.0\n",
      "897500 0 0.0\n",
      "900000 0 0.0\n",
      "902500 0 0.0\n",
      "905000 0 0.0\n",
      "907500 0 0.0\n",
      "910000 0 0.0\n",
      "912500 0 0.0\n",
      "915000 0 0.0\n",
      "917500 0 0.0\n",
      "920000 0 0.0\n",
      "922500 0 0.0\n",
      "925000 0 0.0\n",
      "927500 0 0.0\n",
      "930000 0 0.0\n",
      "932500 0 0.0\n",
      "935000 0 0.0\n",
      "937500 0 0.0\n",
      "940000 0 0.0\n",
      "942500 0 0.0\n",
      "945000 0 0.0\n",
      "947500 0 0.0\n",
      "950000 0 0.0\n",
      "952500 0 0.0\n",
      "955000 0 0.0\n",
      "957500 0 0.0\n",
      "960000 0 0.0\n",
      "962500 0 0.0\n",
      "965000 0 0.0\n",
      "967500 0 0.0\n",
      "970000 0 0.0\n",
      "972500 0 0.0\n",
      "975000 0 0.0\n",
      "977500 0 0.0\n",
      "980000 0 0.0\n",
      "982500 0 0.0\n",
      "985000 0 0.0\n",
      "987500 0 0.0\n",
      "990000 0 0.0\n",
      "992500 0 0.0\n",
      "995000 0 0.0\n",
      "997500 0 0.0\n",
      "1000000 0 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(sample_col.keys()):\n",
    "    gen_sample_rows = einops.rearrange(sample_col[epoch].round().int(), 'B attr (R h) W -> (B R) (attr h W)', R=3, h=3, W=9).numpy().astype(int)\n",
    "    gen_sample_rows_list = [tuple(gen_sample_rows[i]) for i in range(gen_sample_rows.shape[0])]\n",
    "    cnt, frac = check_fraction_train_set(gen_sample_rows_list, train_X_row_set)\n",
    "    print(epoch, cnt, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data from /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/SiT/results/017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None/samples\n",
      "example file: 0155000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003bbf4a98124ab499142025d1a2a794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusion model, just fetch ab init generation\n",
      "(402, 2048, 3) (402, 2, 2048)\n"
     ]
    }
   ],
   "source": [
    "# for expfullname in syndf_SiT.full_name:\n",
    "for expfullname in [\"017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None/tensorboard_logs\"]:\n",
    "    tb_record = tb_data_col_SiT[expfullname]\n",
    "    expname = expfullname.split(\"/tensorboard_logs\")[0]\n",
    "    prefix = \"sample_rule_eval_\" #\"eval_step\" if \"stream\" in expname else \"eval_epoch\"\n",
    "    eval_col = sweep_collect_eval_data(expname, SiT_exproot, prefix=prefix)\n",
    "    epoch_list, rule_list_all, consistency_all = extract_rule_list_from_eval_col_Diffusion(eval_col, )\n",
    "    rule_cnt_mat, cons3_rule_cnt_mat, cons2_rule_cnt_mat = format_rule_list_to_mat(rule_list_all, consistency_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot all individual rule data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expfullname in syndf_SiT.full_name:\n",
    "    tb_record = tb_data_col_SiT[expfullname]\n",
    "    expname = expfullname.split(\"/tensorboard_logs\")[0]\n",
    "    prefix = \"sample_rule_eval_\" #\"eval_step\" if \"stream\" in expname else \"eval_epoch\"\n",
    "    eval_col = sweep_collect_eval_data(expname, SiT_exproot, prefix=prefix)\n",
    "    epoch_list, rule_list_all, consistency_all = extract_rule_list_from_eval_col_Diffusion(eval_col, )\n",
    "    rule_cnt_mat, cons3_rule_cnt_mat, cons2_rule_cnt_mat = format_rule_list_to_mat(rule_list_all, consistency_all)\n",
    "    eval_sample_num = rule_list_all.shape[1]\n",
    "    print(expname)\n",
    "    if \"heldout0\" in expname:\n",
    "        heldout_id = [1, 16, 20, 34, 37]  \n",
    "    else:\n",
    "        heldout_id = []\n",
    "\n",
    "    figh, axs = visualize_indiv_rule_dynam(epoch_list, rule_cnt_mat, conv_wid=10, heldout_id=heldout_id,\n",
    "                            titlestr=f\"{expname}\\nValid rule count separated by rule type\")\n",
    "    saveallforms(SiTfigdir, f\"{expname}_indiv_rule_validity\", figh)\n",
    "\n",
    "    figh, axs = visualize_indiv_rule_dynam(epoch_list, cons3_rule_cnt_mat, conv_wid=10, heldout_id=heldout_id,\n",
    "                                        titlestr=f\"{expname}\\nConsistency 3 (blue) and 2 (orange) rule count\", )\n",
    "    figh, axs = visualize_indiv_rule_dynam(epoch_list, cons2_rule_cnt_mat, conv_wid=10, heldout_id=heldout_id,\n",
    "                                        titlestr=f\"{expname}\\nConsistency 3 (blue) and 2 (orange) rule count\", axs=axs)\n",
    "    saveallforms(SiTfigdir, f\"{expname}_indiv_rule_consistency\", figh)\n",
    "    \n",
    "    figh = visualize_train_heldout_rule(epoch_list, rule_cnt_mat, heldout_id, \n",
    "                                normalizer=eval_sample_num * 3, reflevel=1 / 40,\n",
    "                                titlestr=f\"{expname}\\nValid rule fraction\")\n",
    "    saveallforms(EDMfigdir, f\"{expname}_train_held_rule_validity\", figh)\n",
    "\n",
    "    figh = visualize_train_heldout_rule(epoch_list, cons3_rule_cnt_mat, heldout_id, \n",
    "                                normalizer=eval_sample_num, reflevel=1 / 40,\n",
    "                                titlestr=f\"{expname}\\nC3 sample fraction\")\n",
    "    saveallforms(SiTfigdir, f\"{expname}_train_held_rule_consistency\", figh)\n",
    "    # raise ValueError(\"stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
