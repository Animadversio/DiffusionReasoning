{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternatively, create a custom model class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertModel\n",
    "\n",
    "# Load the default BERT configuration\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "# Customize the configuration\n",
    "# reduce vocab size\n",
    "config.vocab_size = 8 * 11 * 11\n",
    "config.max_position_embeddings = 82\n",
    "config.num_hidden_layers = 6          # Reduce the number of transformer layers\n",
    "config.hidden_size = 384              # Decrease the hidden size\n",
    "config.num_attention_heads = 6        # Adjust the number of attention heads\n",
    "config.intermediate_size = 1536       # Modify the size of the feedforward layers\n",
    "config.hidden_dropout_prob = 0.2      # Increase dropout to prevent overfitting\n",
    "config.attention_probs_dropout_prob = 0.2\n",
    "config.num_labels = 40                 # For a 3-class classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-2.2080,  2.6604,  2.1954,  ...,  0.4806,  0.5610, -2.0110],\n",
      "         [ 0.2337, -1.2299,  0.5211,  ...,  0.2094, -0.5270, -0.5702],\n",
      "         [ 0.2861,  0.8851,  0.0446,  ...,  0.5752,  0.3057, -0.4804],\n",
      "         ...,\n",
      "         [ 0.1296,  0.5067, -0.1854,  ..., -0.3859, -0.2433, -0.6874],\n",
      "         [ 0.5463, -0.5763,  2.0978,  ..., -0.1174, -0.4010,  1.9679],\n",
      "         [-3.2281,  2.2028,  0.2580,  ...,  1.0704,  0.2995, -0.0545]]]), pooler_output=tensor([[-7.5671e-02, -3.9718e-02,  1.7146e-02,  2.7881e-01,  1.8024e-01,\n",
      "          1.3249e-01, -1.7843e-01,  3.4028e-01,  2.8295e-01, -3.4014e-01,\n",
      "         -6.5024e-01, -9.9486e-02,  2.4463e-01, -3.7889e-01, -3.5526e-01,\n",
      "         -2.1448e-01, -3.2601e-01, -5.1166e-01,  4.8278e-01, -8.3381e-01,\n",
      "          1.6468e-02,  3.1327e-01, -6.6662e-01, -7.4291e-01,  5.2439e-01,\n",
      "          1.6485e-01, -2.3875e-01, -5.4885e-01,  7.3861e-01, -2.4308e-01,\n",
      "          5.2492e-01, -5.3238e-01, -1.7474e-01,  2.3853e-01, -4.7072e-01,\n",
      "          1.3604e-01, -8.9252e-02,  4.2724e-01, -1.3750e-01,  1.8160e-01,\n",
      "         -2.6803e-01,  2.8112e-01, -6.8757e-01,  4.8171e-01, -4.8765e-01,\n",
      "          3.6946e-01, -2.5305e-01,  2.3792e-01, -3.7325e-01, -4.7932e-01,\n",
      "         -4.7911e-01,  4.8792e-01,  4.6405e-01, -9.7632e-03, -1.1038e-01,\n",
      "          5.7288e-01,  7.8404e-01,  7.0675e-01, -2.9398e-01, -1.4720e-01,\n",
      "          1.7415e-01, -2.9999e-02,  2.5641e-01,  9.7069e-02,  2.1953e-01,\n",
      "         -2.1188e-01, -5.0793e-01,  4.1081e-01,  4.4015e-01, -3.3139e-01,\n",
      "         -4.8571e-01, -3.2792e-02,  7.6450e-01,  2.6869e-01, -5.6813e-01,\n",
      "          7.8216e-01, -4.0740e-01,  1.0265e-01,  2.6026e-01, -4.8336e-01,\n",
      "         -2.1862e-01,  2.8864e-01, -5.1056e-01,  3.2782e-01,  5.5046e-01,\n",
      "         -5.7141e-01,  1.6971e-01,  3.7486e-01, -5.7273e-01, -1.6197e-01,\n",
      "         -2.4178e-01,  1.3901e-01, -2.7841e-01, -4.2872e-01, -9.2021e-02,\n",
      "          5.8636e-01, -5.4276e-01,  5.5353e-02, -3.1131e-01, -2.6875e-01,\n",
      "          6.7179e-01, -6.1696e-01,  2.1437e-01,  5.3433e-02, -4.1868e-01,\n",
      "          2.1051e-01, -1.0713e-01, -3.4230e-01,  4.2221e-01, -5.2905e-02,\n",
      "         -4.2469e-01,  9.5196e-02, -2.9435e-01, -1.3294e-01,  1.0556e-01,\n",
      "         -8.3710e-02, -6.8112e-01,  4.3337e-02,  3.4821e-01, -4.7818e-01,\n",
      "         -2.5971e-03,  3.6462e-01,  1.7134e-02,  3.1226e-01,  1.4918e-02,\n",
      "          3.0493e-01,  3.6721e-01, -4.0115e-02,  3.9211e-02,  2.3522e-01,\n",
      "          5.6316e-01, -2.7902e-01, -7.1385e-02, -4.7478e-01,  3.5309e-01,\n",
      "         -1.3387e-01,  2.8552e-01,  4.9337e-01,  3.7850e-01,  4.4801e-03,\n",
      "         -8.1320e-02, -3.8802e-01,  2.4412e-01, -6.1763e-01,  1.5082e-01,\n",
      "          4.9342e-01, -5.9759e-02, -5.2320e-02, -4.5382e-02,  2.9199e-01,\n",
      "         -1.9454e-01,  3.3101e-01, -5.9664e-01, -5.5780e-01, -2.3922e-01,\n",
      "          9.1741e-02,  7.3288e-02, -3.2817e-02,  7.5664e-01, -5.4075e-01,\n",
      "         -5.4040e-02, -1.6873e-01,  4.9138e-01, -9.0818e-02,  2.0543e-01,\n",
      "         -2.5063e-01, -2.1199e-01,  2.5226e-01,  1.3739e-01, -5.3063e-01,\n",
      "          7.1900e-02,  6.3308e-01,  2.4451e-01, -9.9794e-02, -6.5543e-02,\n",
      "          4.7467e-01,  1.6704e-01,  6.0229e-01,  1.5599e-01,  4.2122e-01,\n",
      "          3.3785e-01, -7.9348e-02,  5.2972e-01, -2.4987e-01,  4.9227e-01,\n",
      "         -2.0125e-01,  1.2161e-01, -6.8259e-01, -6.9931e-02, -7.9057e-02,\n",
      "         -8.2144e-02,  3.1544e-01,  5.8301e-02, -5.5613e-01, -7.0867e-02,\n",
      "          7.1488e-02, -2.0794e-01, -2.0857e-01, -2.0824e-01,  1.9625e-01,\n",
      "          5.0886e-01,  1.8178e-02,  1.9127e-01, -3.6844e-01, -1.6545e-01,\n",
      "          1.5854e-01, -1.7746e-01,  5.0597e-01,  6.7482e-01, -2.6177e-01,\n",
      "          4.4163e-01,  4.3143e-01,  9.4740e-02, -1.6696e-01,  2.5999e-05,\n",
      "         -5.0029e-01,  3.1375e-01,  4.0537e-01,  5.0115e-01, -3.0842e-01,\n",
      "         -2.0768e-01,  5.4394e-01,  2.4090e-01,  1.0972e-01, -3.3340e-01,\n",
      "         -1.2685e-01, -1.0141e-01, -4.3589e-01,  4.4211e-01,  7.4755e-01,\n",
      "         -1.5100e-01,  2.0346e-01, -1.1030e-01,  2.8369e-01, -2.3545e-01,\n",
      "          4.2458e-01, -2.0222e-01, -3.4084e-01, -4.2114e-01, -1.5355e-01,\n",
      "          5.4262e-01,  2.1336e-01,  4.7952e-01, -5.5849e-01, -2.6651e-01,\n",
      "         -4.5341e-02, -4.6281e-04,  4.1203e-01,  2.5141e-01, -5.9646e-01,\n",
      "          2.9248e-01, -5.0175e-01,  2.0186e-01, -1.2665e-01,  1.4425e-01,\n",
      "          1.3344e-01, -5.2071e-02, -2.7154e-01,  1.0203e-01,  2.4490e-01,\n",
      "         -2.6013e-01,  3.2648e-01, -4.5560e-01,  5.8816e-01,  7.0103e-01,\n",
      "          4.4360e-01,  1.1992e-01,  5.2361e-01,  3.3160e-01,  5.1352e-03,\n",
      "         -4.1329e-01,  6.5854e-02,  5.5652e-01,  1.5467e-01, -4.6499e-02,\n",
      "         -5.8154e-02,  1.1570e-01,  4.0922e-01, -5.5060e-01, -1.8256e-01,\n",
      "          4.5007e-02,  3.9045e-01,  1.1798e-01, -8.5209e-01,  4.2251e-01,\n",
      "          5.4420e-01,  2.7803e-01, -5.0874e-02,  1.7679e-01, -1.4691e-01,\n",
      "          2.1260e-01,  1.5153e-01,  1.1278e-01, -1.7911e-01,  2.7060e-01,\n",
      "         -1.2738e-01, -1.0995e-01,  7.5206e-01, -2.4414e-02, -8.5730e-02,\n",
      "          8.0758e-02, -3.1118e-01, -2.3107e-01, -4.8786e-01,  4.4299e-02,\n",
      "         -5.8252e-01,  4.3818e-01, -4.4010e-02,  4.1347e-01, -3.8991e-01,\n",
      "          2.5884e-01, -2.3192e-01,  7.1612e-02, -4.3528e-01, -1.7389e-01,\n",
      "         -5.3002e-01,  1.6419e-01, -1.8736e-01,  2.6274e-01, -9.4872e-02,\n",
      "         -3.9069e-01, -2.8526e-01, -5.0595e-01,  6.5193e-02, -5.4228e-01,\n",
      "          1.6986e-02, -4.1666e-01, -3.1869e-02, -1.5667e-01,  1.5146e-01,\n",
      "          4.2049e-01,  1.7571e-01, -1.4571e-01, -1.2039e-01, -5.2708e-01,\n",
      "          3.7374e-01,  5.5608e-01,  6.8814e-02,  1.1487e-01,  3.9261e-01,\n",
      "         -4.1549e-01, -2.9310e-01,  2.2156e-01,  1.3574e-01,  2.3089e-01,\n",
      "         -1.9927e-01, -9.7941e-02,  6.4274e-01, -2.9943e-01,  3.1330e-03,\n",
      "          2.1947e-03, -4.4239e-01, -8.7020e-02, -6.7634e-02, -1.1542e-02,\n",
      "          6.9097e-02,  5.0879e-01, -3.5591e-01,  2.8466e-01, -1.2326e-01,\n",
      "         -2.8736e-02,  3.7665e-01, -2.7831e-01, -4.2399e-01, -2.8961e-01,\n",
      "          5.5863e-01,  9.5304e-02,  5.7773e-02, -3.5587e-01, -1.8193e-01,\n",
      "         -2.1606e-01,  4.4449e-01,  5.5574e-01,  5.5810e-01,  2.7725e-01,\n",
      "          4.9905e-01,  2.7276e-01, -2.4415e-01, -5.1145e-01, -5.6437e-01,\n",
      "          4.5560e-01, -2.8470e-01, -3.9527e-05,  4.6911e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs_embeds=torch.randn(1, 81, 384))\n",
    "    print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('/n/home12/binxuwang/Github/DiffusionReasoning/')\n",
    "from GPT_models.GPT_RAVEN_model_lib import SepWordEmbed, CmbWordEmbed, SepLMhead, CmbLMhead\n",
    "class MultiIdxBERTModel(nn.Module):\n",
    "    def __init__(self, attribute_dims=(7,10,10), vocab_size=0, max_length=128, n_embd=768, n_class=40, is_sep_embed=True, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        # Combine embeddings\n",
    "        combined_embedding_size = n_embd  # Adjust based on your combination strategy\n",
    "        if is_sep_embed:\n",
    "            self.sep_word_embed = SepWordEmbed(attribute_dims, embed_size=n_embd//3)\n",
    "            self.multi_lmhead = SepLMhead(attribute_dims, embed_size=n_embd//3)\n",
    "        else:\n",
    "            self.sep_word_embed = CmbWordEmbed(attribute_dims, embed_size=n_embd)\n",
    "            self.multi_lmhead = CmbLMhead(attribute_dims, embed_size=n_embd)\n",
    "        config = BertConfig(vocab_size=vocab_size, \n",
    "                            max_position_embeddings=max_length, \n",
    "                            hidden_size=combined_embedding_size, **kwargs)\n",
    "        self.bert = BertModel(config)\n",
    "        self.context_embed = nn.Embedding(1, n_embd) # dummy embedding for start token\n",
    "        self.classifier = nn.Linear(n_embd, n_class)\n",
    "\n",
    "    def forward(self, input_ids, y=None):\n",
    "        # input_ids is expected to be a list of three tensors [attr1, attr2, attr3]\n",
    "        SOS = torch.zeros(input_ids.shape[0], dtype=th.long).to(input_ids[0].device)\n",
    "        SOS_vec = self.context_embed(SOS)\n",
    "        combined_embedding = self.sep_word_embed(input_ids)\n",
    "        combined_embedding = torch.concat([SOS_vec[:,None,:], combined_embedding, ], dim=1)\n",
    "        outputs = self.bert(inputs_embeds=combined_embedding)\n",
    "        logits = self.classifier(outputs.pooler_output)\n",
    "        return logits, outputs.last_hidden_state\n",
    "    \n",
    "\n",
    "# def multi_attr_loss(outputs, targets, loss_fn=F.cross_entropy, ):\n",
    "#     loss1 = loss_fn(outputs[0].permute(0,2,1), targets[..., 0])\n",
    "#     loss2 = loss_fn(outputs[1].permute(0,2,1), targets[..., 1])\n",
    "#     loss3 = loss_fn(outputs[2].permute(0,2,1), targets[..., 2])\n",
    "#     return loss1 + loss2 + loss3\n",
    "\n",
    "\n",
    "# def multi_attr_loss_vec(outputs, targets, loss_fn=F.cross_entropy, ):\n",
    "#     logits1, logits2, logits3 = outputs[0], outputs[1], outputs[2]\n",
    "#     loss1 = loss_fn(logits1.reshape(-1, logits1.size(-1)), targets[..., 0].view(-1))\n",
    "#     loss2 = loss_fn(logits2.reshape(-1, logits2.size(-1)), targets[..., 1].view(-1))\n",
    "#     loss3 = loss_fn(logits3.reshape(-1, logits3.size(-1)), targets[..., 2].view(-1))\n",
    "#     return loss1 + loss2 + loss3\n",
    "\n",
    "\n",
    "# def next_token_loss(outputs, targets, loss_fn=F.cross_entropy):\n",
    "#     logits1, logits2, logits3 = outputs[0], outputs[1], outputs[2]\n",
    "#     loss1 = loss_fn(logits1[:, :-1, :].permute(0,2,1), targets[:, 1:, 0])\n",
    "#     loss2 = loss_fn(logits2[:, :-1, :].permute(0,2,1), targets[:, 1:, 1])\n",
    "#     loss3 = loss_fn(logits3[:, :-1, :].permute(0,2,1), targets[:, 1:, 2])\n",
    "#     return loss1 + loss2 + loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1200000, 3, 9, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/einops/parsing.py:137: RuntimeWarning: It is discouraged to use axes names that are keywords: class\n",
      "  warnings.warn(\"It is discouraged to use axes names that are keywords: {}\".format(name), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([140000, 81, 3]) torch.Size([20000, 81, 3]) torch.Size([2000, 81, 3])\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "def preprocess_ids(attr_seq_tsr, ):\n",
    "    attr_seq_tsr_pps = attr_seq_tsr + 1 # clone() removed\n",
    "    return attr_seq_tsr_pps\n",
    "\n",
    "cmb_per_class = 4000\n",
    "heldout_id = [1, 16, 20, 34, 37]\n",
    "# Create a mask with all True values\n",
    "# Set the specified rows to False\n",
    "train_mask = torch.ones(40, dtype=torch.bool)\n",
    "train_mask[heldout_id] = False\n",
    "# old version\n",
    "# data_dir = '/n/home12/binxuwang/Github/DiffusionReasoning/'\n",
    "# attr_all = np.load(data_dir+'attr_all.npy')\n",
    "data_dir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Datasets/RPM_dataset/RPM1000k\"\n",
    "attr_all = np.load(join(data_dir, \"attr_all_1000k.npy\"))\n",
    "print(attr_all.shape)\n",
    "attr_all_rows = torch.from_numpy(attr_all, )\n",
    "del attr_all\n",
    "# attr_img_tsr = einops.rearrange(attr_all_rows,  'class (B R) p (h w) attr -> class B attr (R h) (p w)', h=3,w=3,p=3,R=3)\n",
    "attr_seq_tsr = einops.rearrange(attr_all_rows,  'class (B R) p (h w) attr -> class B (R p h w) attr', h=3,w=3,p=3,R=3)\n",
    "del attr_all_rows\n",
    "# Set the y of the dataset, which is the class index; split the y into training and validation\n",
    "y_rule = th.arange(attr_seq_tsr.shape[0], dtype=th.long).unsqueeze(1)\n",
    "y_rule = y_rule.repeat(1, attr_seq_tsr.shape[1])\n",
    "attr_seq_tsr = preprocess_ids(attr_seq_tsr)\n",
    "# if the cmb_per_class is too large, change it such that it won't overlap with the validation set\n",
    "if cmb_per_class > attr_seq_tsr.shape[1] - 500:\n",
    "    cmb_per_class = attr_seq_tsr.shape[1] - 500\n",
    "attr_seq_tsr_train, attr_seq_tsr_val, attr_seq_tsr_val_eval = \\\n",
    "    attr_seq_tsr[train_mask, :cmb_per_class], attr_seq_tsr[:, -500:], attr_seq_tsr[:, -50:] # changed June 30, 2024, also eval on untrained rules.\n",
    "y_rule_train, y_rule_val, y_rule_val_eval = \\\n",
    "    y_rule[train_mask, :cmb_per_class], y_rule[:, -500:], y_rule[:, -50:]\n",
    "y_rule_train = einops.rearrange(y_rule_train, 'class B -> (class B)', )\n",
    "y_rule_val = einops.rearrange(y_rule_val, 'class B -> (class B)', )\n",
    "y_rule_val_eval = einops.rearrange(y_rule_val_eval, 'class B -> (class B)', )\n",
    "# combine the first 2 axes into 1\n",
    "attr_seq_tsr_train = einops.rearrange(attr_seq_tsr_train, 'class B (R p h w) attr -> (class B) (R p h w) attr', R=3, p=3, h=3, w=3)\n",
    "attr_seq_tsr_val = einops.rearrange(attr_seq_tsr_val, 'class B (R p h w) attr -> (class B) (R p h w) attr', R=3, p=3, h=3, w=3)\n",
    "attr_seq_tsr_val_eval = einops.rearrange(attr_seq_tsr_val_eval, 'class B (R p h w) attr -> (class B) (R p h w) attr', R=3, p=3, h=3, w=3)\n",
    "print(attr_seq_tsr_train.shape, attr_seq_tsr_val.shape, attr_seq_tsr_val_eval.shape)\n",
    "del attr_seq_tsr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del attr_seq_tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIdxBERTModel(\n",
       "  (sep_word_embed): SepWordEmbed(\n",
       "    (embedding1): Embedding(8, 128)\n",
       "    (embedding2): Embedding(11, 128)\n",
       "    (embedding3): Embedding(11, 128)\n",
       "  )\n",
       "  (multi_lmhead): SepLMhead(\n",
       "    (lmhead1): Linear(in_features=128, out_features=8, bias=True)\n",
       "    (lmhead2): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (lmhead3): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(27, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(83, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (context_embed): Embedding(1, 384)\n",
       "  (classifier): Linear(in_features=384, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import trange\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(attr_seq_tsr_train, y_rule_train)\n",
    "val_dataset = TensorDataset(attr_seq_tsr_val, y_rule_val)\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "bert_raven = MultiIdxBERTModel(attribute_dims=(7,10,10), vocab_size=27, max_length=83, \n",
    "                                n_class=40, n_embd=384, is_sep_embed=True, n_layer=6, n_head=6)\n",
    "# train loop\n",
    "lr = 1e-4 #2e-5\n",
    "num_warmup_steps = 1000\n",
    "epoch_total = 10\n",
    "eval_every_step = 500\n",
    "total_steps = len(data_loader) * epoch_total\n",
    "# bug fix @2024-08-18, before which, the num_training_steps is not the total_steps, so wrong scheduler \n",
    "# num_training_steps = len(data_loader) * epoch_total\n",
    "optimizer = AdamW(bert_raven.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
    "bert_raven.train().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20cc9160331491ea361667193f4ee34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Validation loss: 3.710217418549936, accuracy: 0.0283\n",
      "Step 249 Validation loss: 3.572138068042224, accuracy: 0.0682\n",
      "Step 499 Validation loss: 3.59108993071544, accuracy: 0.08995\n",
      "Step 749 Validation loss: 3.518622908411147, accuracy: 0.11245\n",
      "Step 999 Validation loss: 3.520975873440127, accuracy: 0.12895\n",
      "Step 1249 Validation loss: 3.4385248603700083, accuracy: 0.1527\n",
      "Step 1499 Validation loss: 3.3835425965393644, accuracy: 0.16985\n",
      "Step 1749 Validation loss: 3.3505380010303063, accuracy: 0.1835\n",
      "Step 1999 Validation loss: 3.2733103814004343, accuracy: 0.20335\n",
      "Step 2249 Validation loss: 3.284302406861812, accuracy: 0.21135\n",
      "Step 2499 Validation loss: 3.175745446847964, accuracy: 0.2245\n",
      "Step 2749 Validation loss: 3.1793598615670504, accuracy: 0.2381\n",
      "Step 2999 Validation loss: 3.089216758933248, accuracy: 0.24835\n",
      "Step 3249 Validation loss: 3.071441326714769, accuracy: 0.2623\n",
      "Step 3499 Validation loss: 2.990386594134041, accuracy: 0.27275\n",
      "Step 3749 Validation loss: 2.991743972029867, accuracy: 0.28375\n",
      "Step 3999 Validation loss: 2.9408808418467074, accuracy: 0.2975\n",
      "Step 4249 Validation loss: 2.9554058195480817, accuracy: 0.2942\n",
      "Step 4499 Validation loss: 2.860357742237894, accuracy: 0.32245\n",
      "Step 4749 Validation loss: 2.8318672138678878, accuracy: 0.32245\n",
      "Step 4999 Validation loss: 2.824178544875187, accuracy: 0.3402\n",
      "Step 5249 Validation loss: 2.848322373685203, accuracy: 0.345\n",
      "Step 5499 Validation loss: 2.8378004337413403, accuracy: 0.3488\n",
      "Step 5749 Validation loss: 2.8245952443420133, accuracy: 0.3568\n",
      "Step 5999 Validation loss: 2.8219153248245203, accuracy: 0.35355\n",
      "Step 6249 Validation loss: 2.826251824068118, accuracy: 0.3676\n",
      "Step 6499 Validation loss: 2.769281599293404, accuracy: 0.35835\n",
      "Step 6749 Validation loss: 2.712199214704429, accuracy: 0.37245\n",
      "Step 6999 Validation loss: 2.6989535264718003, accuracy: 0.378\n",
      "Step 7249 Validation loss: 2.663881112173011, accuracy: 0.3796\n",
      "Step 7499 Validation loss: 2.629009882860546, accuracy: 0.393\n",
      "Step 7749 Validation loss: 2.6652541336473785, accuracy: 0.39665\n",
      "Step 7999 Validation loss: 2.6250278371138664, accuracy: 0.38715\n",
      "Step 8249 Validation loss: 2.6042460663173395, accuracy: 0.39475\n",
      "Step 8499 Validation loss: 2.6754947188487157, accuracy: 0.3907\n",
      "Step 8749 Validation loss: 2.670536903546581, accuracy: 0.38495\n",
      "Step 8999 Validation loss: 2.6602882053467294, accuracy: 0.39635\n",
      "Step 9249 Validation loss: 2.6048681495970563, accuracy: 0.41305\n",
      "Step 9499 Validation loss: 2.5832307263029906, accuracy: 0.39455\n",
      "Step 9749 Validation loss: 2.6345573592035074, accuracy: 0.40275\n",
      "Step 9999 Validation loss: 2.679421682618087, accuracy: 0.4011\n",
      "Step 10249 Validation loss: 2.5897957296405414, accuracy: 0.4129\n",
      "Step 10499 Validation loss: 2.627213160684214, accuracy: 0.4174\n",
      "Step 10749 Validation loss: 2.6290645943011475, accuracy: 0.4247\n",
      "Step 10999 Validation loss: 2.6177544831475124, accuracy: 0.4209\n",
      "Step 11249 Validation loss: 2.6394999360406324, accuracy: 0.4252\n",
      "Step 11499 Validation loss: 2.582710670330856, accuracy: 0.4396\n",
      "Step 11749 Validation loss: 2.556019877001077, accuracy: 0.46375\n",
      "Step 11999 Validation loss: 2.4545841083119186, accuracy: 0.47825\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, ys)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/transformers/optimization.py:647\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m    646\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m--> 647\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    650\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = trange(total_steps)\n",
    "data_iter = iter(data_loader)\n",
    "for step in pbar:\n",
    "    try:\n",
    "        inputs, ys = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(data_loader)\n",
    "        inputs, ys = next(data_iter)\n",
    "    inputs = inputs.cuda()\n",
    "    ys = ys.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    logits, outputs = bert_raven(inputs, y=ys)\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    pbar.set_postfix(loss=loss.item())\n",
    "    # evaluate test set\n",
    "    if (step + 1) % eval_every_step == 0 or step == total_steps - 1 or step == 0:\n",
    "        bert_raven.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            acc_cnt = 0\n",
    "            for inputs, ys in val_loader:\n",
    "                inputs = inputs.cuda()\n",
    "                ys = ys.cuda()\n",
    "                logits, outputs = bert_raven(inputs, y=ys)\n",
    "                loss = F.cross_entropy(logits, ys)\n",
    "                val_loss += loss.item()\n",
    "                acc_cnt += (logits.argmax(dim=-1) == ys).float().sum().item()\n",
    "            acc_ratio = acc_cnt / len(val_loader.dataset)\n",
    "            loss_avg = val_loss / len(val_loader)\n",
    "            print(f\"Step {step} Validation loss: {loss_avg}, accuracy: {acc_ratio}\")\n",
    "        bert_raven.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the custom configuration\n",
    "model = BertForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(968, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(82, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=384, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class CustomBERTModel(nn.Module):\n",
    "#     def __init__(self, config):\n",
    "#         super(CustomBERTModel, self).__init__()\n",
    "#         self.bert = BertForSequenceClassification(config)\n",
    "#         # Add additional layers if needed\n",
    "#         self.additional_layer = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "#         outputs = self.bert(\n",
    "#             input_ids, \n",
    "#             attention_mask=attention_mask, \n",
    "#             token_type_ids=token_type_ids, \n",
    "#             labels=labels,\n",
    "#             return_dict=False\n",
    "#         )\n",
    "#         pooled_output = outputs[1]\n",
    "#         # Apply additional layers\n",
    "#         x = self.additional_layer(pooled_output)\n",
    "#         x = self.relu(x)\n",
    "#         logits = self.bert.classifier(x)\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             loss = nn.CrossEntropyLoss()(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
    "#         return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# # Instantiate the custom model\n",
    "# custom_model = CustomBERTModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "\n",
    "# Create a dataset and dataloader\n",
    "dataset = TensorDataset(\n",
    "    encoded_inputs['input_ids'], \n",
    "    encoded_inputs['attention_mask'], \n",
    "    labels\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):  # Number of epochs\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1} completed with loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
