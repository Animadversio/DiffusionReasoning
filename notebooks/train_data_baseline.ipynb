{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\t loss_curve.png  samples_inferred_rule_consistency.npz\n",
      "dataset_idx.pkl  samples\t std.log\n"
     ]
    }
   ],
   "source": [
    "!ls /n/holylabs/LABS/kempner_fellows/Users/binxuwang/DL_Projects/mini_edm/exps/BigBlnrX3_RAVEN10_abstract_20240305-2338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from os.path import join\n",
    "\n",
    "expdir = r'/n/holylabs/LABS/kempner_fellows/Users/binxuwang/DL_Projects/mini_edm/exps/BigBlnrX3_RAVEN10_abstract_20240305-2338'\n",
    "# dataset_idx = np.load(join(expdir, 'dataset_idx.pkl'))\n",
    "dataset_idx = pkl.load(open(join(expdir, 'dataset_idx.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/Github/DiffusionReasoning/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import partial\n",
    "import os \n",
    "from os.path import join\n",
    "from tqdm import trange, tqdm\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import re\n",
    "import pandas as pd\n",
    "import einops\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as pltb\n",
    "import sys\n",
    "sys.path.append('/n/home12/binxuwang/Github/DiffusionReasoning')\n",
    "from edm_utils import parse_train_logfile\n",
    "from dataset_utils import onehot2attr_tsr\n",
    "from stats_plot_utils import estimate_CI, shaded_error\n",
    "from rule_utils import get_rule_list, get_obj_list, get_rule_img, check_consistent\n",
    "\n",
    "def batch_load_samples_infer_rules(samples_dir, epoch_list, encoding=\"onehot\", fmt=\"tensor_%s.pt\"):\n",
    "    rules_all = []\n",
    "    for epoch in tqdm(epoch_list): \n",
    "        if not os.path.exists(join(samples_dir, fmt % epoch)):\n",
    "            print(epoch, \"not exist\")\n",
    "            break\n",
    "        samples = torch.load(join(samples_dir, fmt % epoch)) # (batch, 27, 9, 9)\n",
    "        if encoding == \"onehot\":\n",
    "            attr_tsr_list = onehot2attr_tsr(samples, threshold=0.5)\n",
    "        elif encoding == \"digit\":\n",
    "            attr_tsr_list = torch.round(samples).int() # (batch, 3, 9, 9)\n",
    "        else:\n",
    "            raise ValueError(\"encoding should be onehot or digit\")\n",
    "        rules_list = []\n",
    "        for i, attr_tsr in enumerate(attr_tsr_list): \n",
    "            rule_img = get_rule_img(attr_tsr) # (3, 9, 9) -> (3,)\n",
    "            rules_list.append(rule_img)\n",
    "        rules_all.append(rules_list)\n",
    "    rules_all = np.asarray(rules_all) # (201, 25, 3)\n",
    "    epoch_list = epoch_list[:len(rules_all)]\n",
    "    \n",
    "    consistent_mat = []\n",
    "    for epoch_i in trange(len(rules_all)): \n",
    "        consistent_all = [check_consistent(rules) \n",
    "                          for rules in rules_all[epoch_i]]\n",
    "        consistent_mat.append(consistent_all)\n",
    "    consistent_mat = np.asarray(consistent_mat)\n",
    "    return rules_all, consistent_mat, epoch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.20it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_dir= \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiT/results/008-RAVEN10_abstract-DiT_S_3/samples/\"\n",
    "\n",
    "rules_all, consistent_mat, epoch_list = batch_load_samples_infer_rules(sample_dir, epoch_list=[682000,], encoding=\"digit\", fmt=\"%07d.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683000 not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_dir= \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiT/results/008-RAVEN10_abstract-DiT_S_3/samples/\"\n",
    "\n",
    "rules_all, consistent_mat, epoch_list = batch_load_samples_infer_rules(sample_dir, epoch_list=[683000,], encoding=\"digit\", fmt=\"%07d.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000-RAVEN10_abstract-DiT_S_1',\n",
       " '001-RAVEN10_abstract-DiT_B_1',\n",
       " '002-RAVEN10_abstract-DiT_S_1',\n",
       " '003-RAVEN10_abstract_onehot-DiT_S_1',\n",
       " '004-RAVEN10_abstract-DiT_S_1',\n",
       " '005-RAVEN10_abstract_onehot-DiT_S_1',\n",
       " '006-RAVEN10_abstract-DiT_S_1',\n",
       " '007-RAVEN10_abstract_onehot-DiT_S_1',\n",
       " '008-RAVEN10_abstract-DiT_S_3',\n",
       " '009-RAVEN10_abstract-DiT_S_1',\n",
       " '010-RAVEN10_abstract-DiT_L_1',\n",
       " '011-RAVEN10_abstract-DiT_B_1',\n",
       " '012-RAVEN10_abstract-DiT_B_3',\n",
       " '013-RAVEN10_abstract-DiT_S_3',\n",
       " '014-RAVEN10_abstract_onehot-DiT_S_3',\n",
       " '015-RAVEN10_abstract_onehot-DiT_B_3',\n",
       " '016-RAVEN10_abstract-DiT_S_3',\n",
       " '017-RAVEN10_abstract_onehot-DiT_S_1',\n",
       " '018-RAVEN10_abstract-DiT_S_1',\n",
       " '019-RAVEN10_abstract_onehot-DiT_S_1',\n",
       " '020-RAVEN10_abstract-DiT_S_1',\n",
       " '021-RAVEN10_abstract-uncond-DiT_S_3_20240308-1349',\n",
       " '022-RAVEN10_abstract_onehot-uncond-DiT_B_3_20240308-1349',\n",
       " '023-RAVEN10_abstract_onehot-uncond-DiT_S_3_20240308-1349',\n",
       " '024-RAVEN10_abstract-uncond-DiT_B_3_20240308-1349',\n",
       " '025-RAVEN10_abstract_onehot-cond-DiT_S_3_20240308-1349',\n",
       " '026-RAVEN10_abstract-cond-DiT_S_3_20240308-1349',\n",
       " '027-RAVEN10_abstract-uncond-DiT_S_1_20240308-1349',\n",
       " '028-RAVEN10_abstract_onehot-uncond-DiT_S_1_20240308-1349',\n",
       " '029-RAVEN10_abstract-cond-DiT_S_1_20240308-1349',\n",
       " '030-RAVEN10_abstract_onehot-cond-DiT_S_1_20240308-1350']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiT/results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([[0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['row_ids', 'y'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_idx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1088, 6569, 2527],\n",
       "        [4894, 4650, 5613],\n",
       "        [9876, 6563, 4420],\n",
       "        ...,\n",
       "        [3171,  578, 6258],\n",
       "        [6818, 5413, 6417],\n",
       "        [5928, 4555,   35]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_idx['row_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 34, 34, 34], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_idx['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import einops\n",
    "import einops\n",
    "from tqdm import trange, tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def _sample_panels(train_row_img, cmb_per_class=3333):\n",
    "    \"\"\"\n",
    "    train_row_img: [35, 10000, 3, 3, 9] \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    row_ids = []\n",
    "    n_classes = train_row_img.shape[0]\n",
    "    n_samples = train_row_img.shape[1]\n",
    "    for iclass in trange(n_classes):\n",
    "        tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "        X_class = []\n",
    "        row_ids_cls = []\n",
    "        while True:\n",
    "            try:\n",
    "                batch = next(iter(tuple_loader))\n",
    "                rows = train_row_img[iclass][batch]\n",
    "                mtg = torch.cat(tuple(rows), dim=1)\n",
    "                X_class.append(mtg)\n",
    "                row_ids_cls.append(batch)\n",
    "                if len(X_class) == cmb_per_class:\n",
    "                    break\n",
    "            except StopIteration:\n",
    "                tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "\n",
    "        y_class = torch.tensor([iclass]*len(X_class), dtype=torch.int)\n",
    "        X_class = torch.stack(X_class)\n",
    "        row_ids_cls = torch.stack(row_ids_cls)\n",
    "        y.append(y_class)\n",
    "        X.append(X_class)\n",
    "        row_ids.append(row_ids_cls)\n",
    "    X = torch.cat(X, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    row_ids = torch.cat(row_ids, dim=0)\n",
    "    return X, y, row_ids\n",
    "\n",
    "\n",
    "def reconstruct_imgs(X, row_ids, ys):\n",
    "    \"\"\" \"\"\"\n",
    "    img_all = []\n",
    "    for iclass, batch_id in zip(ys, row_ids):\n",
    "        rows = X[iclass][batch_id]\n",
    "        mtg = torch.cat(tuple(rows), dim=1)\n",
    "        img_all.append(mtg)\n",
    "    img_all = torch.stack(img_all)\n",
    "    return img_all\n",
    "\n",
    "\n",
    "class dataset_PGM_abstract(Dataset): \n",
    "    def __init__(self, cmb_per_class=3333, train_attrs=None, device=\"cpu\", onehot=False): \n",
    "        \"\"\"attr_list: [num_samples, 3, 9, 3]\"\"\"\n",
    "        if train_attrs is None:\n",
    "            train_attrs = torch.load('/n/home12/binxuwang/Github/DiffusionReasoning/train_inputs.pt') # [35, 10000, 3, 9, 3]\n",
    "        n_classes = train_attrs.shape[0] # 35\n",
    "        n_samples = train_attrs.shape[1] # 10k\n",
    "        self.labels = torch.arange(0, n_classes).unsqueeze(1).expand(n_classes, n_samples)\n",
    "        train_attrs = train_attrs.to(int)\n",
    "        self.train_row_img = einops.rearrange(train_attrs, 'c s pnl (H W) attr -> c s attr H (pnl W)', H=3, W=3, attr=3, pnl=3)\n",
    "        self.X, self.y, self.row_ids = _sample_panels(self.train_row_img, cmb_per_class)\n",
    "        self.X = self.X.to(device) # [35 * cmb_per_class, 3, 9, 9]\n",
    "        if onehot is True:\n",
    "            O1 = torch.cat([torch.eye(7, 7, dtype=int), torch.zeros(1, 7, dtype=int)], dim=0)\n",
    "            O2 = torch.cat([torch.eye(10, 10, dtype=int), torch.zeros(1, 10, dtype=int)], dim=0)\n",
    "            O3 = torch.cat([torch.eye(10, 10, dtype=int), torch.zeros(1, 10, dtype=int)], dim=0)\n",
    "            X_onehot = torch.cat([O1[self.X[:, 0], :], O2[self.X[:, 1], :], O3[self.X[:, 2], :], ], dim=-1)\n",
    "            print(X_onehot.shape)\n",
    "            self.X = einops.rearrange(X_onehot, 'b h w C -> b C h w')\n",
    "            print(self.X.shape)\n",
    "            self.Xmean = torch.tensor([0.5, ]).view(1, 1, 1, 1)\n",
    "            self.Xstd = torch.tensor([0.5, ]).view(1, 1, 1, 1)\n",
    "            self.X = (self.X.float() - self.Xmean) / self.Xstd\n",
    "        else:\n",
    "            self.Xmean = torch.tensor([1.5, 2.5, 2.5]).view(1, 3, 1, 1).to(device)\n",
    "            self.Xstd = torch.tensor([2.5, 3.5, 3.5]).view(1, 3, 1, 1).to(device)\n",
    "            self.X = (self.X - self.Xmean) / self.Xstd\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"attr: [3, 9, 3]\"\"\"\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def dict(self):\n",
    "        return {'row_ids': self.row_ids, 'y': self.y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 10000, 3, 3, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import einops\n",
    "train_attrs = torch.load('/n/home12/binxuwang/Github/DiffusionReasoning/train_inputs.pt')\n",
    "train_row_img = einops.rearrange(train_attrs, 'c s pnl (H W) attr -> c s attr H (pnl W)', H=3, W=3, attr=3, pnl=3)\n",
    "train_row_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = r'/n/holylabs/LABS/kempner_fellows/Users/binxuwang/DL_Projects/mini_edm/exps/BigBlnrX3_RAVEN10_abstract_20240305-2338'\n",
    "# dataset_idx = np.load(join(expdir, 'dataset_idx.pkl'))\n",
    "dataset_idx = pkl.load(open(join(expdir, 'dataset_idx.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_imgs(X, row_ids, ys):\n",
    "    \"\"\" \"\"\"\n",
    "    img_all = []\n",
    "    for iclass, batch_id in zip(ys, row_ids):\n",
    "        rows = X[iclass][batch_id]\n",
    "        mtg = torch.cat(tuple(rows), dim=1)\n",
    "        img_all.append(mtg)\n",
    "    img_all = torch.stack(img_all)\n",
    "    return img_all\n",
    "\n",
    "X_all = reconstruct_imgs(train_row_img, dataset_idx['row_ids'], dataset_idx['y']).to(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([116655, 3, 9, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_summary_table(rules_all, consistent_mat, epoch_list):\n",
    "    rule_summary_df = []\n",
    "    assert rules_all.shape[0] == consistent_mat.shape[0] == len(epoch_list)\n",
    "    for rule_ep, consistent_ep, epoch in zip(rules_all, consistent_mat, epoch_list): \n",
    "        rule_valid = (rule_ep != -1).mean()\n",
    "        rule_valid_cnt = (rule_ep != -1).sum()\n",
    "        rule_consistent_1 = (consistent_ep == 1).mean()\n",
    "        rule_consistent_1_cnt = (consistent_ep == 1).sum()\n",
    "        rule_consistent_2 = (consistent_ep == 2).mean()\n",
    "        rule_consistent_2_cnt = (consistent_ep == 2).sum()\n",
    "        rule_consistent_3 = (consistent_ep == 3).mean()\n",
    "        rule_consistent_3_cnt = (consistent_ep == 3).sum()\n",
    "        rule_summary_df.append({\"epoch\": epoch,\n",
    "                                \"valid\": rule_valid.mean(),\n",
    "                                \"valid_cnt\": rule_valid_cnt,\n",
    "                                \"cst_1\": rule_consistent_1.mean(),\n",
    "                                \"cst_1_cnt\": rule_consistent_1_cnt,\n",
    "                                \"cst_2\": rule_consistent_2.mean(),\n",
    "                                \"cst_2_cnt\": rule_consistent_2_cnt,\n",
    "                                \"cst_3\": rule_consistent_3.mean(),\n",
    "                                \"cst_3_cnt\": rule_consistent_3_cnt,\n",
    "                                })\n",
    "    rule_summary_df = pd.DataFrame(rule_summary_df)\n",
    "    print(rule_summary_df.tail())\n",
    "    return rule_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/n/home12/binxuwang/Github/DiffusionReasoning')\n",
    "from edm_utils import parse_train_logfile\n",
    "from dataset_utils import onehot2attr_tsr\n",
    "from stats_plot_utils import estimate_CI, shaded_error\n",
    "from rule_utils import get_rule_list, get_obj_list, get_rule_img, check_consistent\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "def batch_infer_rule(X, threshold=0.5, encoding=\"onehot\"):\n",
    "    \"\"\" \n",
    "    X: [batch, 3, 9, 9]\n",
    "    \"\"\"\n",
    "    rules_list = []\n",
    "    for attr_tsr in trange(X): \n",
    "        rule_img = get_rule_img(attr_tsr) # (3, 9, 9) -> (3,)\n",
    "        rules_list.append(rule_img)\n",
    "    rules_all = np.asarray(rules_list)\n",
    "    # consistent_mat = []\n",
    "    # for epoch_i in trange(len(rules_all)): \n",
    "    consistent_all = [check_consistent(rules) \n",
    "                        for rules in rules_all]\n",
    "        # consistent_mat.append(consistent_all)\n",
    "    consistent_mat = np.asarray(consistent_all)\n",
    "    return rules_all, consistent_mat\n",
    "\n",
    "rules_all_train, consistent_mat_train = batch_infer_rule(X_all, threshold=0.5, encoding=\"digit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch     valid  valid_cnt     cst_1  cst_1_cnt     cst_2  cst_2_cnt  \\\n",
      "0  None  0.644073     225403  0.571411      66658  0.077356       9024   \n",
      "\n",
      "      cst_3  cst_3_cnt  \n",
      "0  0.059346       6923  \n"
     ]
    }
   ],
   "source": [
    "rule_summary_df = rule_summary_table(rules_all_train[None,:], consistent_mat_train[None,:], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(join(expdir, 'train_set_rule_summary.npz'), rules_all_train=rules_all_train, consistent_mat_train=consistent_mat_train)\n",
    "rule_summary_df.to_csv(join(expdir, 'train_set_rule_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
