{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import json\n",
    "import torch\n",
    "import torch as th\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "plt.rcParams['figure.edgecolor'] = (1, 1, 1, 0)\n",
    "plt.rcParams['figure.facecolor'] = (1, 1, 1, 0)\n",
    "# vector graphics type\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "import circuit_toolkit\n",
    "# print(circuit_toolkit.__file__)\n",
    "from circuit_toolkit.layer_hook_utils import print_specific_layer, get_module_name_shapes, featureFetcher_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/mini_edm\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/SiT\")\n",
    "# sys.path.append(\"/n/home12/binxuwang/Github/DiT\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionReasoning\")\n",
    "# from train_edm import create_model, edm_sampler, EDM\n",
    "# from edm_utils import edm_sampler_inpaint, create_edm, get_default_config\n",
    "# from rule_utils import get_rule_img, get_obj_list, get_rule_list, check_consistent\n",
    "from dataset_utils import train_data2attr_tsr,load_raw_data,load_PGM_abstract\n",
    "from rule_new_utils import check_r3_r2_batch, infer_rule_from_sample_batch, compute_rule_statistics\n",
    "from models import SiT_models, SiT\n",
    "from transport import create_transport, Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in SiT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiT_configs = {\n",
    "    \"SiT_XL_1\": {\"depth\": 28, \"hidden_size\": 1152, \"patch_size\": 1, \"num_heads\": 16},\n",
    "    \"SiT_XL_3\": {\"depth\": 28, \"hidden_size\": 1152, \"patch_size\": 3, \"num_heads\": 16},\n",
    "    \"SiT_L_1\": {\"depth\": 24, \"hidden_size\": 1024, \"patch_size\": 1, \"num_heads\": 16},\n",
    "    \"SiT_L_3\": {\"depth\": 24, \"hidden_size\": 1024, \"patch_size\": 3, \"num_heads\": 16},\n",
    "    \"SiT_B_1\": {\"depth\": 12, \"hidden_size\": 768, \"patch_size\": 1, \"num_heads\": 12},\n",
    "    \"SiT_B_3\": {\"depth\": 12, \"hidden_size\": 768, \"patch_size\": 3, \"num_heads\": 12},\n",
    "    \"SiT_S_1\": {\"depth\": 12, \"hidden_size\": 384, \"patch_size\": 1, \"num_heads\": 6},\n",
    "    \"SiT_S_3\": {\"depth\": 12, \"hidden_size\": 384, \"patch_size\": 3, \"num_heads\": 6},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dropout_prob = 1.0\n",
    "num_classes = 0\n",
    "model_cfg = SiT_configs[\"SiT_S_1\"]\n",
    "model_SiT = SiT(\n",
    "        input_size=9,\n",
    "        in_channels=3,\n",
    "        num_classes=num_classes,\n",
    "        class_dropout_prob=class_dropout_prob,\n",
    "        learn_sigma=True,\n",
    "        **model_cfg,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004-SiT_S_1-stream0_16M_pilot-Linear-velocity-None\n",
      "005-SiT_B_1-stream0_16M_pilot-Linear-velocity-None\n",
      "006-SiT_S_1-stream0_016M_all-Linear-velocity-None\n",
      "007-SiT_S_1-stream0_16M_all-Linear-velocity-None\n",
      "008-SiT_S_1-stream1_6M_all-Linear-velocity-None\n",
      "009-SiT_S_1-stream16M_all-Linear-velocity-None\n",
      "010-SiT_S_1-stream16M_all-Linear-velocity-None\n",
      "011-SiT_B_1-stream0_16M_all-Linear-velocity-None\n",
      "011-SiT_S_1-stream16M_heldout0-Linear-velocity-None\n",
      "012-SiT_B_1-stream0_016M_all-Linear-velocity-None\n",
      "012-SiT_S_1-stream1_6M_heldout0-Linear-velocity-None\n",
      "013-SiT_B_1-stream16M_all-Linear-velocity-None\n",
      "013-SiT_S_1-stream0_016M_heldout0-Linear-velocity-None\n",
      "014-SiT_B_1-stream1_6M_all-Linear-velocity-None\n",
      "014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None\n",
      "015-SiT_B_1-stream0_016M_heldout0-Linear-velocity-None\n",
      "016-SiT_B_1-stream16M_heldout0-Linear-velocity-None\n",
      "017-SiT_B_1-stream0_16M_heldout0-Linear-velocity-None\n",
      "018-SiT_B_1-stream1_6M_heldout0-Linear-velocity-None\n",
      "019-SiT_B_1-stream16M_all-Linear-velocity-None\n",
      "020-SiT_B_1-stream0_16M_all-Linear-velocity-None\n",
      "021-SiT_B_1-stream1_6M_all-Linear-velocity-None\n",
      "022-SiT_B_1-stream0_016M_all-Linear-velocity-None\n"
     ]
    }
   ],
   "source": [
    "!ls /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/SiT/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exproot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/SiT/results\"\n",
    "expname = r\"014-SiT_S_1-stream0_16M_heldout0-Linear-velocity-None\"\n",
    "expdir = join(exproot, expname)\n",
    "ckptdir = join(expdir, \"checkpoints\")\n",
    "ckpt_path = join(ckptdir, \"1000000.pt\")\n",
    "state_dict = th.load(ckpt_path, )\n",
    "model_SiT.load_state_dict(state_dict['ema']) # \"model\"\n",
    "model_SiT.to(device).eval();\n",
    "config = edict(json.load(open(join(expdir, \"args.json\"), \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract RAVEN dataset\n",
    "dataset_Xmean = th.tensor([1.5, 2.5, 2.5]).view(1, 3, 1, 1).to(\"cuda\")\n",
    "dataset_Xstd = th.tensor([2.5, 3.5, 3.5]).view(1, 3, 1, 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = create_transport(\n",
    "    config.path_type, #\"Linear\",\n",
    "    config.prediction, #\"velocity\", \n",
    "    config.loss_weight, #None, \n",
    "    config.train_eps, #None,\n",
    "    config.sample_eps, #None,\n",
    ")  # default: velocity; \n",
    "transport_sampler = Sampler(transport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run and rule inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1447/2048 (0.71), C3 + C2: 1720/2048 (0.84), AnyValid: 5196/6144 (0.85)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "zs = th.randn(batch_size, 3, 9, 9).to(device)\n",
    "ys = torch.zeros((batch_size,), device=device, dtype=torch.int)    \n",
    "sample_model_kwargs = dict(y=ys)\n",
    "model_fn = model_SiT.forward\n",
    "sample_fn = transport_sampler.sample_ode() # default to ode sampling\n",
    "with th.no_grad():\n",
    "    samples = sample_fn(zs, model_fn, **sample_model_kwargs)[-1] # takes 75 sec, pretty slow...\n",
    "samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_id_dict = {\n",
    "    'train_inputs_new.pt'       : [1, 16, 20, 34, 37], \n",
    "    'train_inputs_new_split0.pt': [1, 16, 20, 34, 37], \n",
    "    'train_inputs_new_split1.pt': [8, 12, 24, 36, 39],\n",
    "    'train_inputs_new_split2.pt': [5, 17, 21, 33, 38],\n",
    "    'train_inputs_new_split3.pt': [3, 10, 29, 31, 37],\n",
    "    'train_inputs_new_split4.pt': [0, 14, 27, 35, 38],\n",
    "    'train_inputs_new_split5.pt': [4, 19, 26, 30, 39],\n",
    "    'train_inputs_new_split6.pt': [9, 13, 25, 32, 37],\n",
    "    'train_inputs_new_split7.pt': [2, 18, 23, 30, 38],\n",
    "    'train_inputs_new_split8.pt': [7, 15, 22, 34, 39],\n",
    "    'train_inputs_new_split9.pt': [6, 11, 28, 33, 37],\n",
    "}\n",
    "heldout_rules = heldout_id_dict[\"train_inputs_new.pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_fn = \"train_inputs_new.pt\"\n",
    "# train_attrs = torch.load(f'/n/home12/binxuwang/Github/DiffusionReasoning/{train_data_fn}')\n",
    "# train_attrs = train_attrs.to(int)\n",
    "train_attrs = np.load(\"/n/home12/binxuwang/Github/DiffusionReasoning/attr_all.npy\")\n",
    "train_attrs = th.from_numpy(train_attrs).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_row_img = einops.rearrange(train_attrs, 'c s pnl (H W) att -> c s att H (pnl W)', H=3, W=3, att=3, pnl=3)\n",
    "train_sample_img = einops.rearrange(train_row_img, 'c (S R) att H W -> c S att (R H) W', R=3,att=3, H=3, W=9)\n",
    "labels_tsr = torch.arange(len(train_sample_img)).to(int).view(-1,1).repeat(1, train_sample_img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5,  5,  5,  5,  5, -1,  5, -1,  5],\n",
      "         [ 5,  5,  5, -1, -1,  5,  5,  5,  5],\n",
      "         [ 5,  5,  5,  5, -1, -1, -1,  5,  5],\n",
      "         [-1,  6,  6,  6, -1, -1,  6,  6,  6],\n",
      "         [-1, -1, -1, -1,  6,  6,  6,  6,  6],\n",
      "         [-1,  6,  6,  6,  6, -1, -1,  6,  6],\n",
      "         [ 2, -1,  2,  2,  2,  2, -1, -1,  2],\n",
      "         [ 2,  2, -1,  2, -1, -1, -1, -1, -1],\n",
      "         [ 2,  2,  2, -1,  2,  2,  2,  2, -1]],\n",
      "\n",
      "        [[ 4,  4,  4,  2,  2, -1,  9, -1,  9],\n",
      "         [ 4,  4,  4, -1, -1,  2,  9,  9,  9],\n",
      "         [ 4,  4,  4,  2, -1, -1, -1,  9,  9],\n",
      "         [-1,  5,  1,  5, -1, -1,  7,  1,  5],\n",
      "         [-1, -1, -1, -1,  0,  1,  7,  4,  0],\n",
      "         [-1,  3,  1,  8,  2, -1, -1,  7,  6],\n",
      "         [ 5, -1,  5,  3,  3,  3, -1, -1,  6],\n",
      "         [ 5,  5, -1,  3, -1, -1, -1, -1, -1],\n",
      "         [ 5,  5,  5, -1,  3,  3,  6,  6, -1]],\n",
      "\n",
      "        [[ 4,  8,  4,  5,  0, -1,  6, -1,  4],\n",
      "         [ 0,  5,  4, -1, -1,  1,  2,  5,  8],\n",
      "         [ 7,  3,  1,  2, -1, -1, -1,  8,  2],\n",
      "         [-1,  9,  9,  7, -1, -1,  3,  3,  3],\n",
      "         [-1, -1, -1, -1,  7,  7,  3,  3,  3],\n",
      "         [-1,  9,  9,  7,  7, -1, -1,  3,  3],\n",
      "         [ 7, -1,  7,  6,  6,  6, -1, -1,  4],\n",
      "         [ 7,  7, -1,  6, -1, -1, -1, -1, -1],\n",
      "         [ 7,  7,  7, -1,  6,  6,  4,  4, -1]]])\n"
     ]
    }
   ],
   "source": [
    "print(train_sample_img[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 3, 9, 9]) torch.Size([120000])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "X_train = train_sample_img[:, :3000]\n",
    "y_train = labels_tsr[:, :3000]\n",
    "X_test = train_sample_img[:, 3000:]\n",
    "y_test = labels_tsr[:, 3000:]\n",
    "X_train = X_train.reshape(-1, 3, 9, 9)\n",
    "y_train = y_train.reshape(-1)\n",
    "X_test = X_test.reshape(-1, 3, 9, 9)\n",
    "y_test = y_test.reshape(-1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils to train a linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "# Define the linear classifier model\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, train_loader, num_epochs, learning_rate, print_every=50,\n",
    "                eval_every=500, eval_func=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_record = []\n",
    "    test_record = []\n",
    "    for epoch in range(num_epochs):\n",
    "        acc_total = 0\n",
    "        cnt_total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc_cnt = (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            acc_total += acc_cnt\n",
    "            cnt_total += len(labels)\n",
    "        accuracy = acc_total / cnt_total\n",
    "        if (epoch + 1) % print_every == 0 or epoch == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        train_record.append((epoch, loss.item(), accuracy))\n",
    "        if ((epoch + 1) % eval_every == 0 or epoch == num_epochs - 1) and eval_func is not None:\n",
    "            test_acc, _ = eval_func(model)\n",
    "            test_record.append((epoch, test_acc))\n",
    "    train_record = pd.DataFrame(train_record, columns=[\"epoch\", \"loss\", \"accuracy\"])\n",
    "    test_record = pd.DataFrame(test_record, columns=[\"epoch\", \"accuracy\"])\n",
    "    return train_record, test_record\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    acc_total = 0\n",
    "    cnt_total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "        with th.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        pred_cls = outputs.argmax(dim=1)\n",
    "        acc_cnt = (pred_cls == labels).sum().item()\n",
    "        acc_total += acc_cnt\n",
    "        cnt_total += len(labels)\n",
    "    accuracy = acc_total / cnt_total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy, pred_cls\n",
    "\n",
    "\n",
    "def fit_SGD_linear_classifier(train_X, train_y, test_X=None, test_y=None, \n",
    "                              num_classes=40, \n",
    "                              batch_size=1024, num_epochs=100, \n",
    "                              learning_rate = 0.001, print_every=100, eval_every=500,):\n",
    "    # Define the linear classifier model\n",
    "    input_size = train_X.shape[1]\n",
    "    model = LinearClassifier(input_size, num_classes).to(\"cuda\")\n",
    "    if batch_size is None:\n",
    "        feat_loader = [(train_X.to(\"cuda\"), train_y.to(\"cuda\"))]\n",
    "    else:\n",
    "        feat_dataset = TensorDataset(train_X.to(\"cuda\"), train_y.to(\"cuda\")) # .to(\"cuda\")\n",
    "        feat_loader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True,\n",
    "                             drop_last=True) # pin_memory=True, num_workers=\n",
    "    \n",
    "    if test_X is not None and test_y is not None:\n",
    "        if batch_size is None:\n",
    "            test_feat_loader = [(test_X.to(\"cuda\"), test_y.to(\"cuda\"))]\n",
    "        else:\n",
    "            test_dataset = TensorDataset(test_X.to(\"cuda\"), test_y.to(\"cuda\")) # .to(\"cuda\")\n",
    "            test_feat_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Define the training loop\n",
    "    train_record, test_record = train_model(model, feat_loader, num_epochs, learning_rate, print_every=print_every, eval_every=eval_every,\n",
    "                eval_func=lambda model: test_model(model, test_feat_loader) if test_feat_loader is not None else None)\n",
    "    # Define the testing loop\n",
    "    test_acc, pred_cls = test_model(model, test_feat_loader)\n",
    "    results = edict()\n",
    "    results.train_record = train_record\n",
    "    results.test_record = test_record\n",
    "    results.test_acc = test_acc\n",
    "    results.pred_cls = pred_cls\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca_sgd_classifiers(\n",
    "    feature_col,\n",
    "    feature_col_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    PC_dim=1024,\n",
    "    noPCA=False,\n",
    "    num_classes=40,\n",
    "    batch_size=None,\n",
    "    num_epochs=5000,\n",
    "    print_every=250,\n",
    "    eval_every=1000,\n",
    "    learning_rate=0.005,\n",
    "    device='cuda'  # Specify 'cuda' or 'cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains SGD linear classifiers on PCA-transformed features for each layer.\n",
    "\n",
    "    Args:\n",
    "        feature_col (dict): Training features for each layer.\n",
    "        feature_col_test (dict): Test features for each layer.\n",
    "        y_train (torch.Tensor or np.ndarray): Training labels.\n",
    "        y_test (torch.Tensor or np.ndarray): Test labels.\n",
    "        PC_dim (int, optional): Number of principal components. Defaults to 1024.\n",
    "        noPCA (bool, optional): Whether to skip PCA. Defaults to False.\n",
    "        num_classes (int, optional): Number of target classes. Defaults to 40.\n",
    "        batch_size (int, optional): Batch size for SGD. Defaults to None.\n",
    "        num_epochs (int, optional): Number of training epochs. Defaults to 5000.\n",
    "        print_every (int, optional): Frequency of printing progress. Defaults to 250.\n",
    "        eval_every (int, optional): Frequency of evaluating on test set. Defaults to 1000.\n",
    "        learning_rate (float, optional): Learning rate for SGD. Defaults to 0.005.\n",
    "        device (str, optional): Device to use ('cuda' or 'cpu'). Defaults to 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        model_PCA_col (dict): Trained models for each layer.\n",
    "        PC_proj_col (dict): PCA projection parameters for each layer.\n",
    "        results_col (dict): Training and evaluation results for each layer.\n",
    "    \"\"\"\n",
    "    model_PCA_col = {}\n",
    "    PC_proj_col = {}\n",
    "    results_col = {}\n",
    "\n",
    "    for layerkey in feature_col.keys():\n",
    "        print(f\"Processing layer: {layerkey}\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reshape feature matrices\n",
    "        featmat = feature_col[layerkey].view(len(feature_col[layerkey]), -1)\n",
    "        featmat_test = feature_col_test[layerkey].view(len(feature_col_test[layerkey]), -1)\n",
    "\n",
    "        # Compute mean of training features\n",
    "        featmean = featmat.mean(dim=0)\n",
    "        t1 = time.time()\n",
    "\n",
    "        if noPCA:\n",
    "            # Center and normalize features without PCA\n",
    "            feat_PCA = (featmat - featmean[None, :]).to(device)\n",
    "            feat_PCA_std = feat_PCA.std(dim=0)\n",
    "            feat_PCA = feat_PCA / feat_PCA_std[None, :]\n",
    "            feat_PCA_test = (featmat_test - featmean[None, :]).to(device)\n",
    "            feat_PCA_test = feat_PCA_test / feat_PCA_std[None, :]\n",
    "        else:\n",
    "            # Perform PCA\n",
    "            centered_feat = (featmat - featmean[None, :]).to(device)\n",
    "            U, S, V = torch.pca_lowrank(centered_feat, q=PC_dim, center=False, niter=3)\n",
    "            print(f\"PCA components for layer {layerkey}: U shape {U.shape}, S shape {S.shape}, V shape {V.shape}\")\n",
    "            # Clean up unnecessary variables\n",
    "            del U, S\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Project training and test features\n",
    "            feat_PCA = centered_feat @ V\n",
    "            feat_PCA_std = feat_PCA.std(dim=0)\n",
    "            feat_PCA = feat_PCA / feat_PCA_std[None, :]\n",
    "            feat_PCA_test = (featmat_test - featmean[None, :]).to(device) @ V\n",
    "            feat_PCA_test = feat_PCA_test / feat_PCA_std[None, :]\n",
    "            torch.cuda.empty_cache()\n",
    "            V = V.cpu()\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        # Train the SGD linear classifier\n",
    "        model, results_dict = fit_SGD_linear_classifier(\n",
    "            feat_PCA, y_train, feat_PCA_test, y_test,\n",
    "            num_classes=num_classes,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            print_every=print_every,\n",
    "            eval_every=eval_every,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "\n",
    "        t3 = time.time()\n",
    "\n",
    "        print(f\"Layer {layerkey} - PCA time: {t1 - t0:.2f}s, \"\n",
    "              f\"PCA transform time: {t2 - t1:.2f}s, \"\n",
    "              f\"Training time: {t3 - t2:.2f}s\")\n",
    "\n",
    "        # Store the trained model and PCA projection parameters\n",
    "        model_PCA_col[layerkey] = model\n",
    "        PC_proj_col[layerkey] = {\n",
    "            'V': V.cpu() if not noPCA else None,  # PCA components\n",
    "            'mean': featmean.cpu(),\n",
    "            'std': feat_PCA_std.cpu()\n",
    "        }\n",
    "        results_col[layerkey] = results_dict\n",
    "        del feat_PCA, feat_PCA_test\n",
    "\n",
    "    return model_PCA_col, PC_proj_col, results_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which part of the model has rule representation?\n",
    "See if any other part of the model has the rule representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiT(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=384, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(1, 384)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x SiTBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=384, out_features=2304, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((384,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=384, out_features=6, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=384, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "      Layer Id                                           inshape                    outshape                            Type   Module Path                      \n",
      "======================================================================================================================================================\n",
      "        0                                             (2, 3, 9, 9)                (2, 3, 9, 9)                         [Input]   Image                            \n",
      "        1                                           [(2, 3, 9, 9)]              (2, 384, 9, 9)                        [Conv2d]   .x_embedder.proj                 \n",
      "        2                                           [(2, 81, 384)]                (2, 81, 384)                      [Identity]   .x_embedder.norm                 \n",
      "        3                                           [(2, 3, 9, 9)]                (2, 81, 384)                    [PatchEmbed]   .x_embedder                      \n",
      "        4                                               [(2, 256)]                    (2, 384)                    [Sequential]   .t_embedder.mlp                  \n",
      "        5                                                   [(2,)]                    (2, 384)              [TimestepEmbedder]   .t_embedder                      \n",
      "        6                                                   [(2,)]                    (2, 384)                     [Embedding]   .y_embedder.embedding_table      \n",
      "        7                                                   [(2,)]                    (2, 384)                 [LabelEmbedder]   .y_embedder                      \n",
      "        8                                 [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.0                        \n",
      "        9                                 [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.1                        \n",
      "        10                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.2                        \n",
      "        11                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.3                        \n",
      "        12                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.4                        \n",
      "        13                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.5                        \n",
      "        14                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.6                        \n",
      "        15                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.7                        \n",
      "        16                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.8                        \n",
      "        17                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.9                        \n",
      "        18                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.10                       \n",
      "        19                                [(2, 81, 384), (2, 384)]                (2, 81, 384)                      [SiTBlock]   .blocks.11                       \n",
      "        20                                              [(2, 384)]                    (2, 768)                    [Sequential]   .final_layer.adaLN_modulation    \n",
      "        21                                          [(2, 81, 384)]                (2, 81, 384)                     [LayerNorm]   .final_layer.norm_final          \n",
      "        22                                          [(2, 81, 384)]                  (2, 81, 6)                        [Linear]   .final_layer.linear              \n",
      "        23                                [(2, 81, 384), (2, 384)]                  (2, 81, 6)                    [FinalLayer]   .final_layer                     \n",
      "        24                              [(2, 3, 9, 9), (2,), (2,)]                (2, 3, 9, 9)                           [SiT]   .                                \n"
     ]
    }
   ],
   "source": [
    "get_module_name_shapes(model_SiT,inputs_list=[torch.randn(2, 3, 9, 9).to(\"cuda\"), torch.rand(2,).to(\"cuda\"), ], \n",
    "                       model_kwargs={\"y\":torch.zeros(2, dtype=torch.int, device=\"cuda\")});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_DiT(\n",
    "    model,\n",
    "    fetcher,\n",
    "    data_loader,\n",
    "    dataset_Xmean,\n",
    "    dataset_Xstd,\n",
    "    t_scalar,\n",
    "    device='cuda',\n",
    "    progress_bar=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts features from specified layers of the model for the given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        fetcher (FeatureFetcher): An instance of the featureFetcher_module.\n",
    "        data_loader (DataLoader): DataLoader for the dataset.\n",
    "        dataset_mean (torch.Tensor): Mean for input normalization.\n",
    "        dataset_std (torch.Tensor): Standard deviation for input normalization.\n",
    "        t_scalar (float): Scalar value to create the time vector.\n",
    "        device (str, optional): Device to perform computations on. Defaults to 'cuda'.\n",
    "        progress_bar (bool, optional): Whether to display a progress bar. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with layer keys and concatenated activation tensors.\n",
    "    \"\"\"\n",
    "    feature_col = defaultdict(list)\n",
    "    loader = tqdm(data_loader) if progress_bar else data_loader\n",
    "    for X_batch, _ in loader:\n",
    "        # Prepare model inputs\n",
    "        model_kwargs = {'y': th.zeros(X_batch.size(0), dtype=th.int, device=device)}\n",
    "        t_vec = th.ones(X_batch.size(0), dtype=th.float, device=device) * t_scalar\n",
    "        # Normalize the batch\n",
    "        X_batch_norm = (X_batch.cuda().float() - dataset_Xmean) / dataset_Xstd\n",
    "        # Forward pass with no gradient computation\n",
    "        with th.no_grad():\n",
    "            model.forward(X_batch_norm, t_vec, **model_kwargs)\n",
    "        # Collect activations\n",
    "        for key, activations in fetcher.activations.items():\n",
    "            feature_col[key].append(activations.cpu())\n",
    "\n",
    "    # Concatenate all activations for each layer\n",
    "    for key in feature_col:\n",
    "        feature_col[key] = th.cat(feature_col[key], dim=0)\n",
    "        print(f\"{key}: {feature_col[key].shape}\")\n",
    "    return feature_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks2 torch.Size([2, 81, 384])\n",
      "blocks5 torch.Size([2, 81, 384])\n",
      "blocks8 torch.Size([2, 81, 384])\n",
      "blocks11 torch.Size([2, 81, 384])\n",
      "FeatureFetcher hooks all freed\n"
     ]
    }
   ],
   "source": [
    "fetcher = featureFetcher_module()\n",
    "# fetcher.record_module(model.blocks[11], target_name=\"blocks.11\")\n",
    "for i in (2,5,8,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "# fetcher.cleanup()\n",
    "feature_col = defaultdict(list)\n",
    "with th.no_grad():\n",
    "    model_SiT(torch.randn(2, 3, 9, 9).to(\"cuda\"), torch.rand(2,).to(\"cuda\"), y=torch.zeros(2, dtype=torch.int, device=\"cuda\"))\n",
    "for key, activations in fetcher.activations.items():\n",
    "    feature_col[key].append(activations)\n",
    "for key in feature_col.keys():\n",
    "    feature_col[key] = th.cat(feature_col[key], dim=0)\n",
    "    print(key, feature_col[key].shape)\n",
    "fetcher.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the t encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SiT transport interval is 0, 1 uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t0, t1 = self.check_interval(self.train_eps, self.sample_eps)\n",
    "# t = th.rand((x1.shape[0],)) * (t1 - t0) + t0\n",
    "transport.check_interval(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block output early 0.1 doesn't quite work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureFetcher hooks all freed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:36<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:12<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.1\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8450, Accuracy: 0.0251\n",
      "Epoch [250/5000], Loss: 0.8199, Accuracy: 0.7480\n",
      "Epoch [500/5000], Loss: 0.7229, Accuracy: 0.7715\n",
      "Epoch [750/5000], Loss: 0.6819, Accuracy: 0.7825\n",
      "Epoch [1000/5000], Loss: 0.6582, Accuracy: 0.7886\n",
      "Test Accuracy: 0.6708\n",
      "Epoch [1250/5000], Loss: 0.6424, Accuracy: 0.7934\n",
      "Epoch [1500/5000], Loss: 0.6310, Accuracy: 0.7961\n",
      "Epoch [1750/5000], Loss: 0.6224, Accuracy: 0.7986\n",
      "Epoch [2000/5000], Loss: 0.6157, Accuracy: 0.8004\n",
      "Test Accuracy: 0.6793\n",
      "Epoch [2250/5000], Loss: 0.6104, Accuracy: 0.8021\n",
      "Epoch [2500/5000], Loss: 0.6060, Accuracy: 0.8027\n",
      "Epoch [2750/5000], Loss: 0.6024, Accuracy: 0.8034\n",
      "Epoch [3000/5000], Loss: 0.5994, Accuracy: 0.8041\n",
      "Test Accuracy: 0.6804\n",
      "Epoch [3250/5000], Loss: 0.5969, Accuracy: 0.8047\n",
      "Epoch [3500/5000], Loss: 0.5947, Accuracy: 0.8051\n",
      "Epoch [3750/5000], Loss: 0.5928, Accuracy: 0.8057\n",
      "Epoch [4000/5000], Loss: 0.5912, Accuracy: 0.8058\n",
      "Test Accuracy: 0.6799\n",
      "Epoch [4250/5000], Loss: 0.5898, Accuracy: 0.8061\n",
      "Epoch [4500/5000], Loss: 0.5885, Accuracy: 0.8061\n",
      "Epoch [4750/5000], Loss: 0.5874, Accuracy: 0.8062\n",
      "Epoch [5000/5000], Loss: 0.5865, Accuracy: 0.8064\n",
      "Test Accuracy: 0.6796\n",
      "Test Accuracy: 0.6796\n",
      "Layer blocks5 - PCA time: 1.47s, PCA transform time: 10.92s, Training time: 37.60s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8501, Accuracy: 0.0243\n",
      "Epoch [250/5000], Loss: 0.8166, Accuracy: 0.7466\n",
      "Epoch [500/5000], Loss: 0.7404, Accuracy: 0.7657\n",
      "Epoch [750/5000], Loss: 0.7086, Accuracy: 0.7742\n",
      "Epoch [1000/5000], Loss: 0.6904, Accuracy: 0.7788\n",
      "Test Accuracy: 0.6652\n",
      "Epoch [1250/5000], Loss: 0.6783, Accuracy: 0.7822\n",
      "Epoch [1500/5000], Loss: 0.6696, Accuracy: 0.7846\n",
      "Epoch [1750/5000], Loss: 0.6632, Accuracy: 0.7864\n",
      "Epoch [2000/5000], Loss: 0.6582, Accuracy: 0.7874\n",
      "Test Accuracy: 0.6704\n",
      "Epoch [2250/5000], Loss: 0.6542, Accuracy: 0.7884\n",
      "Epoch [2500/5000], Loss: 0.6510, Accuracy: 0.7892\n",
      "Epoch [2750/5000], Loss: 0.6484, Accuracy: 0.7901\n",
      "Epoch [3000/5000], Loss: 0.6463, Accuracy: 0.7908\n",
      "Test Accuracy: 0.6724\n",
      "Epoch [3250/5000], Loss: 0.6444, Accuracy: 0.7912\n",
      "Epoch [3500/5000], Loss: 0.6429, Accuracy: 0.7919\n",
      "Epoch [3750/5000], Loss: 0.6415, Accuracy: 0.7919\n",
      "Epoch [4000/5000], Loss: 0.6403, Accuracy: 0.7923\n",
      "Test Accuracy: 0.6728\n",
      "Epoch [4250/5000], Loss: 0.6393, Accuracy: 0.7925\n",
      "Epoch [4500/5000], Loss: 0.6383, Accuracy: 0.7929\n",
      "Epoch [4750/5000], Loss: 0.6375, Accuracy: 0.7930\n",
      "Epoch [5000/5000], Loss: 0.6367, Accuracy: 0.7933\n",
      "Test Accuracy: 0.6722\n",
      "Test Accuracy: 0.6722\n",
      "Layer blocks11 - PCA time: 1.47s, PCA transform time: 10.90s, Training time: 37.70s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very early t 0.02 ~ this doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:43<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.02\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8546, Accuracy: 0.0245\n",
      "Epoch [250/5000], Loss: 1.0529, Accuracy: 0.6748\n",
      "Epoch [500/5000], Loss: 0.9508, Accuracy: 0.6989\n",
      "Epoch [750/5000], Loss: 0.9090, Accuracy: 0.7093\n",
      "Epoch [1000/5000], Loss: 0.8856, Accuracy: 0.7156\n",
      "Test Accuracy: 0.5992\n",
      "Epoch [1250/5000], Loss: 0.8707, Accuracy: 0.7191\n",
      "Epoch [1500/5000], Loss: 0.8604, Accuracy: 0.7221\n",
      "Epoch [1750/5000], Loss: 0.8529, Accuracy: 0.7239\n",
      "Epoch [2000/5000], Loss: 0.8472, Accuracy: 0.7248\n",
      "Test Accuracy: 0.6085\n",
      "Epoch [2250/5000], Loss: 0.8428, Accuracy: 0.7259\n",
      "Epoch [2500/5000], Loss: 0.8393, Accuracy: 0.7267\n",
      "Epoch [2750/5000], Loss: 0.8364, Accuracy: 0.7273\n",
      "Epoch [3000/5000], Loss: 0.8340, Accuracy: 0.7278\n",
      "Test Accuracy: 0.6092\n",
      "Epoch [3250/5000], Loss: 0.8320, Accuracy: 0.7283\n",
      "Epoch [3500/5000], Loss: 0.8302, Accuracy: 0.7288\n",
      "Epoch [3750/5000], Loss: 0.8287, Accuracy: 0.7289\n",
      "Epoch [4000/5000], Loss: 0.8274, Accuracy: 0.7292\n",
      "Test Accuracy: 0.6098\n",
      "Epoch [4250/5000], Loss: 0.8262, Accuracy: 0.7292\n",
      "Epoch [4500/5000], Loss: 0.8252, Accuracy: 0.7298\n",
      "Epoch [4750/5000], Loss: 0.8242, Accuracy: 0.7297\n",
      "Epoch [5000/5000], Loss: 0.8234, Accuracy: 0.7297\n",
      "Test Accuracy: 0.6102\n",
      "Test Accuracy: 0.6102\n",
      "Layer blocks5 - PCA time: 1.46s, PCA transform time: 10.72s, Training time: 37.32s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8592, Accuracy: 0.0242\n",
      "Epoch [250/5000], Loss: 0.9256, Accuracy: 0.7136\n",
      "Epoch [500/5000], Loss: 0.8360, Accuracy: 0.7365\n",
      "Epoch [750/5000], Loss: 0.7980, Accuracy: 0.7464\n",
      "Epoch [1000/5000], Loss: 0.7759, Accuracy: 0.7519\n",
      "Test Accuracy: 0.6370\n",
      "Epoch [1250/5000], Loss: 0.7611, Accuracy: 0.7557\n",
      "Epoch [1500/5000], Loss: 0.7503, Accuracy: 0.7588\n",
      "Epoch [1750/5000], Loss: 0.7422, Accuracy: 0.7607\n",
      "Epoch [2000/5000], Loss: 0.7358, Accuracy: 0.7623\n",
      "Test Accuracy: 0.6454\n",
      "Epoch [2250/5000], Loss: 0.7307, Accuracy: 0.7637\n",
      "Epoch [2500/5000], Loss: 0.7266, Accuracy: 0.7646\n",
      "Epoch [2750/5000], Loss: 0.7233, Accuracy: 0.7656\n",
      "Epoch [3000/5000], Loss: 0.7205, Accuracy: 0.7662\n",
      "Test Accuracy: 0.6472\n",
      "Epoch [3250/5000], Loss: 0.7182, Accuracy: 0.7665\n",
      "Epoch [3500/5000], Loss: 0.7162, Accuracy: 0.7669\n",
      "Epoch [3750/5000], Loss: 0.7146, Accuracy: 0.7675\n",
      "Epoch [4000/5000], Loss: 0.7132, Accuracy: 0.7677\n",
      "Test Accuracy: 0.6470\n",
      "Epoch [4250/5000], Loss: 0.7120, Accuracy: 0.7680\n",
      "Epoch [4500/5000], Loss: 0.7109, Accuracy: 0.7681\n",
      "Epoch [4750/5000], Loss: 0.7100, Accuracy: 0.7682\n",
      "Epoch [5000/5000], Loss: 0.7091, Accuracy: 0.7684\n",
      "Test Accuracy: 0.6463\n",
      "Test Accuracy: 0.6463\n",
      "Layer blocks11 - PCA time: 1.47s, PCA transform time: 10.84s, Training time: 37.48s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very late t ~ 1 (not working... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:53<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:17<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.99\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8462, Accuracy: 0.0263\n",
      "Epoch [250/5000], Loss: 1.5306, Accuracy: 0.5521\n",
      "Epoch [500/5000], Loss: 1.3139, Accuracy: 0.5962\n",
      "Epoch [750/5000], Loss: 1.2215, Accuracy: 0.6172\n",
      "Epoch [1000/5000], Loss: 1.1687, Accuracy: 0.6294\n",
      "Test Accuracy: 0.5127\n",
      "Epoch [1250/5000], Loss: 1.1343, Accuracy: 0.6379\n",
      "Epoch [1500/5000], Loss: 1.1101, Accuracy: 0.6438\n",
      "Epoch [1750/5000], Loss: 1.0924, Accuracy: 0.6481\n",
      "Epoch [2000/5000], Loss: 1.0789, Accuracy: 0.6512\n",
      "Test Accuracy: 0.5357\n",
      "Epoch [2250/5000], Loss: 1.0684, Accuracy: 0.6537\n",
      "Epoch [2500/5000], Loss: 1.0601, Accuracy: 0.6558\n",
      "Epoch [2750/5000], Loss: 1.0534, Accuracy: 0.6578\n",
      "Epoch [3000/5000], Loss: 1.0478, Accuracy: 0.6597\n",
      "Test Accuracy: 0.5435\n",
      "Epoch [3250/5000], Loss: 1.0432, Accuracy: 0.6607\n",
      "Epoch [3500/5000], Loss: 1.0393, Accuracy: 0.6616\n",
      "Epoch [3750/5000], Loss: 1.0360, Accuracy: 0.6624\n",
      "Epoch [4000/5000], Loss: 1.0331, Accuracy: 0.6629\n",
      "Test Accuracy: 0.5475\n",
      "Epoch [4250/5000], Loss: 1.0305, Accuracy: 0.6636\n",
      "Epoch [4500/5000], Loss: 1.0283, Accuracy: 0.6642\n",
      "Epoch [4750/5000], Loss: 1.0263, Accuracy: 0.6648\n",
      "Epoch [5000/5000], Loss: 1.0246, Accuracy: 0.6652\n",
      "Test Accuracy: 0.5493\n",
      "Test Accuracy: 0.5493\n",
      "Layer blocks5 - PCA time: 1.49s, PCA transform time: 11.05s, Training time: 37.50s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8479, Accuracy: 0.0256\n",
      "Epoch [250/5000], Loss: 1.2954, Accuracy: 0.6189\n",
      "Epoch [500/5000], Loss: 1.1130, Accuracy: 0.6560\n",
      "Epoch [750/5000], Loss: 1.0330, Accuracy: 0.6739\n",
      "Epoch [1000/5000], Loss: 0.9866, Accuracy: 0.6848\n",
      "Test Accuracy: 0.5756\n",
      "Epoch [1250/5000], Loss: 0.9560, Accuracy: 0.6922\n",
      "Epoch [1500/5000], Loss: 0.9342, Accuracy: 0.6978\n",
      "Epoch [1750/5000], Loss: 0.9179, Accuracy: 0.7019\n",
      "Epoch [2000/5000], Loss: 0.9053, Accuracy: 0.7051\n",
      "Test Accuracy: 0.5924\n",
      "Epoch [2250/5000], Loss: 0.8953, Accuracy: 0.7076\n",
      "Epoch [2500/5000], Loss: 0.8871, Accuracy: 0.7098\n",
      "Epoch [2750/5000], Loss: 0.8803, Accuracy: 0.7111\n",
      "Epoch [3000/5000], Loss: 0.8746, Accuracy: 0.7126\n",
      "Test Accuracy: 0.5981\n",
      "Epoch [3250/5000], Loss: 0.8698, Accuracy: 0.7137\n",
      "Epoch [3500/5000], Loss: 0.8657, Accuracy: 0.7147\n",
      "Epoch [3750/5000], Loss: 0.8622, Accuracy: 0.7157\n",
      "Epoch [4000/5000], Loss: 0.8591, Accuracy: 0.7164\n",
      "Test Accuracy: 0.6014\n",
      "Epoch [4250/5000], Loss: 0.8563, Accuracy: 0.7171\n",
      "Epoch [4500/5000], Loss: 0.8539, Accuracy: 0.7176\n",
      "Epoch [4750/5000], Loss: 0.8517, Accuracy: 0.7182\n",
      "Epoch [5000/5000], Loss: 0.8498, Accuracy: 0.7189\n",
      "Test Accuracy: 0.6026\n",
      "Test Accuracy: 0.6026\n",
      "Layer blocks11 - PCA time: 1.48s, PCA transform time: 11.07s, Training time: 37.42s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avg_col = {k: v.mean(dim=1) for k, v in feature_col.items()}\n",
    "feature_avg_col_test = {k: v.mean(dim=1) for k, v in feature_col_test.items()}\n",
    "feature_last_col = {k: v[:, -1] for k, v in feature_col.items()}\n",
    "feature_last_col_test = {k: v[:, -1] for k, v in feature_col_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8256, Accuracy: 0.0273\n",
      "Epoch [250/5000], Loss: 1.7013, Accuracy: 0.5004\n",
      "Epoch [500/5000], Loss: 1.4548, Accuracy: 0.5607\n",
      "Epoch [750/5000], Loss: 1.3253, Accuracy: 0.5941\n",
      "Epoch [1000/5000], Loss: 1.2418, Accuracy: 0.6158\n",
      "Test Accuracy: 0.6020\n",
      "Epoch [1250/5000], Loss: 1.1819, Accuracy: 0.6320\n",
      "Epoch [1500/5000], Loss: 1.1367, Accuracy: 0.6450\n",
      "Epoch [1750/5000], Loss: 1.1008, Accuracy: 0.6545\n",
      "Epoch [2000/5000], Loss: 1.0715, Accuracy: 0.6625\n",
      "Test Accuracy: 0.6465\n",
      "Epoch [2250/5000], Loss: 1.0467, Accuracy: 0.6694\n",
      "Epoch [2500/5000], Loss: 1.0258, Accuracy: 0.6755\n",
      "Epoch [2750/5000], Loss: 1.0076, Accuracy: 0.6805\n",
      "Epoch [3000/5000], Loss: 0.9916, Accuracy: 0.6849\n",
      "Test Accuracy: 0.6663\n",
      "Epoch [3250/5000], Loss: 0.9775, Accuracy: 0.6889\n",
      "Epoch [3500/5000], Loss: 0.9649, Accuracy: 0.6927\n",
      "Epoch [3750/5000], Loss: 0.9533, Accuracy: 0.6955\n",
      "Epoch [4000/5000], Loss: 0.9433, Accuracy: 0.6981\n",
      "Test Accuracy: 0.6771\n",
      "Epoch [4250/5000], Loss: 0.9338, Accuracy: 0.7008\n",
      "Epoch [4500/5000], Loss: 0.9250, Accuracy: 0.7031\n",
      "Epoch [4750/5000], Loss: 0.9173, Accuracy: 0.7053\n",
      "Epoch [5000/5000], Loss: 0.9100, Accuracy: 0.7077\n",
      "Test Accuracy: 0.6847\n",
      "Test Accuracy: 0.6847\n",
      "Layer blocks5 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.19s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.8005, Accuracy: 0.0258\n",
      "Epoch [250/5000], Loss: 1.5963, Accuracy: 0.5256\n",
      "Epoch [500/5000], Loss: 1.3598, Accuracy: 0.5849\n",
      "Epoch [750/5000], Loss: 1.2427, Accuracy: 0.6148\n",
      "Epoch [1000/5000], Loss: 1.1701, Accuracy: 0.6335\n",
      "Test Accuracy: 0.6108\n",
      "Epoch [1250/5000], Loss: 1.1198, Accuracy: 0.6468\n",
      "Epoch [1500/5000], Loss: 1.0828, Accuracy: 0.6560\n",
      "Epoch [1750/5000], Loss: 1.0546, Accuracy: 0.6637\n",
      "Epoch [2000/5000], Loss: 1.0322, Accuracy: 0.6697\n",
      "Test Accuracy: 0.6442\n",
      "Epoch [2250/5000], Loss: 1.0143, Accuracy: 0.6749\n",
      "Epoch [2500/5000], Loss: 0.9994, Accuracy: 0.6792\n",
      "Epoch [2750/5000], Loss: 0.9866, Accuracy: 0.6820\n",
      "Epoch [3000/5000], Loss: 0.9760, Accuracy: 0.6850\n",
      "Test Accuracy: 0.6559\n",
      "Epoch [3250/5000], Loss: 0.9670, Accuracy: 0.6872\n",
      "Epoch [3500/5000], Loss: 0.9593, Accuracy: 0.6892\n",
      "Epoch [3750/5000], Loss: 0.9521, Accuracy: 0.6913\n",
      "Epoch [4000/5000], Loss: 0.9462, Accuracy: 0.6927\n",
      "Test Accuracy: 0.6619\n",
      "Epoch [4250/5000], Loss: 0.9406, Accuracy: 0.6938\n",
      "Epoch [4500/5000], Loss: 0.9362, Accuracy: 0.6952\n",
      "Epoch [4750/5000], Loss: 0.9319, Accuracy: 0.6962\n",
      "Epoch [5000/5000], Loss: 0.9278, Accuracy: 0.6981\n",
      "Test Accuracy: 0.6653\n",
      "Test Accuracy: 0.6653\n",
      "Layer blocks11 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.12s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_avg_col, feature_avg_col_test, y_train, y_test,\n",
    "    PC_dim=None, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8554, Accuracy: 0.0213\n",
      "Epoch [250/5000], Loss: 1.8759, Accuracy: 0.4603\n",
      "Epoch [500/5000], Loss: 1.3052, Accuracy: 0.5935\n",
      "Epoch [750/5000], Loss: 1.2309, Accuracy: 0.6134\n",
      "Epoch [1000/5000], Loss: 1.1767, Accuracy: 0.6267\n",
      "Test Accuracy: 0.6142\n",
      "Epoch [1250/5000], Loss: 1.2961, Accuracy: 0.6064\n",
      "Epoch [1500/5000], Loss: 1.1012, Accuracy: 0.6506\n",
      "Epoch [1750/5000], Loss: 1.0763, Accuracy: 0.6576\n",
      "Epoch [2000/5000], Loss: 1.0623, Accuracy: 0.6596\n",
      "Test Accuracy: 0.6432\n",
      "Epoch [2250/5000], Loss: 1.0457, Accuracy: 0.6637\n",
      "Epoch [2500/5000], Loss: 1.0272, Accuracy: 0.6701\n",
      "Epoch [2750/5000], Loss: 1.4363, Accuracy: 0.6006\n",
      "Epoch [3000/5000], Loss: 0.9951, Accuracy: 0.6806\n",
      "Test Accuracy: 0.6631\n",
      "Epoch [3250/5000], Loss: 0.9842, Accuracy: 0.6838\n",
      "Epoch [3500/5000], Loss: 0.9781, Accuracy: 0.6856\n",
      "Epoch [3750/5000], Loss: 0.9794, Accuracy: 0.6822\n",
      "Epoch [4000/5000], Loss: 0.9720, Accuracy: 0.6848\n",
      "Test Accuracy: 0.6677\n",
      "Epoch [4250/5000], Loss: 1.5547, Accuracy: 0.5980\n",
      "Epoch [4500/5000], Loss: 0.9469, Accuracy: 0.6950\n",
      "Epoch [4750/5000], Loss: 0.9384, Accuracy: 0.6986\n",
      "Epoch [5000/5000], Loss: 0.9382, Accuracy: 0.6975\n",
      "Test Accuracy: 0.6739\n",
      "Test Accuracy: 0.6739\n",
      "Layer blocks5 - PCA time: 0.02s, PCA transform time: 0.08s, Training time: 32.22s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.8640, Accuracy: 0.0223\n",
      "Epoch [250/5000], Loss: 1.3058, Accuracy: 0.5926\n",
      "Epoch [500/5000], Loss: 1.1697, Accuracy: 0.6282\n",
      "Epoch [750/5000], Loss: 1.1120, Accuracy: 0.6456\n",
      "Epoch [1000/5000], Loss: 1.0788, Accuracy: 0.6510\n",
      "Test Accuracy: 0.6284\n",
      "Epoch [1250/5000], Loss: 1.0485, Accuracy: 0.6607\n",
      "Epoch [1500/5000], Loss: 1.0271, Accuracy: 0.6664\n",
      "Epoch [1750/5000], Loss: 1.0148, Accuracy: 0.6697\n",
      "Epoch [2000/5000], Loss: 1.0006, Accuracy: 0.6715\n",
      "Test Accuracy: 0.6471\n",
      "Epoch [2250/5000], Loss: 0.9890, Accuracy: 0.6757\n",
      "Epoch [2500/5000], Loss: 0.9800, Accuracy: 0.6787\n",
      "Epoch [2750/5000], Loss: 0.9746, Accuracy: 0.6799\n",
      "Epoch [3000/5000], Loss: 0.9662, Accuracy: 0.6832\n",
      "Test Accuracy: 0.6538\n",
      "Epoch [3250/5000], Loss: 0.9671, Accuracy: 0.6809\n",
      "Epoch [3500/5000], Loss: 0.9516, Accuracy: 0.6878\n",
      "Epoch [3750/5000], Loss: 0.9549, Accuracy: 0.6836\n",
      "Epoch [4000/5000], Loss: 2.3308, Accuracy: 0.5364\n",
      "Test Accuracy: 0.4991\n",
      "Epoch [4250/5000], Loss: 0.9357, Accuracy: 0.6948\n",
      "Epoch [4500/5000], Loss: 0.9257, Accuracy: 0.6978\n",
      "Epoch [4750/5000], Loss: 0.9253, Accuracy: 0.6971\n",
      "Epoch [5000/5000], Loss: 0.9310, Accuracy: 0.6941\n",
      "Test Accuracy: 0.6599\n",
      "Test Accuracy: 0.6599\n",
      "Layer blocks11 - PCA time: 0.02s, PCA transform time: 0.08s, Training time: 32.17s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_avg_col, feature_avg_col_test, y_train, y_test,\n",
    "    PC_dim=None, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.05,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middel time t ~ 0.5 working a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:58<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.5\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8595, Accuracy: 0.0236\n",
      "Epoch [250/5000], Loss: 0.4368, Accuracy: 0.8811\n",
      "Epoch [500/5000], Loss: 0.3277, Accuracy: 0.9097\n",
      "Epoch [750/5000], Loss: 0.2797, Accuracy: 0.9208\n",
      "Epoch [1000/5000], Loss: 0.2510, Accuracy: 0.9279\n",
      "Test Accuracy: 0.8232\n",
      "Epoch [1250/5000], Loss: 0.2312, Accuracy: 0.9327\n",
      "Epoch [1500/5000], Loss: 0.2165, Accuracy: 0.9364\n",
      "Epoch [1750/5000], Loss: 0.2049, Accuracy: 0.9393\n",
      "Epoch [2000/5000], Loss: 0.1955, Accuracy: 0.9416\n",
      "Test Accuracy: 0.8253\n",
      "Epoch [2250/5000], Loss: 0.1876, Accuracy: 0.9437\n",
      "Epoch [2500/5000], Loss: 0.1809, Accuracy: 0.9453\n",
      "Epoch [2750/5000], Loss: 0.1750, Accuracy: 0.9467\n",
      "Epoch [3000/5000], Loss: 0.1698, Accuracy: 0.9480\n",
      "Test Accuracy: 0.8221\n",
      "Epoch [3250/5000], Loss: 0.1651, Accuracy: 0.9492\n",
      "Epoch [3500/5000], Loss: 0.1609, Accuracy: 0.9503\n",
      "Epoch [3750/5000], Loss: 0.1571, Accuracy: 0.9513\n",
      "Epoch [4000/5000], Loss: 0.1536, Accuracy: 0.9522\n",
      "Test Accuracy: 0.8185\n",
      "Epoch [4250/5000], Loss: 0.1504, Accuracy: 0.9530\n",
      "Epoch [4500/5000], Loss: 0.1474, Accuracy: 0.9534\n",
      "Epoch [4750/5000], Loss: 0.1446, Accuracy: 0.9540\n",
      "Epoch [5000/5000], Loss: 0.1421, Accuracy: 0.9547\n",
      "Test Accuracy: 0.8145\n",
      "Test Accuracy: 0.8145\n",
      "Layer blocks5 - PCA time: 1.49s, PCA transform time: 11.06s, Training time: 37.75s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8548, Accuracy: 0.0255\n",
      "Epoch [250/5000], Loss: 0.2225, Accuracy: 0.9348\n",
      "Epoch [500/5000], Loss: 0.1803, Accuracy: 0.9447\n",
      "Epoch [750/5000], Loss: 0.1617, Accuracy: 0.9491\n",
      "Epoch [1000/5000], Loss: 0.1506, Accuracy: 0.9520\n",
      "Test Accuracy: 0.8612\n",
      "Epoch [1250/5000], Loss: 0.1429, Accuracy: 0.9537\n",
      "Epoch [1500/5000], Loss: 0.1372, Accuracy: 0.9549\n",
      "Epoch [1750/5000], Loss: 0.1328, Accuracy: 0.9557\n",
      "Epoch [2000/5000], Loss: 0.1292, Accuracy: 0.9562\n",
      "Test Accuracy: 0.8567\n",
      "Epoch [2250/5000], Loss: 0.1263, Accuracy: 0.9566\n",
      "Epoch [2500/5000], Loss: 0.1238, Accuracy: 0.9571\n",
      "Epoch [2750/5000], Loss: 0.1217, Accuracy: 0.9575\n",
      "Epoch [3000/5000], Loss: 0.1200, Accuracy: 0.9577\n",
      "Test Accuracy: 0.8518\n",
      "Epoch [3250/5000], Loss: 0.1184, Accuracy: 0.9578\n",
      "Epoch [3500/5000], Loss: 0.1171, Accuracy: 0.9580\n",
      "Epoch [3750/5000], Loss: 0.1159, Accuracy: 0.9580\n",
      "Epoch [4000/5000], Loss: 0.1149, Accuracy: 0.9580\n",
      "Test Accuracy: 0.8476\n",
      "Epoch [4250/5000], Loss: 0.1140, Accuracy: 0.9581\n",
      "Epoch [4500/5000], Loss: 0.1132, Accuracy: 0.9581\n",
      "Epoch [4750/5000], Loss: 0.1125, Accuracy: 0.9581\n",
      "Epoch [5000/5000], Loss: 0.1119, Accuracy: 0.9582\n",
      "Test Accuracy: 0.8447\n",
      "Test Accuracy: 0.8447\n",
      "Layer blocks11 - PCA time: 1.48s, PCA transform time: 11.10s, Training time: 37.48s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avg_col = {k: v.mean(dim=1) for k, v in feature_col.items()}\n",
    "feature_avg_col_test = {k: v.mean(dim=1) for k, v in feature_col_test.items()}\n",
    "feature_last_col = {k: v[:, -1] for k, v in feature_col.items()}\n",
    "feature_last_col_test = {k: v[:, -1] for k, v in feature_col_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8451, Accuracy: 0.0229\n",
      "Epoch [250/5000], Loss: 0.4860, Accuracy: 0.8466\n",
      "Epoch [500/5000], Loss: 0.3952, Accuracy: 0.8701\n",
      "Epoch [750/5000], Loss: 0.3535, Accuracy: 0.8817\n",
      "Epoch [1000/5000], Loss: 0.3279, Accuracy: 0.8895\n",
      "Test Accuracy: 0.8655\n",
      "Epoch [1250/5000], Loss: 0.3100, Accuracy: 0.8941\n",
      "Epoch [1500/5000], Loss: 0.2965, Accuracy: 0.8976\n",
      "Epoch [1750/5000], Loss: 0.2858, Accuracy: 0.9006\n",
      "Epoch [2000/5000], Loss: 0.2770, Accuracy: 0.9031\n",
      "Test Accuracy: 0.8740\n",
      "Epoch [2250/5000], Loss: 0.2696, Accuracy: 0.9052\n",
      "Epoch [2500/5000], Loss: 0.2633, Accuracy: 0.9069\n",
      "Epoch [2750/5000], Loss: 0.2580, Accuracy: 0.9083\n",
      "Epoch [3000/5000], Loss: 0.2531, Accuracy: 0.9095\n",
      "Test Accuracy: 0.8763\n",
      "Epoch [3250/5000], Loss: 0.2489, Accuracy: 0.9107\n",
      "Epoch [3500/5000], Loss: 0.2451, Accuracy: 0.9117\n",
      "Epoch [3750/5000], Loss: 0.2417, Accuracy: 0.9129\n",
      "Epoch [4000/5000], Loss: 0.2387, Accuracy: 0.9136\n",
      "Test Accuracy: 0.8772\n",
      "Epoch [4250/5000], Loss: 0.2360, Accuracy: 0.9143\n",
      "Epoch [4500/5000], Loss: 0.2334, Accuracy: 0.9152\n",
      "Epoch [4750/5000], Loss: 0.2311, Accuracy: 0.9158\n",
      "Epoch [5000/5000], Loss: 0.2290, Accuracy: 0.9162\n",
      "Test Accuracy: 0.8782\n",
      "Test Accuracy: 0.8782\n",
      "Layer blocks5 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.05s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.9220, Accuracy: 0.0171\n",
      "Epoch [250/5000], Loss: 0.3396, Accuracy: 0.8885\n",
      "Epoch [500/5000], Loss: 0.2876, Accuracy: 0.9027\n",
      "Epoch [750/5000], Loss: 0.2643, Accuracy: 0.9092\n",
      "Epoch [1000/5000], Loss: 0.2504, Accuracy: 0.9132\n",
      "Test Accuracy: 0.8896\n",
      "Epoch [1250/5000], Loss: 0.2410, Accuracy: 0.9156\n",
      "Epoch [1500/5000], Loss: 0.2341, Accuracy: 0.9175\n",
      "Epoch [1750/5000], Loss: 0.2288, Accuracy: 0.9190\n",
      "Epoch [2000/5000], Loss: 0.2246, Accuracy: 0.9204\n",
      "Test Accuracy: 0.8899\n",
      "Epoch [2250/5000], Loss: 0.2212, Accuracy: 0.9214\n",
      "Epoch [2500/5000], Loss: 0.2183, Accuracy: 0.9221\n",
      "Epoch [2750/5000], Loss: 0.2161, Accuracy: 0.9225\n",
      "Epoch [3000/5000], Loss: 0.2140, Accuracy: 0.9231\n",
      "Test Accuracy: 0.8892\n",
      "Epoch [3250/5000], Loss: 0.2123, Accuracy: 0.9236\n",
      "Epoch [3500/5000], Loss: 0.2106, Accuracy: 0.9242\n",
      "Epoch [3750/5000], Loss: 0.2093, Accuracy: 0.9246\n",
      "Epoch [4000/5000], Loss: 0.2081, Accuracy: 0.9251\n",
      "Test Accuracy: 0.8881\n",
      "Epoch [4250/5000], Loss: 0.2071, Accuracy: 0.9253\n",
      "Epoch [4500/5000], Loss: 0.2062, Accuracy: 0.9256\n",
      "Epoch [4750/5000], Loss: 0.2054, Accuracy: 0.9259\n",
      "Epoch [5000/5000], Loss: 0.2047, Accuracy: 0.9260\n",
      "Test Accuracy: 0.8875\n",
      "Test Accuracy: 0.8875\n",
      "Layer blocks11 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.07s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_avg_col, feature_avg_col_test, y_train, y_test,\n",
    "    PC_dim=None, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middle to late time t ~ 0.8? (yes this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:05<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.8\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8472, Accuracy: 0.0256\n",
      "Epoch [250/5000], Loss: 0.3276, Accuracy: 0.9192\n",
      "Epoch [500/5000], Loss: 0.2292, Accuracy: 0.9414\n",
      "Epoch [750/5000], Loss: 0.1874, Accuracy: 0.9510\n",
      "Epoch [1000/5000], Loss: 0.1628, Accuracy: 0.9570\n",
      "Test Accuracy: 0.8574\n",
      "Epoch [1250/5000], Loss: 0.1460, Accuracy: 0.9609\n",
      "Epoch [1500/5000], Loss: 0.1336, Accuracy: 0.9640\n",
      "Epoch [1750/5000], Loss: 0.1239, Accuracy: 0.9663\n",
      "Epoch [2000/5000], Loss: 0.1160, Accuracy: 0.9681\n",
      "Test Accuracy: 0.8549\n",
      "Epoch [2250/5000], Loss: 0.1094, Accuracy: 0.9700\n",
      "Epoch [2500/5000], Loss: 0.1038, Accuracy: 0.9712\n",
      "Epoch [2750/5000], Loss: 0.0989, Accuracy: 0.9722\n",
      "Epoch [3000/5000], Loss: 0.0947, Accuracy: 0.9733\n",
      "Test Accuracy: 0.8516\n",
      "Epoch [3250/5000], Loss: 0.0909, Accuracy: 0.9740\n",
      "Epoch [3500/5000], Loss: 0.0876, Accuracy: 0.9747\n",
      "Epoch [3750/5000], Loss: 0.0845, Accuracy: 0.9753\n",
      "Epoch [4000/5000], Loss: 0.0818, Accuracy: 0.9757\n",
      "Test Accuracy: 0.8467\n",
      "Epoch [4250/5000], Loss: 0.0793, Accuracy: 0.9762\n",
      "Epoch [4500/5000], Loss: 0.0771, Accuracy: 0.9765\n",
      "Epoch [4750/5000], Loss: 0.0750, Accuracy: 0.9769\n",
      "Epoch [5000/5000], Loss: 0.0731, Accuracy: 0.9773\n",
      "Test Accuracy: 0.8424\n",
      "Test Accuracy: 0.8424\n",
      "Layer blocks5 - PCA time: 1.47s, PCA transform time: 10.77s, Training time: 37.63s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8357, Accuracy: 0.0273\n",
      "Epoch [250/5000], Loss: 0.0220, Accuracy: 0.9968\n",
      "Epoch [500/5000], Loss: 0.0122, Accuracy: 0.9988\n",
      "Epoch [750/5000], Loss: 0.0082, Accuracy: 0.9997\n",
      "Epoch [1000/5000], Loss: 0.0061, Accuracy: 0.9999\n",
      "Test Accuracy: 0.9720\n",
      "Epoch [1250/5000], Loss: 0.0047, Accuracy: 1.0000\n",
      "Epoch [1500/5000], Loss: 0.0037, Accuracy: 1.0000\n",
      "Epoch [1750/5000], Loss: 0.0030, Accuracy: 1.0000\n",
      "Epoch [2000/5000], Loss: 0.0024, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9691\n",
      "Epoch [2250/5000], Loss: 0.0020, Accuracy: 1.0000\n",
      "Epoch [2500/5000], Loss: 0.0017, Accuracy: 1.0000\n",
      "Epoch [2750/5000], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [3000/5000], Loss: 0.0012, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9665\n",
      "Epoch [3250/5000], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [3500/5000], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [3750/5000], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [4000/5000], Loss: 0.0007, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9649\n",
      "Epoch [4250/5000], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [4500/5000], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [4750/5000], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [5000/5000], Loss: 0.0004, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9634\n",
      "Test Accuracy: 0.9634\n",
      "Layer blocks11 - PCA time: 1.47s, PCA transform time: 10.80s, Training time: 37.39s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avg_col = {k: v.mean(dim=1) for k, v in feature_col.items()}\n",
    "feature_avg_col_test = {k: v.mean(dim=1) for k, v in feature_col_test.items()}\n",
    "feature_last_col = {k: v[:, -1] for k, v in feature_col.items()}\n",
    "feature_last_col_test = {k: v[:, -1] for k, v in feature_col_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8384, Accuracy: 0.0275\n",
      "Epoch [250/5000], Loss: 0.3325, Accuracy: 0.8945\n",
      "Epoch [500/5000], Loss: 0.2651, Accuracy: 0.9113\n",
      "Epoch [750/5000], Loss: 0.2346, Accuracy: 0.9197\n",
      "Epoch [1000/5000], Loss: 0.2158, Accuracy: 0.9258\n",
      "Test Accuracy: 0.9073\n",
      "Epoch [1250/5000], Loss: 0.2027, Accuracy: 0.9291\n",
      "Epoch [1500/5000], Loss: 0.1928, Accuracy: 0.9319\n",
      "Epoch [1750/5000], Loss: 0.1849, Accuracy: 0.9344\n",
      "Epoch [2000/5000], Loss: 0.1785, Accuracy: 0.9364\n",
      "Test Accuracy: 0.9132\n",
      "Epoch [2250/5000], Loss: 0.1732, Accuracy: 0.9381\n",
      "Epoch [2500/5000], Loss: 0.1686, Accuracy: 0.9393\n",
      "Epoch [2750/5000], Loss: 0.1647, Accuracy: 0.9404\n",
      "Epoch [3000/5000], Loss: 0.1613, Accuracy: 0.9414\n",
      "Test Accuracy: 0.9146\n",
      "Epoch [3250/5000], Loss: 0.1583, Accuracy: 0.9421\n",
      "Epoch [3500/5000], Loss: 0.1556, Accuracy: 0.9429\n",
      "Epoch [3750/5000], Loss: 0.1532, Accuracy: 0.9437\n",
      "Epoch [4000/5000], Loss: 0.1510, Accuracy: 0.9441\n",
      "Test Accuracy: 0.9149\n",
      "Epoch [4250/5000], Loss: 0.1489, Accuracy: 0.9452\n",
      "Epoch [4500/5000], Loss: 0.1472, Accuracy: 0.9459\n",
      "Epoch [4750/5000], Loss: 0.1454, Accuracy: 0.9463\n",
      "Epoch [5000/5000], Loss: 0.1440, Accuracy: 0.9464\n",
      "Test Accuracy: 0.9147\n",
      "Test Accuracy: 0.9147\n",
      "Layer blocks5 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.03s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.9350, Accuracy: 0.0258\n",
      "Epoch [250/5000], Loss: 0.0701, Accuracy: 0.9822\n",
      "Epoch [500/5000], Loss: 0.0492, Accuracy: 0.9865\n",
      "Epoch [750/5000], Loss: 0.0404, Accuracy: 0.9886\n",
      "Epoch [1000/5000], Loss: 0.0351, Accuracy: 0.9899\n",
      "Test Accuracy: 0.9803\n",
      "Epoch [1250/5000], Loss: 0.0315, Accuracy: 0.9908\n",
      "Epoch [1500/5000], Loss: 0.0289, Accuracy: 0.9916\n",
      "Epoch [1750/5000], Loss: 0.0268, Accuracy: 0.9921\n",
      "Epoch [2000/5000], Loss: 0.0251, Accuracy: 0.9926\n",
      "Test Accuracy: 0.9810\n",
      "Epoch [2250/5000], Loss: 0.0237, Accuracy: 0.9930\n",
      "Epoch [2500/5000], Loss: 0.0224, Accuracy: 0.9933\n",
      "Epoch [2750/5000], Loss: 0.0214, Accuracy: 0.9935\n",
      "Epoch [3000/5000], Loss: 0.0205, Accuracy: 0.9938\n",
      "Test Accuracy: 0.9810\n",
      "Epoch [3250/5000], Loss: 0.0196, Accuracy: 0.9940\n",
      "Epoch [3500/5000], Loss: 0.0189, Accuracy: 0.9942\n",
      "Epoch [3750/5000], Loss: 0.0182, Accuracy: 0.9943\n",
      "Epoch [4000/5000], Loss: 0.0176, Accuracy: 0.9946\n",
      "Test Accuracy: 0.9805\n",
      "Epoch [4250/5000], Loss: 0.0170, Accuracy: 0.9948\n",
      "Epoch [4500/5000], Loss: 0.0165, Accuracy: 0.9949\n",
      "Epoch [4750/5000], Loss: 0.0160, Accuracy: 0.9951\n",
      "Epoch [5000/5000], Loss: 0.0156, Accuracy: 0.9952\n",
      "Test Accuracy: 0.9803\n",
      "Test Accuracy: 0.9803\n",
      "Layer blocks11 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 31.99s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_avg_col, feature_avg_col_test, y_train, y_test,\n",
    "    PC_dim=None, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Later t=0.9, this is perfect, accuracy goes to 0.996 perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:12<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([120000, 81, 384])\n",
      "blocks11: torch.Size([120000, 81, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks5: torch.Size([40000, 81, 384])\n",
      "blocks11: torch.Size([40000, 81, 384])\n"
     ]
    }
   ],
   "source": [
    "t_scalar = 0.9\n",
    "fetcher = featureFetcher_module()\n",
    "for i in (5,11):#range(len(model.blocks)):\n",
    "    fetcher.record_module(model_SiT.blocks[i], target_name=f\"blocks{i}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "feature_col = extract_features_DiT(model_SiT, fetcher, train_loader, dataset_Xmean, dataset_Xstd, t_scalar)\n",
    "feature_col_test = extract_features_DiT(model_SiT, fetcher, test_loader, dataset_Xmean, dataset_Xstd, t_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "PCA components for layer blocks5: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8470, Accuracy: 0.0250\n",
      "Epoch [250/5000], Loss: 0.5505, Accuracy: 0.8570\n",
      "Epoch [500/5000], Loss: 0.4052, Accuracy: 0.8907\n",
      "Epoch [750/5000], Loss: 0.3424, Accuracy: 0.9055\n",
      "Epoch [1000/5000], Loss: 0.3053, Accuracy: 0.9143\n",
      "Test Accuracy: 0.8085\n",
      "Epoch [1250/5000], Loss: 0.2800, Accuracy: 0.9201\n",
      "Epoch [1500/5000], Loss: 0.2614, Accuracy: 0.9244\n",
      "Epoch [1750/5000], Loss: 0.2468, Accuracy: 0.9277\n",
      "Epoch [2000/5000], Loss: 0.2351, Accuracy: 0.9303\n",
      "Test Accuracy: 0.8139\n",
      "Epoch [2250/5000], Loss: 0.2253, Accuracy: 0.9322\n",
      "Epoch [2500/5000], Loss: 0.2170, Accuracy: 0.9343\n",
      "Epoch [2750/5000], Loss: 0.2098, Accuracy: 0.9361\n",
      "Epoch [3000/5000], Loss: 0.2035, Accuracy: 0.9377\n",
      "Test Accuracy: 0.8126\n",
      "Epoch [3250/5000], Loss: 0.1979, Accuracy: 0.9388\n",
      "Epoch [3500/5000], Loss: 0.1929, Accuracy: 0.9402\n",
      "Epoch [3750/5000], Loss: 0.1885, Accuracy: 0.9412\n",
      "Epoch [4000/5000], Loss: 0.1844, Accuracy: 0.9418\n",
      "Test Accuracy: 0.8092\n",
      "Epoch [4250/5000], Loss: 0.1807, Accuracy: 0.9428\n",
      "Epoch [4500/5000], Loss: 0.1773, Accuracy: 0.9437\n",
      "Epoch [4750/5000], Loss: 0.1742, Accuracy: 0.9445\n",
      "Epoch [5000/5000], Loss: 0.1714, Accuracy: 0.9452\n",
      "Test Accuracy: 0.8060\n",
      "Test Accuracy: 0.8060\n",
      "Layer blocks5 - PCA time: 1.47s, PCA transform time: 10.87s, Training time: 37.51s\n",
      "Processing layer: blocks11\n",
      "PCA components for layer blocks11: U shape torch.Size([120000, 1024]), S shape torch.Size([1024]), V shape torch.Size([31104, 1024])\n",
      "Epoch [1/5000], Loss: 3.8648, Accuracy: 0.0236\n",
      "Epoch [250/5000], Loss: 0.0156, Accuracy: 1.0000\n",
      "Epoch [500/5000], Loss: 0.0068, Accuracy: 1.0000\n",
      "Epoch [750/5000], Loss: 0.0040, Accuracy: 1.0000\n",
      "Epoch [1000/5000], Loss: 0.0027, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9855\n",
      "Epoch [1250/5000], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [1500/5000], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [1750/5000], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [2000/5000], Loss: 0.0009, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9852\n",
      "Epoch [2250/5000], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [2500/5000], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [2750/5000], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [3000/5000], Loss: 0.0004, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9853\n",
      "Epoch [3250/5000], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [3500/5000], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [3750/5000], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [4000/5000], Loss: 0.0002, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9850\n",
      "Epoch [4250/5000], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [4500/5000], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [4750/5000], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [5000/5000], Loss: 0.0001, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9848\n",
      "Test Accuracy: 0.9848\n",
      "Layer blocks11 - PCA time: 1.48s, PCA transform time: 10.88s, Training time: 37.44s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_col, feature_col_test, y_train, y_test,\n",
    "    PC_dim=1024, noPCA=False, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avg_col = {k: v.mean(dim=1) for k, v in feature_col.items()}\n",
    "feature_avg_col_test = {k: v.mean(dim=1) for k, v in feature_col_test.items()}\n",
    "feature_last_col = {k: v[:, -1] for k, v in feature_col.items()}\n",
    "feature_last_col_test = {k: v[:, -1] for k, v in feature_col_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8335, Accuracy: 0.0252\n",
      "Epoch [250/5000], Loss: 0.4078, Accuracy: 0.8794\n",
      "Epoch [500/5000], Loss: 0.3108, Accuracy: 0.9030\n",
      "Epoch [750/5000], Loss: 0.2676, Accuracy: 0.9140\n",
      "Epoch [1000/5000], Loss: 0.2415, Accuracy: 0.9203\n",
      "Test Accuracy: 0.9056\n",
      "Epoch [1250/5000], Loss: 0.2235, Accuracy: 0.9251\n",
      "Epoch [1500/5000], Loss: 0.2100, Accuracy: 0.9286\n",
      "Epoch [1750/5000], Loss: 0.1995, Accuracy: 0.9311\n",
      "Epoch [2000/5000], Loss: 0.1910, Accuracy: 0.9337\n",
      "Test Accuracy: 0.9148\n",
      "Epoch [2250/5000], Loss: 0.1838, Accuracy: 0.9360\n",
      "Epoch [2500/5000], Loss: 0.1778, Accuracy: 0.9380\n",
      "Epoch [2750/5000], Loss: 0.1727, Accuracy: 0.9393\n",
      "Epoch [3000/5000], Loss: 0.1679, Accuracy: 0.9409\n",
      "Test Accuracy: 0.9181\n",
      "Epoch [3250/5000], Loss: 0.1638, Accuracy: 0.9421\n",
      "Epoch [3500/5000], Loss: 0.1601, Accuracy: 0.9432\n",
      "Epoch [3750/5000], Loss: 0.1568, Accuracy: 0.9442\n",
      "Epoch [4000/5000], Loss: 0.1538, Accuracy: 0.9449\n",
      "Test Accuracy: 0.9201\n",
      "Epoch [4250/5000], Loss: 0.1510, Accuracy: 0.9458\n",
      "Epoch [4500/5000], Loss: 0.1484, Accuracy: 0.9466\n",
      "Epoch [4750/5000], Loss: 0.1461, Accuracy: 0.9471\n",
      "Epoch [5000/5000], Loss: 0.1440, Accuracy: 0.9480\n",
      "Test Accuracy: 0.9210\n",
      "Test Accuracy: 0.9210\n",
      "Layer blocks5 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.19s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.7965, Accuracy: 0.0383\n",
      "Epoch [250/5000], Loss: 0.0425, Accuracy: 0.9942\n",
      "Epoch [500/5000], Loss: 0.0224, Accuracy: 0.9970\n",
      "Epoch [750/5000], Loss: 0.0149, Accuracy: 0.9981\n",
      "Epoch [1000/5000], Loss: 0.0109, Accuracy: 0.9989\n",
      "Test Accuracy: 0.9958\n",
      "Epoch [1250/5000], Loss: 0.0084, Accuracy: 0.9993\n",
      "Epoch [1500/5000], Loss: 0.0067, Accuracy: 0.9995\n",
      "Epoch [1750/5000], Loss: 0.0054, Accuracy: 0.9997\n",
      "Epoch [2000/5000], Loss: 0.0045, Accuracy: 0.9998\n",
      "Test Accuracy: 0.9962\n",
      "Epoch [2250/5000], Loss: 0.0038, Accuracy: 0.9998\n",
      "Epoch [2500/5000], Loss: 0.0032, Accuracy: 0.9999\n",
      "Epoch [2750/5000], Loss: 0.0027, Accuracy: 1.0000\n",
      "Epoch [3000/5000], Loss: 0.0024, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9964\n",
      "Epoch [3250/5000], Loss: 0.0020, Accuracy: 1.0000\n",
      "Epoch [3500/5000], Loss: 0.0018, Accuracy: 1.0000\n",
      "Epoch [3750/5000], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [4000/5000], Loss: 0.0014, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9964\n",
      "Epoch [4250/5000], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [4500/5000], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [4750/5000], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [5000/5000], Loss: 0.0008, Accuracy: 1.0000\n",
      "Test Accuracy: 0.9964\n",
      "Test Accuracy: 0.9964\n",
      "Layer blocks11 - PCA time: 0.01s, PCA transform time: 0.08s, Training time: 32.11s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_avg_col, feature_avg_col_test, y_train, y_test,\n",
    "    PC_dim=None, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: blocks5\n",
      "Epoch [1/5000], Loss: 3.8476, Accuracy: 0.0271\n",
      "Epoch [250/5000], Loss: 1.0351, Accuracy: 0.6681\n",
      "Epoch [500/5000], Loss: 0.9538, Accuracy: 0.6896\n",
      "Epoch [750/5000], Loss: 0.9183, Accuracy: 0.6993\n",
      "Epoch [1000/5000], Loss: 0.8973, Accuracy: 0.7046\n",
      "Test Accuracy: 0.6678\n",
      "Epoch [1250/5000], Loss: 0.8832, Accuracy: 0.7091\n",
      "Epoch [1500/5000], Loss: 0.8731, Accuracy: 0.7115\n",
      "Epoch [1750/5000], Loss: 0.8656, Accuracy: 0.7138\n",
      "Epoch [2000/5000], Loss: 0.8597, Accuracy: 0.7158\n",
      "Test Accuracy: 0.6763\n",
      "Epoch [2250/5000], Loss: 0.8551, Accuracy: 0.7173\n",
      "Epoch [2500/5000], Loss: 0.8513, Accuracy: 0.7181\n",
      "Epoch [2750/5000], Loss: 0.8483, Accuracy: 0.7189\n",
      "Epoch [3000/5000], Loss: 0.8456, Accuracy: 0.7197\n",
      "Test Accuracy: 0.6792\n",
      "Epoch [3250/5000], Loss: 0.8433, Accuracy: 0.7204\n",
      "Epoch [3500/5000], Loss: 0.8414, Accuracy: 0.7210\n",
      "Epoch [3750/5000], Loss: 0.8397, Accuracy: 0.7213\n",
      "Epoch [4000/5000], Loss: 0.8383, Accuracy: 0.7215\n",
      "Test Accuracy: 0.6798\n",
      "Epoch [4250/5000], Loss: 0.8373, Accuracy: 0.7216\n",
      "Epoch [4500/5000], Loss: 0.8360, Accuracy: 0.7223\n",
      "Epoch [4750/5000], Loss: 0.8350, Accuracy: 0.7224\n",
      "Epoch [5000/5000], Loss: 0.8342, Accuracy: 0.7227\n",
      "Test Accuracy: 0.6806\n",
      "Test Accuracy: 0.6806\n",
      "Layer blocks5 - PCA time: 0.02s, PCA transform time: 0.09s, Training time: 31.73s\n",
      "Processing layer: blocks11\n",
      "Epoch [1/5000], Loss: 3.8716, Accuracy: 0.0267\n",
      "Epoch [250/5000], Loss: 0.2838, Accuracy: 0.9292\n",
      "Epoch [500/5000], Loss: 0.2142, Accuracy: 0.9432\n",
      "Epoch [750/5000], Loss: 0.1852, Accuracy: 0.9498\n",
      "Epoch [1000/5000], Loss: 0.1683, Accuracy: 0.9539\n",
      "Test Accuracy: 0.9269\n",
      "Epoch [1250/5000], Loss: 0.1570, Accuracy: 0.9565\n",
      "Epoch [1500/5000], Loss: 0.1486, Accuracy: 0.9585\n",
      "Epoch [1750/5000], Loss: 0.1421, Accuracy: 0.9599\n",
      "Epoch [2000/5000], Loss: 0.1369, Accuracy: 0.9610\n",
      "Test Accuracy: 0.9266\n",
      "Epoch [2250/5000], Loss: 0.1326, Accuracy: 0.9621\n",
      "Epoch [2500/5000], Loss: 0.1290, Accuracy: 0.9631\n",
      "Epoch [2750/5000], Loss: 0.1259, Accuracy: 0.9637\n",
      "Epoch [3000/5000], Loss: 0.1232, Accuracy: 0.9643\n",
      "Test Accuracy: 0.9252\n",
      "Epoch [3250/5000], Loss: 0.1209, Accuracy: 0.9649\n",
      "Epoch [3500/5000], Loss: 0.1188, Accuracy: 0.9653\n",
      "Epoch [3750/5000], Loss: 0.1169, Accuracy: 0.9658\n",
      "Epoch [4000/5000], Loss: 0.1153, Accuracy: 0.9662\n",
      "Test Accuracy: 0.9240\n",
      "Epoch [4250/5000], Loss: 0.1138, Accuracy: 0.9666\n",
      "Epoch [4500/5000], Loss: 0.1124, Accuracy: 0.9668\n",
      "Epoch [4750/5000], Loss: 0.1112, Accuracy: 0.9670\n",
      "Epoch [5000/5000], Loss: 0.1101, Accuracy: 0.9673\n",
      "Test Accuracy: 0.9223\n",
      "Test Accuracy: 0.9223\n",
      "Layer blocks11 - PCA time: 0.02s, PCA transform time: 0.09s, Training time: 31.75s\n"
     ]
    }
   ],
   "source": [
    "model_PCA_col, PC_proj_col, results_col = train_pca_sgd_classifiers(\n",
    "    feature_last_col, feature_last_col_test, y_train, y_test,\n",
    "    PC_dim=512, noPCA=True, num_classes=40, batch_size=None,\n",
    "    num_epochs=5000, print_every=250, eval_every=1000, learning_rate=0.005,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMap and repr similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "# Define a discrete colormap\n",
    "cmap = ListedColormap(['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf','#999999', '#d000d0'])\n",
    "row_table = {\n",
    "    0: \"Constant\",\n",
    "    1: \"Prog. neg 2\",\n",
    "    2: \"Prog. neg 1\",\n",
    "    3: \"Prog. pos 1\",\n",
    "    4: \"Prog. pos 2\",\n",
    "    5: \"Arith. pos\",\n",
    "    6: \"Arith. neg\",\n",
    "    7: \"XOR\",\n",
    "    8: \"OR\",\n",
    "    9: \"AND\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 384])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_avg_col_test[\"blocks11\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming features is your feature matrix and labels is your label array\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(feature_avg_col_test[\"blocks11\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rela_test = (y_test % 10) \n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=rela_test, cmap=cmap, s=5, alpha=0.5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "cb = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "cb.set_ticks(np.arange(10))#boundaries=np.arange(41)-0.5).set_ticks(np.arange(40))\n",
    "cb.set_ticklabels([row_table[i] for i in range(10)])\n",
    "plt.title('UMAP projection of the dataset (abstract relation)', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_test = (y_test//10) + (y_test > 36).int()\n",
    "cmap = ListedColormap(sns.color_palette(\"Spectral\", 6))\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=attr_test, cmap=cmap, s=5, alpha=0.5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "cb = plt.colorbar(boundaries=np.arange(6)-0.5)\n",
    "cb.set_ticks(np.arange(5),)#[\"shape\",\"size\",\"color\",\"number\",\"position\"])\n",
    "cb.set_ticklabels([\"shape\",\"size\",\"color\",\"number\",\"position\"], fontsize=12)\n",
    "plt.title('UMAP projection of the dataset (attribute)', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSA structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "layername = \"blocks11\"#\"dec.1x1_in1\"#\"dec.3x3_up\";#\"dec.1x1_in1\" # \"enc.1x1_down\"\n",
    "# Compute the cosine similarity matrix\n",
    "featmatr = feature_avg_col_test[layername].flatten(start_dim=1)#.squeeze()\n",
    "feat_shape = feature_avg_col_test[layername].shape[1:]\n",
    "feat_mean = featmatr.mean(dim=0)\n",
    "feat_cent = featmatr - feat_mean[None, :]\n",
    "featmat_sparse = feat_cent[::5,:]\n",
    "cosine_sim_matrix = cosine_similarity(featmat_sparse)\n",
    "# print(cosine_sim_matrix)\n",
    "n = cosine_sim_matrix.shape[0]\n",
    "reshaped = cosine_sim_matrix.reshape(40, n//40, 40, n//40)\n",
    "coarse_grained_matrix = reshaped.mean(axis=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_ids = heldout_rules\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(coarse_grained_matrix, annot=False, cmap='coolwarm', \n",
    "            xticklabels=True, yticklabels=True)\n",
    "for sep in [10,20,30]:\n",
    "    plt.axhline(sep, color=\"r\", linestyle=\":\")\n",
    "    plt.axvline(sep, color=\"r\", linestyle=\":\")\n",
    "xticks = plt.gca().get_xticklabels()\n",
    "yticks = plt.gca().get_yticklabels()\n",
    "for i, xtick in enumerate(xticks):\n",
    "    if i in heldout_ids:  # Change color of every 10th xtick label\n",
    "        xtick.set_color('red')\n",
    "for i, ytick in enumerate(yticks):\n",
    "    if i in heldout_ids:  # Change color of every 10th ytick label\n",
    "        ytick.set_color('red')\n",
    "plt.axis(\"image\")\n",
    "plt.title(f\"Cosine similarity matrix of {layername} features ({tuple(feat_shape)}) (coarse-grained)\\n{expname}\") #  (red=held-out)\n",
    "# saveallforms(fig_expdir, f\"cosine_sim_{layername}_t{t_str}\",)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
