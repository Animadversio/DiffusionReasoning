{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/mini_edm\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionReasoning\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiT\")\n",
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch as th\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "plt.rcParams['figure.edgecolor'] = (1, 1, 1, 0)\n",
    "plt.rcParams['figure.facecolor'] = (1, 1, 1, 0)\n",
    "# vector graphics type\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "from train_edm import create_model, edm_sampler, EDM\n",
    "from edm_utils import edm_sampler_inpaint, create_edm, get_default_config, create_edm_new, edm_sampler_stoch\n",
    "from dataset_utils import train_data2attr_tsr,load_raw_data,load_PGM_abstract\n",
    "from rule_new_utils import check_r3_r2_batch, infer_rule_from_sample_batch, compute_rule_statistics\n",
    "import circuit_toolkit\n",
    "from circuit_toolkit.layer_hook_utils import print_specific_layer, get_module_name_shapes, featureFetcher_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_20240711-0204\n",
      "BaseBlnr_RAVEN10_abstract_20240212-2142\n",
      "BaseBlnr_RAVEN10_abstract_onehot_20240212-2143\n",
      "BaseBlnrX3_new_RAVEN10_abstract_20240313-1736\n",
      "BaseBlnrX3_new_RAVEN10_abstract_onehot_20240313-1736\n",
      "BaseBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240921-2218\n",
      "BaseBlnrX3_new_stream0_16M_RAVEN10_abstract_20240921-2218\n",
      "base_cifar10_20240130-2317\n",
      "base_cifar10_20240130-2318\n",
      "base_gabor_prime_20240130-2251\n",
      "base_gabor_sf_20240130-2306\n",
      "base_mnist_20240129-1342\n",
      "base_mnist_20240129-1406\n",
      "base_mnist_20240130-2207\n",
      "base_RAVEN10_20240131-2049\n",
      "base_RAVEN10_abstract_20240201-0036\n",
      "Base_RAVEN10_abstract_20240212-2139\n",
      "base_RAVEN10_abstract_onehot_20240201-0147\n",
      "Base_RAVEN10_abstract_onehot_20240212-2140\n",
      "BBigBlnrX3_new_RAVEN10_abstract_20240313-1809\n",
      "BBigBlnrX3_new_RAVEN10_abstract_onehot_20240313-1810\n",
      "BBigBlnrX3_new_RAVEN10_abstract_onehot_20240314-0112\n",
      "BBigBlnrX3_RAVEN10_abstract_20240305-2341\n",
      "BigBlnrlrsm_RAVEN10_abstract_onehot_20240209-1411\n",
      "BigBlnr_RAVEN10_abstract_20240208-1709\n",
      "BigBlnr_RAVEN10_abstract_onehot_20240209-0208\n",
      "BigBlnrX3_new_RAVEN10_abstract_20240313-1753\n",
      "BigBlnrX3_new_RAVEN10_abstract_20240315-1328\n",
      "BigBlnrX3_new_RAVEN10_abstract_20240412-0143\n",
      "BigBlnrX3_new_RAVEN10_abstract_onehot_20240313-1754\n",
      "BigBlnrX3_new_RAVEN10_abstract_onehot_20240315-1328\n",
      "BigBlnrX3_new_RAVEN10_abstract_onehot_20240412-0143\n",
      "BigBlnrX3_new_stream0_016M_heldout0_RAVEN10_abstract_20240816-0104\n",
      "BigBlnrX3_new_stream0_016M_RAVEN10_abstract_20240816-0104\n",
      "BigBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240708-2052\n",
      "BigBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240708-2308\n",
      "BigBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240709-1249\n",
      "BigBlnrX3_new_stream0_16M_RAVEN10_abstract_20240828-1332\n",
      "BigBlnrX3_new_stream0_48M_heldout0_RAVEN10_abstract_20240708-2052\n",
      "BigBlnrX3_new_stream0_48M_heldout0_RAVEN10_abstract_20240708-2314\n",
      "BigBlnrX3_new_stream0_48M_heldout0_RAVEN10_abstract_20240709-1249\n",
      "BigBlnrX3_new_stream0_48M_RAVEN10_abstract_20240828-1332\n",
      "BigBlnrX3_new_stream16M_heldout0_RAVEN10_abstract_20240708-2052\n",
      "BigBlnrX3_new_stream1_6M_heldout0_RAVEN10_abstract_20240708-2052\n",
      "BigBlnrX3_new_stream16M_RAVEN10_abstract_20240705-0237\n",
      "BigBlnrX3_new_stream1_6M_RAVEN10_abstract_20240705-1903\n",
      "BigBlnrX3_new_stream4_8M_heldout0_RAVEN10_abstract_20240708-2052\n",
      "BigBlnrX3_new_stream4_8M_RAVEN10_abstract_20240705-1903\n",
      "BigBlnrX3_RAVEN10_abstract_20240305-2338\n",
      "Big_RAVEN10_abstract_20240207-1925\n",
      "Big_RAVEN10_abstract_onehot_20240207-1925\n",
      "WideBlnr_RAVEN10_abstract_20240211-1747\n",
      "WideBlnr_RAVEN10_abstract_onehot_20240211-1743\n",
      "WideBlnrX3_new_noattn_RAVEN10_abstract_20240412-1254\n",
      "WideBlnrX3_new_RAVEN10_abstract_20240313-1737\n",
      "WideBlnrX3_new_RAVEN10_abstract_20240315-1327\n",
      "WideBlnrX3_new_RAVEN10_abstract_20240412-0143\n",
      "WideBlnrX3_new_RAVEN10_abstract_20240412-1347\n",
      "WideBlnrX3_new_RAVEN10_abstract_20240704-1713\n",
      "WideBlnrX3_new_RAVEN10_abstract_onehot_20240313-1737\n",
      "WideBlnrX3_new_RAVEN10_abstract_onehot_20240315-1328\n",
      "WideBlnrX3_new_stream0_016M_heldout0_RAVEN10_abstract_20240816-0105\n",
      "WideBlnrX3_new_stream0_016M_RAVEN10_abstract_20240816-0105\n",
      "WideBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240708-2054\n",
      "WideBlnrX3_new_stream0_16M_RAVEN10_abstract_20240705-1908\n",
      "WideBlnrX3_new_stream0_48M_heldout0_RAVEN10_abstract_20240708-2054\n",
      "WideBlnrX3_new_stream0_48M_RAVEN10_abstract_20240705-1908\n",
      "WideBlnrX3_new_stream16M_heldout0_RAVEN10_abstract_20240708-2054\n",
      "WideBlnrX3_new_stream1_6M_heldout0_RAVEN10_abstract_20240708-2054\n",
      "WideBlnrX3_new_stream16M_RAVEN10_abstract_20240705-0023\n",
      "WideBlnrX3_new_stream1_6M_RAVEN10_abstract_20240705-1908\n",
      "WideBlnrX3_new_stream4_8M_heldout0_RAVEN10_abstract_20240708-2054\n",
      "WideBlnrX3_new_stream4_8M_heldout0_RAVEN10_abstract_20240708-2207\n",
      "WideBlnrX3_new_stream4_8M_heldout0_RAVEN10_abstract_20240709-1249\n",
      "WideBlnrX3_new_stream4_8M_RAVEN10_abstract_20240705-1908\n",
      "WideBlnrX3_new_stream4_8M_RAVEN10_abstract_20240921-2016\n",
      "WideBlnrX3_RAVEN10_abstract_20240305-2336\n",
      "Wide_RAVEN10_abstract_20240206-2323\n",
      "Wide_RAVEN10_abstract_onehot_20240206-2324\n"
     ]
    }
   ],
   "source": [
    "!ls {exproot}\n",
    "!rm -r {exproot}/090*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ckpt0999999EMA: from /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/mini_edm/exps/WideBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240708-2054/checkpoints/ema_999999.pth, use_ema: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_mapping = {\n",
    "    \"BaseBlnrX3\" : dict(layers_per_block=1, model_channels=64, channel_mult=[1, 2, 4], attn_resolutions=[9, 3], spatial_matching=\"bilinear\"),\n",
    "    \"WideBlnrX3\" : dict(layers_per_block=2, model_channels=128, channel_mult=[1, 2, 4], attn_resolutions=[9, 3], spatial_matching=\"bilinear\"),\n",
    "    \"BigBlnrX3\"  : dict(layers_per_block=3, model_channels=192, channel_mult=[1, 2, 4], attn_resolutions=[9, 3], spatial_matching=\"bilinear\"),\n",
    "}\n",
    "\n",
    "import json \n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--expname\", type=str, default=\"090-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_20240711-0204\")\n",
    "# parser.add_argument(\"--epoch\", type=int, default=999999)\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=2048)\n",
    "# parser.add_argument(\"--reps\", type=int, default=10)\n",
    "# args = parser.parse_args()\n",
    "expname = r\"WideBlnrX3_new_stream0_16M_heldout0_RAVEN10_abstract_20240708-2054\"\n",
    "epoch = 999999 #1000000\n",
    "batch_size = 2048\n",
    "reps = 10\n",
    "# expname = args.expname\n",
    "# epoch = args.epoch\n",
    "# batch_size = args.batch_size\n",
    "# reps = args.reps\n",
    "device = \"cuda\"\n",
    "train_steps = epoch\n",
    "\n",
    "DATASET = \"RAVEN10_abstract\"\n",
    "use_ema = True\n",
    "exproot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/mini_edm/exps\"\n",
    "expdir = join(exproot, expname)\n",
    "ckptdir = join(expdir, \"checkpoints\")\n",
    "savedir = join(expdir, \"uncond_samples\")\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "model_scale = expname.split(\"_\")[0]\n",
    "config_ft = get_default_config(DATASET, **config_mapping[model_scale])\n",
    "if epoch == -1:\n",
    "    edm, model_EDM = create_edm_new(None, config_ft, device) \n",
    "    ckpt_str = \"ckptRNDINIT\"\n",
    "    print(\"Random initialization\")\n",
    "else:\n",
    "    ckpt_path = join(ckptdir, f\"ema_{epoch}.pth\")\n",
    "    edm, model_EDM = create_edm_new(ckpt_path, config_ft, device) \n",
    "    ckpt_str = f\"ckpt{epoch:07d}EMA\"\n",
    "    print(f\"Loaded {ckpt_str}: from {ckpt_path}, use_ema: {use_ema}\")\n",
    "    \n",
    "dataset_Xmean = th.tensor([1.5, 2.5, 2.5]).view(1, 3, 1, 1).to(\"cuda\")\n",
    "dataset_Xstd = th.tensor([2.5, 3.5, 3.5]).view(1, 3, 1, 1).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edm.ema.to(device).eval()\n",
    "edm.model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "@torch.no_grad()\n",
    "def edm_sampler_stoch(\n",
    "    net, latents, class_labels=None, randn_like=torch.randn_like,\n",
    "    num_steps=18, sigma_min=0.002, sigma_max=80, rho=7,\n",
    "    S_churn=0, S_min=0, S_max=float('inf'), S_noise=1,\n",
    "):\n",
    "    # Adjust noise levels based on what's supported by the network.\n",
    "    sigma_min = max(sigma_min, net.sigma_min)\n",
    "    sigma_max = min(sigma_max, net.sigma_max)\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=torch.float64, device=latents.device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([net.round_sigma(t_steps), torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    x_next = latents.to(torch.float64) * t_steps[0]\n",
    "    for i, (t_cur, t_next) in tqdm(enumerate(zip(t_steps[:-1], t_steps[1:]))): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        gamma = min(S_churn / num_steps, np.sqrt(2) - 1) if S_min <= t_cur <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_cur + gamma * t_cur)\n",
    "        x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * randn_like(x_cur)\n",
    "\n",
    "        # Euler step.\n",
    "        denoised = net(x_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (x_hat - denoised) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if i < num_steps - 1:\n",
    "            denoised = net(x_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (x_next - denoised) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return x_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with Heun5...rep0\n",
      "C3: 0/2048 (0.00), C3 + C2: 24/2048 (0.01), AnyValid: 1065/6144 (0.17)\n",
      "Sampling with Heun10...rep0\n",
      "C3: 607/2048 (0.30), C3 + C2: 1063/2048 (0.52), AnyValid: 3832/6144 (0.62)\n",
      "Sampling with Heun20...rep0\n",
      "C3: 903/2048 (0.44), C3 + C2: 1340/2048 (0.65), AnyValid: 4385/6144 (0.71)\n",
      "Sampling with Heun50...rep0\n",
      "C3: 970/2048 (0.47), C3 + C2: 1409/2048 (0.69), AnyValid: 4468/6144 (0.73)\n",
      "Sampling with Heun100...rep0\n",
      "C3: 976/2048 (0.48), C3 + C2: 1420/2048 (0.69), AnyValid: 4489/6144 (0.73)\n",
      "Sampling with Heun200...rep0\n",
      "C3: 972/2048 (0.47), C3 + C2: 1421/2048 (0.69), AnyValid: 4488/6144 (0.73)\n",
      "Sampling with Heun500...rep0\n",
      "C3: 972/2048 (0.47), C3 + C2: 1421/2048 (0.69), AnyValid: 4486/6144 (0.73)\n",
      "Sampling with Heun1000...rep0\n",
      "C3: 972/2048 (0.47), C3 + C2: 1421/2048 (0.69), AnyValid: 4485/6144 (0.73)\n"
     ]
    }
   ],
   "source": [
    "# Now, let's do the same for the SDE DDPM sampling\n",
    "for rep in range(1):\n",
    "    for steps in [5, 10, 20, 50, 100, 200, 500, 1000]:\n",
    "        print(f\"Sampling with Heun{steps}...rep{rep}\")\n",
    "        noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device='cuda').manual_seed(rep))\n",
    "        samples = edm_sampler(edm, noise, num_steps=steps).detach()\n",
    "        samples = edm_sampler_stoch(edm, noise, num_steps=steps,).detach()\n",
    "        samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "        r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "        C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)\n",
    "        torch.save(samples, f\"{savedir}/{train_steps:07d}_Heun{steps}_rep{rep}.pt\")\n",
    "        torch.save({'c3_list': r3_list, 'c2_list': r2_list, 'rule_col': rule_col, \n",
    "                'c3_cnt': C3_count, 'c2_cnt': C2_count, 'anyvalid_cnt': anyvalid_count, 'total': total},\n",
    "                            f'{savedir}/sample_rule_eval_{train_steps}_Heun{steps}_rep{rep}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with Heun5...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aed63c93544f3c82302da7eb517c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 0/2048 (0.00), C3 + C2: 35/2048 (0.02), AnyValid: 1065/6144 (0.17)\n",
      "Sampling with Heun10...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbec26d009343e7b6d4fb44dc7d7367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 392/2048 (0.19), C3 + C2: 856/2048 (0.42), AnyValid: 3372/6144 (0.55)\n",
      "Sampling with Heun20...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed8dc8dd5294199bee04a82af6a5c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 892/2048 (0.44), C3 + C2: 1294/2048 (0.63), AnyValid: 4289/6144 (0.70)\n",
      "Sampling with Heun50...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca595fa8dfea4a0ab2f85afeeebc5de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1086/2048 (0.53), C3 + C2: 1431/2048 (0.70), AnyValid: 4531/6144 (0.74)\n",
      "Sampling with Heun100...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8965f6705a942ae884e5dbd0a42caba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1177/2048 (0.57), C3 + C2: 1460/2048 (0.71), AnyValid: 4586/6144 (0.75)\n",
      "Sampling with Heun200...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bc767d444f4a849f0f7e66de410f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1250/2048 (0.61), C3 + C2: 1506/2048 (0.74), AnyValid: 4719/6144 (0.77)\n",
      "Sampling with Heun500...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d510a33f09c4578a66cdc0feae423ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1274/2048 (0.62), C3 + C2: 1536/2048 (0.75), AnyValid: 4723/6144 (0.77)\n",
      "Sampling with Heun1000...rep0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb96b35af149fda4bf7b45301176af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stoch_kwargs = dict(S_churn=40, S_min=0.05, S_max=50, S_noise=1.003)\n",
    "stoch_str = \"_\".join([f\"{k}{v}\" for k, v in stoch_kwargs.items()])\n",
    "# Now, let's do the same for the SDE DDPM sampling\n",
    "for rep in range(1):\n",
    "    for steps in [5, 10, 20, 50, 100, 200, 500, 1000]:\n",
    "        print(f\"Sampling with Heun{steps}...rep{rep}\")\n",
    "        noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device='cuda').manual_seed(rep))\n",
    "        samples = edm_sampler_stoch(edm, noise, num_steps=steps,\n",
    "                                    **stoch_kwargs).detach()\n",
    "        samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "        r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "        C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)\n",
    "        torch.save(samples, f\"{savedir}/{train_steps:07d}_HeunStoch{steps}_{stoch_str}_rep{rep}.pt\")\n",
    "        torch.save({'c3_list': r3_list, 'c2_list': r2_list, 'rule_col': rule_col, \n",
    "                'c3_cnt': C3_count, 'c2_cnt': C2_count, 'anyvalid_cnt': anyvalid_count, 'total': total},\n",
    "                            f'{savedir}/sample_rule_eval_{train_steps}_HeunStoch{steps}_{stoch_str}_rep{rep}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edm.ema.to(device).eval()\n",
    "edm.model.to(device).eval()\n",
    "# Now, let's do the same for the SDE DDPM sampling\n",
    "for rep in range(1):\n",
    "    for steps in [5, 10, 20, 50, 100, 200, 500, 1000]:\n",
    "        print(f\"Sampling with Heun{steps}...rep{rep}\")\n",
    "        noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device='cuda').manual_seed(rep))\n",
    "        samples = edm_sampler_stoch(edm, noise, num_steps=steps,).detach()\n",
    "        samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "        r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "        C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)\n",
    "        torch.save(samples, f\"{savedir}/{train_steps:07d}_Heun{steps}_rep{rep}.pt\")\n",
    "        torch.save({'c3_list': r3_list, 'c2_list': r2_list, 'rule_col': rule_col, \n",
    "                'c3_cnt': C3_count, 'c2_cnt': C2_count, 'anyvalid_cnt': anyvalid_count, 'total': total},\n",
    "                            f'{savedir}/sample_rule_eval_{train_steps}_Heun{steps}_rep{rep}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
