{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load multiple DiT models of different random seed. \n",
    "* compare weights? should not be the same \n",
    "* compar linkage from initial noise to final outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/mini_edm\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionReasoning\")\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch as th\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = [6.0, 4.0]\n",
    "plt.rcParams['figure.edgecolor'] = (1, 1, 1, 0)\n",
    "plt.rcParams['figure.facecolor'] = (1, 1, 1, 0)\n",
    "# vector graphics type\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "# from train_edm import create_model, edm_sampler, EDM\n",
    "# from edm_utils import edm_sampler_inpaint, create_edm, get_default_config\n",
    "# from rule_utils import get_rule_img, get_obj_list, get_rule_list\n",
    "# from rule_utils import check_consistent\n",
    "from dataset_utils import train_data2attr_tsr,load_raw_data,load_PGM_abstract\n",
    "from rule_new_utils import check_r3_r2_batch, infer_rule_from_sample_batch, compute_rule_statistics\n",
    "import circuit_toolkit\n",
    "from circuit_toolkit.layer_hook_utils import print_specific_layer, get_module_name_shapes, featureFetcher_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# abstract RAVEN dataset\n",
    "dataset_Xmean = th.tensor([1.5, 2.5, 2.5]).view(1, 3, 1, 1).to(\"cuda\")\n",
    "dataset_Xstd = th.tensor([2.5, 3.5, 3.5]).view(1, 3, 1, 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiT_exproot = '/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/DiT/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1600\n",
      "110-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1600\n",
      "111-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601\n",
      "111-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601\n",
      "112-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601\n",
      "113-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601\n"
     ]
    }
   ],
   "source": [
    "!ls -d $DiT_exproot/*rep* | xargs -n 1 basename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expnames = [\n",
    "    \"109-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1600\",\n",
    "    \"111-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601\",\n",
    "    \"113-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601\",\n",
    "    \"110-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1600\",\n",
    "    \"111-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601\",\n",
    "    \"112-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import create_diffusion\n",
    "from models import DiT\n",
    "\n",
    "DiT_configs = {\n",
    "    \"DiT_XL_1\": {\"depth\": 28, \"hidden_size\": 1152, \"patch_size\": 1, \"num_heads\": 16},\n",
    "    \"DiT_XL_3\": {\"depth\": 28, \"hidden_size\": 1152, \"patch_size\": 3, \"num_heads\": 16},\n",
    "    \"DiT_L_1\": {\"depth\": 24, \"hidden_size\": 1024, \"patch_size\": 1, \"num_heads\": 16},\n",
    "    \"DiT_L_3\": {\"depth\": 24, \"hidden_size\": 1024, \"patch_size\": 3, \"num_heads\": 16},\n",
    "    \"DiT_B_1\": {\"depth\": 12, \"hidden_size\": 768, \"patch_size\": 1, \"num_heads\": 12},\n",
    "    \"DiT_B_3\": {\"depth\": 12, \"hidden_size\": 768, \"patch_size\": 3, \"num_heads\": 12},\n",
    "    \"DiT_S_1\": {\"depth\": 12, \"hidden_size\": 384, \"patch_size\": 1, \"num_heads\": 6},\n",
    "    \"DiT_S_3\": {\"depth\": 12, \"hidden_size\": 384, \"patch_size\": 3, \"num_heads\": 6},\n",
    "}\n",
    "\n",
    "def load_DiT_model(expname, ckpt_step, use_ema=True, \n",
    "                   cfg = \"DiT_S_1\",\n",
    "                   class_dropout_prob = 1.0,\n",
    "                   num_classes = 0):\n",
    "    model_cfg = DiT_configs[cfg]\n",
    "    model_DiT = DiT(input_size=9,\n",
    "                in_channels=3, **model_cfg,\n",
    "                mlp_ratio=4.0,\n",
    "                class_dropout_prob=class_dropout_prob,\n",
    "                num_classes=num_classes,\n",
    "                learn_sigma=True,)\n",
    "\n",
    "    expdir = join(DiT_exproot, expname)\n",
    "    ckptdir = join(expdir, \"checkpoints\")\n",
    "    ckpt_path = join(ckptdir, f\"{ckpt_step}.pt\")\n",
    "    state_dict = th.load(ckpt_path)\n",
    "    model_DiT.load_state_dict(state_dict['ema' if use_ema else 'model'])\n",
    "    model_DiT.to(\"cuda\").eval()\n",
    "    return model_DiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DiT = load_DiT_model(expnames[0], 1000000, use_ema=True, cfg=\"DiT_S_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a963aa29ab2e450c93ed0572ab0a530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 337/512 (0.66), C3 + C2: 393/512 (0.77), AnyValid: 1222/1536 (0.80)\n"
     ]
    }
   ],
   "source": [
    "diffusion_eval = create_diffusion(timestep_respacing=\"ddim100\")  # default: ddim100\n",
    "batch_size = 512\n",
    "noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device=\"cuda\").manual_seed(0))\n",
    "y = th.zeros(batch_size, dtype=torch.int, device=\"cuda\")\n",
    "model_kwargs = dict(y=y)\n",
    "with th.no_grad():\n",
    "    samples = diffusion_eval.ddim_sample_loop(model_DiT, noise=noise, shape=(batch_size, 3, 9, 9), clip_denoised=False, device=\"cuda\", model_kwargs=model_kwargs, progress=True)\n",
    "samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the reproducibility across training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DiT1 = load_DiT_model(expnames[1], 1000000, use_ema=True, cfg=\"DiT_S_1\")\n",
    "model_DiT2 = load_DiT_model(expnames[2], 1000000, use_ema=True, cfg=\"DiT_S_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0047ab44d01452fa2f0442a65537ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 6505/10240 (0.64), C3 + C2: 7645/10240 (0.75), AnyValid: 23763/30720 (0.77)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95179218e7ba454c86a215fa555ce8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 6564/10240 (0.64), C3 + C2: 7773/10240 (0.76), AnyValid: 24021/30720 (0.78)\n"
     ]
    }
   ],
   "source": [
    "diffusion_eval = create_diffusion(timestep_respacing=\"ddim100\")  # default: ddim100\n",
    "\n",
    "batch_size = 2048 * 5\n",
    "noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device=\"cuda\").manual_seed(42))\n",
    "y = th.zeros(batch_size, dtype=torch.int, device=\"cuda\")\n",
    "model_kwargs = dict(y=y)\n",
    "\n",
    "with th.no_grad():\n",
    "    samples1 = diffusion_eval.ddim_sample_loop(model_DiT1, noise=noise, shape=(batch_size, 3, 9, 9), clip_denoised=False, device=\"cuda\", model_kwargs=model_kwargs, progress=True)\n",
    "samples1 = ((samples1.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "r3_list1, r2_list1, rule_col1 = infer_rule_from_sample_batch(samples1)\n",
    "C3_count1, C2_count1, anyvalid_count1, total1 = compute_rule_statistics(r3_list1, r2_list1, rule_col1, verbose=True)\n",
    "\n",
    "with th.no_grad():\n",
    "    samples2 = diffusion_eval.ddim_sample_loop(model_DiT2, noise=noise, shape=(batch_size, 3, 9, 9), clip_denoised=False, device=\"cuda\", model_kwargs=model_kwargs, progress=True)\n",
    "samples2 = ((samples2.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "r3_list2, r2_list2, rule_col2 = infer_rule_from_sample_batch(samples2)\n",
    "C3_count2, C2_count2, anyvalid_count2, total2 = compute_rule_statistics(r3_list2, r2_list2, rule_col2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence_interval(n, k, confidence=0.95, verbose=True):\n",
    "    \"\"\"Compute confidence interval for binomial proportion using beta distribution\n",
    "    \n",
    "    Args:\n",
    "        n (int): Total number of trials\n",
    "        k (int): Number of successes\n",
    "        confidence (float): Confidence level (default 0.95)\n",
    "        verbose (bool): Whether to print the result (default True)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Lower and upper bounds of confidence interval\n",
    "    \"\"\"\n",
    "    from scipy.stats import beta\n",
    "    a = k + 1  # alpha parameter for beta distribution\n",
    "    b = n - k + 1  # beta parameter\n",
    "    ci = beta.interval(confidence, a, b)\n",
    "    if verbose:\n",
    "        print(f\"ratio {k/n:.3f} {confidence*100}% CI: ({ci[0]:.3f}, {ci[1]:.3f})\")\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.635 95.0% CI: (0.626, 0.645)\n",
      "ratio 0.641 95.0% CI: (0.632, 0.650)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6316722686331505, 0.6502517549080044)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_confidence_interval(total1, C3_count1, confidence=0.95, verbose=True)\n",
    "compute_confidence_interval(total2, C3_count2, confidence=0.95, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "figroot = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning\"\n",
    "outdir = join(figroot, \"Diffusion_reproducibility_analysis\")\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the samples with the same seed\n",
    "th.save(samples1, join(outdir, f\"samples1_{expnames[0]}.pth\"))\n",
    "th.save({\"c3\": r3_list1, \"c2\": r2_list1, \"rule\": rule_col1,\n",
    "         \"C3_count\": C3_count1, \"C2_count\": C2_count1, \"anyvalid_count\": anyvalid_count1, \"total\": total1\n",
    "         }, join(outdir, f\"eval_samples1_{expnames[0]}.pkl\"))\n",
    "th.save(samples2, join(outdir, f\"samples2_{expnames[1]}.pth\"))\n",
    "th.save({\"c3\": r3_list2, \"c2\": r2_list2, \"rule\": rule_col2,\n",
    "         \"C3_count\": C3_count2, \"C2_count\": C2_count2, \"anyvalid_count\": anyvalid_count2, \"total\": total2\n",
    "         }, join(outdir, f\"eval_samples2_{expnames[1]}.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/Diffusion_reproducibility_analysis\n"
     ]
    }
   ],
   "source": [
    "!du -sh $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the reproducibility of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.73 (1822352/2488320)\n"
     ]
    }
   ],
   "source": [
    "# check if the samples entries are the same\n",
    "entry_match_tsr = (samples1.int() == samples2.int())\n",
    "# see how many rules are the same r3\n",
    "sample_match_tsr = entry_match_tsr.all(dim=(1,2,3))\n",
    "sample_match_frac = sample_match_tsr.sum() / batch_size\n",
    "# see how many entries are the same\n",
    "entry_match_frac = entry_match_tsr.sum() / entry_match_tsr.numel()\n",
    "print(f\"sample match frac: {sample_match_frac:.2f} ({sample_match_tsr.sum()}/{batch_size})\")\n",
    "print(f\"entry match frac: {entry_match_frac:.2f} ({entry_match_tsr.sum()}/{entry_match_tsr.numel()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154978190280>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entry_match_tsr[2] \n",
    "# show this as an image\n",
    "plt.imshow(entry_match_tsr[2].permute(1,2,0).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample C3 rule match frac: 0.811 (8309/10240)\n"
     ]
    }
   ],
   "source": [
    "# see how many rules are the same r3\n",
    "C3_rule_match_vec = [set(c3_1) == set(c3_2) for c3_1, c3_2 in zip(r3_list1, r3_list2)]\n",
    "C3_rule_match_frac = sum(C3_rule_match_vec) / len(C3_rule_match_vec)\n",
    "print(f\"Sample C3 rule match frac: {C3_rule_match_frac:.3f} ({sum(C3_rule_match_vec)}/{len(C3_rule_match_vec)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample C2 rule match frac: 0.844 (8645/10240)\n"
     ]
    }
   ],
   "source": [
    "# see how many rules are the same r3\n",
    "C2_rule_match_vec = [set(c2_1) == set(c2_2) for c2_1, c2_2 in zip(r2_list1, r2_list2)]\n",
    "C2_rule_match_frac = sum(C2_rule_match_vec) / len(C2_rule_match_vec)\n",
    "print(f\"Sample C2 rule match frac: {C2_rule_match_frac:.3f} ({sum(C2_rule_match_vec)}/{len(C2_rule_match_vec)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row all rule match frac: 0.717 (22037/30720)\n",
      "Row any rule overlap frac: 0.629 (19332/30720)\n",
      "Row any rule overlap with empty frac: 0.785 (24112/30720)\n"
     ]
    }
   ],
   "source": [
    "rule_col1_flatten = [rule for sublist in rule_col1 for rule in sublist]\n",
    "rule_col2_flatten = [rule for sublist in rule_col2 for rule in sublist]\n",
    "rule_match_vec = [set(rule_1) == set(rule_2) for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "rule_match_frac = sum(rule_match_vec) / len(rule_match_vec)\n",
    "print(f\"Row all rule match frac: {rule_match_frac:.3f} ({sum(rule_match_vec)}/{len(rule_match_vec)})\")\n",
    "# how many rows have at least one rule match intersection in the two sets\n",
    "rule_intersect_vec = [len(set(rule_1) & set(rule_2)) > 0 \n",
    "     for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "rule_intersect_w0_vec = [len(set(rule_1) & set(rule_2)) > 0 or ( len(rule_2)==0 and len(rule_1)==0 )\n",
    "     for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "rule_intersect_frac = sum(rule_intersect_vec) / len(rule_intersect_vec)\n",
    "rule_intersect_w0_frac = sum(rule_intersect_w0_vec) / len(rule_intersect_w0_vec)\n",
    "print(f\"Row any rule overlap frac: {rule_intersect_frac:.3f} ({sum(rule_intersect_vec)}/{len(rule_intersect_vec)})\")\n",
    "print(f\"Row any rule overlap with empty frac: {rule_intersect_w0_frac:.3f} ({sum(rule_intersect_w0_vec)}/{len(rule_intersect_w0_vec)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical splits of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1324/2048 (0.65), C3 + C2: 1552/2048 (0.76), AnyValid: 4813/6144 (0.78)\n",
      "C3: 1310/2048 (0.64), C3 + C2: 1546/2048 (0.75), AnyValid: 4784/6144 (0.78)\n",
      "C3: 1284/2048 (0.63), C3 + C2: 1528/2048 (0.75), AnyValid: 4735/6144 (0.77)\n",
      "C3: 1282/2048 (0.63), C3 + C2: 1496/2048 (0.73), AnyValid: 4689/6144 (0.76)\n",
      "C3: 1305/2048 (0.64), C3 + C2: 1523/2048 (0.74), AnyValid: 4742/6144 (0.77)\n"
     ]
    }
   ],
   "source": [
    "# samples1 = ((samples1.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "for split_idx in range(5):\n",
    "    r3_list_split, r2_list_split, rule_col_split = infer_rule_from_sample_batch(samples1[split_idx*batch_size//5:(split_idx+1)*batch_size//5])\n",
    "    C3_count_split, C2_count_split, anyvalid_count_split, total_split = compute_rule_statistics(r3_list_split, r2_list_split, rule_col_split, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 1324/2048 (0.65), C3 + C2: 1560/2048 (0.76), AnyValid: 4807/6144 (0.78)\n",
      "C3: 1323/2048 (0.65), C3 + C2: 1579/2048 (0.77), AnyValid: 4856/6144 (0.79)\n",
      "C3: 1300/2048 (0.63), C3 + C2: 1545/2048 (0.75), AnyValid: 4800/6144 (0.78)\n",
      "C3: 1297/2048 (0.63), C3 + C2: 1534/2048 (0.75), AnyValid: 4736/6144 (0.77)\n",
      "C3: 1320/2048 (0.64), C3 + C2: 1555/2048 (0.76), AnyValid: 4822/6144 (0.78)\n"
     ]
    }
   ],
   "source": [
    "# samples1 = ((samples1.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "for split_idx in range(5):\n",
    "    r3_list_split, r2_list_split, rule_col_split = infer_rule_from_sample_batch(samples2[split_idx*batch_size//5:(split_idx+1)*batch_size//5])\n",
    "    C3_count_split, C2_count_split, anyvalid_count_split, total_split = compute_rule_statistics(r3_list_split, r2_list_split, rule_col_split, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary across multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sample_match(samples1, samples2):\n",
    "    stats_dict = edict()\n",
    "    C3_list1, C2_list1, rule_col1 = infer_rule_from_sample_batch(samples1)\n",
    "    C3_list2, C2_list2, rule_col2 = infer_rule_from_sample_batch(samples2)\n",
    "    batch_size = samples1.shape[0]\n",
    "    # check if the samples entries are the same\n",
    "    entry_match_tsr = (samples1.int() == samples2.int())\n",
    "    # see how many rules are the same r3\n",
    "    sample_match_tsr = entry_match_tsr.all(dim=(1,2,3))\n",
    "    sample_match_frac = sample_match_tsr.sum() / batch_size\n",
    "    # see how many entries are the same\n",
    "    entry_match_frac = entry_match_tsr.sum() / entry_match_tsr.numel()\n",
    "    print(f\"sample match frac: {sample_match_frac:.2f} ({sample_match_tsr.sum()}/{batch_size})\")\n",
    "    print(f\"entry match frac: {entry_match_frac:.2f} ({entry_match_tsr.sum()}/{entry_match_tsr.numel()})\")\n",
    "    stats_dict[\"entry_match_frac\"] = entry_match_frac\n",
    "    stats_dict[\"entry_match_cnt\"] = entry_match_tsr.sum()\n",
    "    stats_dict[\"entry_match_total\"] = entry_match_tsr.numel()\n",
    "    stats_dict[\"sample_match_frac\"] = sample_match_frac\n",
    "    stats_dict[\"sample_match_cnt\"] = sample_match_tsr.sum()\n",
    "    stats_dict[\"sample_match_total\"] = batch_size\n",
    "    # see how many samples have the same C3 rules\n",
    "    C3_rule_match_vec = [set(c3_1) == set(c3_2) for c3_1, c3_2 in zip(C3_list1, C3_list2)]\n",
    "    C3_rule_match_frac = sum(C3_rule_match_vec) / len(C3_rule_match_vec)\n",
    "    print(f\"Sample C3 rule match frac: {C3_rule_match_frac:.3f} ({sum(C3_rule_match_vec)}/{len(C3_rule_match_vec)})\")\n",
    "    stats_dict[\"C3_rule_match_frac\"] = C3_rule_match_frac\n",
    "    stats_dict[\"C3_rule_match_cnt\"] = sum(C3_rule_match_vec)\n",
    "    stats_dict[\"C3_rule_match_total\"] = len(C3_rule_match_vec)\n",
    "    # see how many samples have the same C2 rules\n",
    "    C2_rule_match_vec = [set(c2_1) == set(c2_2) for c2_1, c2_2 in zip(C2_list1, C2_list2)]\n",
    "    C2_rule_match_frac = sum(C2_rule_match_vec) / len(C2_rule_match_vec)\n",
    "    print(f\"Sample C2 rule match frac: {C2_rule_match_frac:.3f} ({sum(C2_rule_match_vec)}/{len(C2_rule_match_vec)})\")\n",
    "    stats_dict[\"C2_rule_match_frac\"] = C2_rule_match_frac\n",
    "    stats_dict[\"C2_rule_match_cnt\"] = sum(C2_rule_match_vec)\n",
    "    stats_dict[\"C2_rule_match_total\"] = len(C2_rule_match_vec)\n",
    "    # see how many rows have the same rule set\n",
    "    rule_col1_flatten = [rule for sublist in rule_col1 for rule in sublist]\n",
    "    rule_col2_flatten = [rule for sublist in rule_col2 for rule in sublist]\n",
    "    rule_match_vec = [set(rule_1) == set(rule_2) for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "    rule_match_frac = sum(rule_match_vec) / len(rule_match_vec)\n",
    "    print(f\"Row all rule match frac: {rule_match_frac:.3f} ({sum(rule_match_vec)}/{len(rule_match_vec)})\")\n",
    "    stats_dict[\"rule_match_frac\"] = rule_match_frac\n",
    "    stats_dict[\"rule_match_cnt\"] = sum(rule_match_vec)\n",
    "    stats_dict[\"rule_match_total\"] = len(rule_match_vec)\n",
    "    # how many rows have at least one rule match intersection in the two sets\n",
    "    rule_intersect_vec = [len(set(rule_1) & set(rule_2)) > 0 \n",
    "        for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "    rule_intersect_w0_vec = [len(set(rule_1) & set(rule_2)) > 0 or ( len(rule_2)==0 and len(rule_1)==0 )\n",
    "        for rule_1, rule_2 in zip(rule_col1_flatten, rule_col2_flatten)]\n",
    "    rule_intersect_frac = sum(rule_intersect_vec) / len(rule_intersect_vec)\n",
    "    rule_intersect_w0_frac = sum(rule_intersect_w0_vec) / len(rule_intersect_w0_vec)\n",
    "    print(f\"Row any rule overlap frac: {rule_intersect_frac:.3f} ({sum(rule_intersect_vec)}/{len(rule_intersect_vec)})\")\n",
    "    print(f\"Row any rule overlap with empty frac: {rule_intersect_w0_frac:.3f} ({sum(rule_intersect_w0_vec)}/{len(rule_intersect_w0_vec)})\")\n",
    "    stats_dict[\"rule_intersect_frac\"] = rule_intersect_frac\n",
    "    stats_dict[\"rule_intersect_cnt\"] = sum(rule_intersect_vec)\n",
    "    stats_dict[\"rule_intersect_total\"] = len(rule_intersect_vec)\n",
    "    stats_dict[\"rule_intersect_w0_frac\"] = rule_intersect_w0_frac\n",
    "    stats_dict[\"rule_intersect_w0_cnt\"] = sum(rule_intersect_w0_vec)\n",
    "    stats_dict[\"rule_intersect_w0_total\"] = len(rule_intersect_w0_vec)\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/Diffusion_reproducibility_analysis\"\n",
    "\n",
    "samples1 = th.load(join(outdir, f\"samples1_{expnames[0]}.pth\"))\n",
    "samples2 = th.load(join(outdir, f\"samples2_{expnames[1]}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.73 (1822352/2488320)\n",
      "Sample C3 rule match frac: 0.811 (8309/10240)\n",
      "Sample C2 rule match frac: 0.844 (8645/10240)\n",
      "Row all rule match frac: 0.717 (22037/30720)\n",
      "Row any rule overlap frac: 0.629 (19332/30720)\n",
      "Row any rule overlap with empty frac: 0.785 (24112/30720)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entry_match_frac': tensor(0.7324),\n",
       " 'entry_match_cnt': tensor(1822352),\n",
       " 'entry_match_total': 2488320,\n",
       " 'sample_match_frac': tensor(0.),\n",
       " 'sample_match_cnt': tensor(0),\n",
       " 'sample_match_total': 10240,\n",
       " 'C3_rule_match_frac': 0.81142578125,\n",
       " 'C3_rule_match_cnt': 8309,\n",
       " 'C3_rule_match_total': 10240,\n",
       " 'C2_rule_match_frac': 0.84423828125,\n",
       " 'C2_rule_match_cnt': 8645,\n",
       " 'C2_rule_match_total': 10240,\n",
       " 'rule_match_frac': 0.7173502604166667,\n",
       " 'rule_match_cnt': 22037,\n",
       " 'rule_match_total': 30720,\n",
       " 'rule_intersect_frac': 0.629296875,\n",
       " 'rule_intersect_cnt': 19332,\n",
       " 'rule_intersect_total': 30720,\n",
       " 'rule_intersect_w0_frac': 0.7848958333333333,\n",
       " 'rule_intersect_w0_cnt': 24112,\n",
       " 'rule_intersect_w0_total': 30720}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict = eval_sample_match(samples1, samples2)\n",
    "stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample match frac: 0.00 (0/5120)\n",
      "entry match frac: 0.73 (910741/1244160)\n",
      "Sample C3 rule match frac: 0.803 (4109/5120)\n",
      "Sample C2 rule match frac: 0.840 (4301/5120)\n",
      "Row all rule match frac: 0.711 (10926/15360)\n",
      "Row any rule overlap frac: 0.629 (9660/15360)\n",
      "Row any rule overlap with empty frac: 0.781 (11996/15360)\n",
      "sample match frac: 0.00 (0/5120)\n",
      "entry match frac: 0.15 (189452/1244160)\n",
      "Sample C3 rule match frac: 0.147 (751/5120)\n",
      "Sample C2 rule match frac: 0.791 (4051/5120)\n",
      "Row all rule match frac: 0.064 (987/15360)\n",
      "Row any rule overlap frac: 0.021 (317/15360)\n",
      "Row any rule overlap with empty frac: 0.070 (1068/15360)\n"
     ]
    }
   ],
   "source": [
    "batch_size = samples1.shape[0]\n",
    "stats_dict = eval_sample_match(samples1[0:batch_size//2], samples2[0:batch_size//2])\n",
    "stats_dict_ctrl = eval_sample_match(samples1[:batch_size//2], samples1[batch_size//2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large scale synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Figures/DiffusionReasoning/Diffusion_reproducibility_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_SEED = 43\n",
    "samples_S1 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[0]}.pth\"))\n",
    "samples_S2 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[1]}.pth\"))\n",
    "samples_S3 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[2]}.pth\"))\n",
    "samples_B1 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[3]}.pth\"))\n",
    "samples_B2 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[4]}.pth\"))\n",
    "samples_B3 = th.load(join(outdir, f\"samples_RND{RND_SEED}_{expnames[5]}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 vs S2\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.76 (1902899/2488320)\n",
      "Sample C3 rule match frac: 0.805 (8243/10240)\n",
      "Sample C2 rule match frac: 0.833 (8529/10240)\n",
      "Row all rule match frac: 0.706 (21700/30720)\n",
      "Row any rule overlap frac: 0.627 (19271/30720)\n",
      "Row any rule overlap with empty frac: 0.776 (23843/30720)\n",
      "S2 vs S3\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.77 (1908807/2488320)\n",
      "Sample C3 rule match frac: 0.817 (8369/10240)\n",
      "Sample C2 rule match frac: 0.840 (8601/10240)\n",
      "Row all rule match frac: 0.719 (22087/30720)\n",
      "Row any rule overlap frac: 0.634 (19489/30720)\n",
      "Row any rule overlap with empty frac: 0.788 (24195/30720)\n",
      "S1 vs S3\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.77 (1907763/2488320)\n",
      "Sample C3 rule match frac: 0.808 (8275/10240)\n",
      "Sample C2 rule match frac: 0.831 (8514/10240)\n",
      "Row all rule match frac: 0.713 (21915/30720)\n",
      "Row any rule overlap frac: 0.636 (19531/30720)\n",
      "Row any rule overlap with empty frac: 0.784 (24079/30720)\n",
      "B1 vs B2\n",
      "sample match frac: 1.00 (10240/10240)\n",
      "entry match frac: 1.00 (2488320/2488320)\n",
      "Sample C3 rule match frac: 1.000 (10240/10240)\n",
      "Sample C2 rule match frac: 1.000 (10240/10240)\n",
      "Row all rule match frac: 1.000 (30720/30720)\n",
      "Row any rule overlap frac: 0.786 (24143/30720)\n",
      "Row any rule overlap with empty frac: 1.000 (30720/30720)\n",
      "B2 vs B3\n",
      "sample match frac: 1.00 (10240/10240)\n",
      "entry match frac: 1.00 (2488320/2488320)\n",
      "Sample C3 rule match frac: 1.000 (10240/10240)\n",
      "Sample C2 rule match frac: 1.000 (10240/10240)\n",
      "Row all rule match frac: 1.000 (30720/30720)\n",
      "Row any rule overlap frac: 0.786 (24143/30720)\n",
      "Row any rule overlap with empty frac: 1.000 (30720/30720)\n",
      "B1 vs B3\n",
      "sample match frac: 1.00 (10240/10240)\n",
      "entry match frac: 1.00 (2488320/2488320)\n",
      "Sample C3 rule match frac: 1.000 (10240/10240)\n",
      "Sample C2 rule match frac: 1.000 (10240/10240)\n",
      "Row all rule match frac: 1.000 (30720/30720)\n",
      "Row any rule overlap frac: 0.786 (24143/30720)\n",
      "Row any rule overlap with empty frac: 1.000 (30720/30720)\n",
      "S1 vs B1\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.71 (1762913/2488320)\n",
      "Sample C3 rule match frac: 0.750 (7683/10240)\n",
      "Sample C2 rule match frac: 0.811 (8308/10240)\n",
      "Row all rule match frac: 0.633 (19441/30720)\n",
      "Row any rule overlap frac: 0.577 (17722/30720)\n",
      "Row any rule overlap with empty frac: 0.708 (21748/30720)\n",
      "S2 vs B2\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.70 (1737498/2488320)\n",
      "Sample C3 rule match frac: 0.756 (7737/10240)\n",
      "Sample C2 rule match frac: 0.813 (8329/10240)\n",
      "Row all rule match frac: 0.635 (19504/30720)\n",
      "Row any rule overlap frac: 0.575 (17658/30720)\n",
      "Row any rule overlap with empty frac: 0.711 (21853/30720)\n",
      "S3 vs B3\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.70 (1744653/2488320)\n",
      "Sample C3 rule match frac: 0.754 (7720/10240)\n",
      "Sample C2 rule match frac: 0.808 (8278/10240)\n",
      "Row all rule match frac: 0.633 (19446/30720)\n",
      "Row any rule overlap frac: 0.578 (17744/30720)\n",
      "Row any rule overlap with empty frac: 0.711 (21845/30720)\n"
     ]
    }
   ],
   "source": [
    "print(f\"S1 vs S2\")\n",
    "stats_dict_S12 = eval_sample_match(samples_S1, samples_S2)\n",
    "print(f\"S2 vs S3\")\n",
    "stats_dict_S23 = eval_sample_match(samples_S2, samples_S3)\n",
    "print(f\"S1 vs S3\")\n",
    "stats_dict_S13 = eval_sample_match(samples_S1, samples_S3)\n",
    "print(f\"B1 vs B2\")\n",
    "stats_dict_B12 = eval_sample_match(samples_B1, samples_B2)\n",
    "print(f\"B2 vs B3\")\n",
    "stats_dict_B23 = eval_sample_match(samples_B2, samples_B3)\n",
    "print(f\"B1 vs B3\")\n",
    "stats_dict_B13 = eval_sample_match(samples_B1, samples_B3)\n",
    "print(f\"S1 vs B1\")\n",
    "stats_dict_SB1 = eval_sample_match(samples_S1, samples_B1)\n",
    "print(f\"S2 vs B2\")\n",
    "stats_dict_SB2 = eval_sample_match(samples_S2, samples_B2)\n",
    "print(f\"S3 vs B3\")\n",
    "stats_dict_SB3 = eval_sample_match(samples_S3, samples_B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_match_frac</th>\n",
       "      <th>entry_match_cnt</th>\n",
       "      <th>entry_match_total</th>\n",
       "      <th>sample_match_frac</th>\n",
       "      <th>sample_match_cnt</th>\n",
       "      <th>sample_match_total</th>\n",
       "      <th>C3_rule_match_frac</th>\n",
       "      <th>C3_rule_match_cnt</th>\n",
       "      <th>C3_rule_match_total</th>\n",
       "      <th>C2_rule_match_frac</th>\n",
       "      <th>...</th>\n",
       "      <th>C2_rule_match_total</th>\n",
       "      <th>rule_match_frac</th>\n",
       "      <th>rule_match_cnt</th>\n",
       "      <th>rule_match_total</th>\n",
       "      <th>rule_intersect_frac</th>\n",
       "      <th>rule_intersect_cnt</th>\n",
       "      <th>rule_intersect_total</th>\n",
       "      <th>rule_intersect_w0_frac</th>\n",
       "      <th>rule_intersect_w0_cnt</th>\n",
       "      <th>rule_intersect_w0_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1 vs S2</th>\n",
       "      <td>0.764732</td>\n",
       "      <td>1902899</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.804980</td>\n",
       "      <td>8243</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.832910</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.706380</td>\n",
       "      <td>21700</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.627311</td>\n",
       "      <td>19271</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.776139</td>\n",
       "      <td>23843</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2 vs S3</th>\n",
       "      <td>0.767107</td>\n",
       "      <td>1908807</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.817285</td>\n",
       "      <td>8369</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.839941</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.718978</td>\n",
       "      <td>22087</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.634408</td>\n",
       "      <td>19489</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>24195</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1 vs S3</th>\n",
       "      <td>0.766687</td>\n",
       "      <td>1907763</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.808105</td>\n",
       "      <td>8275</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.831445</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.713379</td>\n",
       "      <td>21915</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.635775</td>\n",
       "      <td>19531</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.783822</td>\n",
       "      <td>24079</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1 vs B2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2488320</td>\n",
       "      <td>2488320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2 vs B3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2488320</td>\n",
       "      <td>2488320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1 vs B3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2488320</td>\n",
       "      <td>2488320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10240</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30720</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1 vs B1</th>\n",
       "      <td>0.708475</td>\n",
       "      <td>1762913</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.750293</td>\n",
       "      <td>7683</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.811328</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.632845</td>\n",
       "      <td>19441</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.576888</td>\n",
       "      <td>17722</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.707943</td>\n",
       "      <td>21748</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2 vs B2</th>\n",
       "      <td>0.698261</td>\n",
       "      <td>1737498</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.755566</td>\n",
       "      <td>7737</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.813379</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.634896</td>\n",
       "      <td>19504</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.574805</td>\n",
       "      <td>17658</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.711361</td>\n",
       "      <td>21853</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3 vs B3</th>\n",
       "      <td>0.701137</td>\n",
       "      <td>1744653</td>\n",
       "      <td>2488320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>7720</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.808398</td>\n",
       "      <td>...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>19446</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.577604</td>\n",
       "      <td>17744</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>21845</td>\n",
       "      <td>30720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          entry_match_frac  entry_match_cnt  entry_match_total  \\\n",
       "S1 vs S2          0.764732          1902899            2488320   \n",
       "S2 vs S3          0.767107          1908807            2488320   \n",
       "S1 vs S3          0.766687          1907763            2488320   \n",
       "B1 vs B2          1.000000          2488320            2488320   \n",
       "B2 vs B3          1.000000          2488320            2488320   \n",
       "B1 vs B3          1.000000          2488320            2488320   \n",
       "S1 vs B1          0.708475          1762913            2488320   \n",
       "S2 vs B2          0.698261          1737498            2488320   \n",
       "S3 vs B3          0.701137          1744653            2488320   \n",
       "\n",
       "          sample_match_frac  sample_match_cnt  sample_match_total  \\\n",
       "S1 vs S2                0.0                 0               10240   \n",
       "S2 vs S3                0.0                 0               10240   \n",
       "S1 vs S3                0.0                 0               10240   \n",
       "B1 vs B2                1.0             10240               10240   \n",
       "B2 vs B3                1.0             10240               10240   \n",
       "B1 vs B3                1.0             10240               10240   \n",
       "S1 vs B1                0.0                 0               10240   \n",
       "S2 vs B2                0.0                 0               10240   \n",
       "S3 vs B3                0.0                 0               10240   \n",
       "\n",
       "          C3_rule_match_frac  C3_rule_match_cnt  C3_rule_match_total  \\\n",
       "S1 vs S2            0.804980               8243                10240   \n",
       "S2 vs S3            0.817285               8369                10240   \n",
       "S1 vs S3            0.808105               8275                10240   \n",
       "B1 vs B2            1.000000              10240                10240   \n",
       "B2 vs B3            1.000000              10240                10240   \n",
       "B1 vs B3            1.000000              10240                10240   \n",
       "S1 vs B1            0.750293               7683                10240   \n",
       "S2 vs B2            0.755566               7737                10240   \n",
       "S3 vs B3            0.753906               7720                10240   \n",
       "\n",
       "          C2_rule_match_frac  ...  C2_rule_match_total  rule_match_frac  \\\n",
       "S1 vs S2            0.832910  ...                10240         0.706380   \n",
       "S2 vs S3            0.839941  ...                10240         0.718978   \n",
       "S1 vs S3            0.831445  ...                10240         0.713379   \n",
       "B1 vs B2            1.000000  ...                10240         1.000000   \n",
       "B2 vs B3            1.000000  ...                10240         1.000000   \n",
       "B1 vs B3            1.000000  ...                10240         1.000000   \n",
       "S1 vs B1            0.811328  ...                10240         0.632845   \n",
       "S2 vs B2            0.813379  ...                10240         0.634896   \n",
       "S3 vs B3            0.808398  ...                10240         0.633008   \n",
       "\n",
       "          rule_match_cnt  rule_match_total  rule_intersect_frac  \\\n",
       "S1 vs S2           21700             30720             0.627311   \n",
       "S2 vs S3           22087             30720             0.634408   \n",
       "S1 vs S3           21915             30720             0.635775   \n",
       "B1 vs B2           30720             30720             0.785905   \n",
       "B2 vs B3           30720             30720             0.785905   \n",
       "B1 vs B3           30720             30720             0.785905   \n",
       "S1 vs B1           19441             30720             0.576888   \n",
       "S2 vs B2           19504             30720             0.574805   \n",
       "S3 vs B3           19446             30720             0.577604   \n",
       "\n",
       "          rule_intersect_cnt  rule_intersect_total  rule_intersect_w0_frac  \\\n",
       "S1 vs S2               19271                 30720                0.776139   \n",
       "S2 vs S3               19489                 30720                0.787598   \n",
       "S1 vs S3               19531                 30720                0.783822   \n",
       "B1 vs B2               24143                 30720                1.000000   \n",
       "B2 vs B3               24143                 30720                1.000000   \n",
       "B1 vs B3               24143                 30720                1.000000   \n",
       "S1 vs B1               17722                 30720                0.707943   \n",
       "S2 vs B2               17658                 30720                0.711361   \n",
       "S3 vs B3               17744                 30720                0.711100   \n",
       "\n",
       "          rule_intersect_w0_cnt  rule_intersect_w0_total  \n",
       "S1 vs S2                  23843                    30720  \n",
       "S2 vs S3                  24195                    30720  \n",
       "S1 vs S3                  24079                    30720  \n",
       "B1 vs B2                  30720                    30720  \n",
       "B2 vs B3                  30720                    30720  \n",
       "B1 vs B3                  30720                    30720  \n",
       "S1 vs B1                  21748                    30720  \n",
       "S2 vs B2                  21853                    30720  \n",
       "S3 vs B3                  21845                    30720  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create dictionaries for each comparison\n",
    "# stats_dict_S12 = eval_sample_match(samples_S1, samples_S2)\n",
    "# stats_dict_S23 = eval_sample_match(samples_S2, samples_S3)\n",
    "# stats_dict_S13 = eval_sample_match(samples_S1, samples_S3)\n",
    "# stats_dict_B12 = eval_sample_match(samples_B1, samples_B2)\n",
    "# stats_dict_B23 = eval_sample_match(samples_B2, samples_B3)\n",
    "# stats_dict_B13 = eval_sample_match(samples_B1, samples_B3)\n",
    "# stats_dict_SB1 = eval_sample_match(samples_S1, samples_B1)\n",
    "# stats_dict_SB2 = eval_sample_match(samples_S2, samples_B2)\n",
    "# stats_dict_SB3 = eval_sample_match(samples_S3, samples_B3)\n",
    "# Create DataFrame with all results\n",
    "import pandas as pd\n",
    "\n",
    "comparisons = ['S1 vs S2', 'S2 vs S3', 'S1 vs S3', \n",
    "               'B1 vs B2', 'B2 vs B3', 'B1 vs B3',\n",
    "               'S1 vs B1', 'S2 vs B2', 'S3 vs B3']\n",
    "\n",
    "stats_dicts = [stats_dict_S12, stats_dict_S23, stats_dict_S13,\n",
    "               stats_dict_B12, stats_dict_B23, stats_dict_B13, \n",
    "               stats_dict_SB1, stats_dict_SB2, stats_dict_SB3]\n",
    "\n",
    "df = pd.DataFrame(stats_dicts, index=comparisons) \n",
    "# if some columns are tensor dtype change them to float or int\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: x.item() if isinstance(x, th.Tensor) else x)\n",
    "display(df)\n",
    "df.to_csv(join(outdir, \"DiT_S_B012_cross_model_10k_sample_match_stats.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: 6627/10240 (0.65), C3 + C2: 7868/10240 (0.77), AnyValid: 24229/30720 (0.79)\n",
      "ratio 0.647 95.0% CI: (0.638, 0.656)\n",
      "ratio 0.121 95.0% CI: (0.115, 0.128)\n",
      "ratio 0.789 95.0% CI: (0.784, 0.793)\n",
      "C3: 6556/10240 (0.64), C3 + C2: 7693/10240 (0.75), AnyValid: 23925/30720 (0.78)\n",
      "ratio 0.640 95.0% CI: (0.631, 0.649)\n",
      "ratio 0.111 95.0% CI: (0.105, 0.117)\n",
      "ratio 0.779 95.0% CI: (0.774, 0.783)\n",
      "C3: 6629/10240 (0.65), C3 + C2: 7818/10240 (0.76), AnyValid: 24107/30720 (0.78)\n",
      "ratio 0.647 95.0% CI: (0.638, 0.657)\n",
      "ratio 0.116 95.0% CI: (0.110, 0.122)\n",
      "ratio 0.785 95.0% CI: (0.780, 0.789)\n",
      "C3: 6542/10240 (0.64), C3 + C2: 7831/10240 (0.76), AnyValid: 24143/30720 (0.79)\n",
      "ratio 0.639 95.0% CI: (0.630, 0.648)\n",
      "ratio 0.126 95.0% CI: (0.120, 0.132)\n",
      "ratio 0.786 95.0% CI: (0.781, 0.790)\n",
      "C3: 6542/10240 (0.64), C3 + C2: 7831/10240 (0.76), AnyValid: 24143/30720 (0.79)\n",
      "ratio 0.639 95.0% CI: (0.630, 0.648)\n",
      "ratio 0.126 95.0% CI: (0.120, 0.132)\n",
      "ratio 0.786 95.0% CI: (0.781, 0.790)\n",
      "C3: 6542/10240 (0.64), C3 + C2: 7831/10240 (0.76), AnyValid: 24143/30720 (0.79)\n",
      "ratio 0.639 95.0% CI: (0.630, 0.648)\n",
      "ratio 0.126 95.0% CI: (0.120, 0.132)\n",
      "ratio 0.786 95.0% CI: (0.781, 0.790)\n"
     ]
    }
   ],
   "source": [
    "perf_dict = edict()\n",
    "for samples, labels in zip([samples_S1, samples_S2, samples_S3, samples_B1, samples_B2, samples_B3],\n",
    "                           [\"DiT-S_1\", \"DiT-S_2\", \"DiT-S_3\", \"DiT-B_1\", \"DiT-B_2\", \"DiT-B_3\"]):\n",
    "    stats = {}\n",
    "    r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "    C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)\n",
    "    stats[\"C3_count\"] = C3_count\n",
    "    stats[\"C3_total\"] = total\n",
    "    stats[\"C3_frac\"] = C3_count / total\n",
    "    stats[\"C3_ci_L\"], stats[\"C3_ci_U\"] = compute_confidence_interval(total, C3_count, confidence=0.95, verbose=True)\n",
    "    stats[\"C2_count\"] = C2_count\n",
    "    stats[\"C2_total\"] = total\n",
    "    stats[\"C2_frac\"] = C2_count / total\n",
    "    stats[\"C2_ci_L\"], stats[\"C2_ci_U\"] = compute_confidence_interval(total, C2_count, confidence=0.95, verbose=True)\n",
    "    stats[\"valid_count\"] = anyvalid_count\n",
    "    stats[\"valid_total\"] = total * 3\n",
    "    stats[\"valid_frac\"] = anyvalid_count / (total * 3)\n",
    "    stats[\"valid_ci_L\"], stats[\"valid_ci_U\"] = compute_confidence_interval(total * 3, anyvalid_count, confidence=0.95, verbose=True)\n",
    "    perf_dict[labels] = stats\n",
    "# convert to dataframe, make the index the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C3_count</th>\n",
       "      <th>C3_total</th>\n",
       "      <th>C3_frac</th>\n",
       "      <th>C3_ci_L</th>\n",
       "      <th>C3_ci_U</th>\n",
       "      <th>C2_count</th>\n",
       "      <th>C2_total</th>\n",
       "      <th>C2_frac</th>\n",
       "      <th>C2_ci_L</th>\n",
       "      <th>C2_ci_U</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>valid_total</th>\n",
       "      <th>valid_frac</th>\n",
       "      <th>valid_ci_L</th>\n",
       "      <th>valid_ci_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DiT-S_1</th>\n",
       "      <td>6627</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.647168</td>\n",
       "      <td>0.637858</td>\n",
       "      <td>0.656366</td>\n",
       "      <td>1241</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.121191</td>\n",
       "      <td>0.115014</td>\n",
       "      <td>0.127657</td>\n",
       "      <td>24229</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>0.784103</td>\n",
       "      <td>0.793233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiT-S_2</th>\n",
       "      <td>6556</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.640234</td>\n",
       "      <td>0.630887</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>1137</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.111035</td>\n",
       "      <td>0.105097</td>\n",
       "      <td>0.117269</td>\n",
       "      <td>23925</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.778809</td>\n",
       "      <td>0.774132</td>\n",
       "      <td>0.783414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiT-S_3</th>\n",
       "      <td>6629</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>0.638055</td>\n",
       "      <td>0.656560</td>\n",
       "      <td>1189</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.116113</td>\n",
       "      <td>0.110054</td>\n",
       "      <td>0.122465</td>\n",
       "      <td>24107</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.784733</td>\n",
       "      <td>0.780101</td>\n",
       "      <td>0.789293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiT-B_1</th>\n",
       "      <td>6542</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.638867</td>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.648116</td>\n",
       "      <td>1289</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>0.132446</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.781282</td>\n",
       "      <td>0.790456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiT-B_2</th>\n",
       "      <td>6542</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.638867</td>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.648116</td>\n",
       "      <td>1289</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>0.132446</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.781282</td>\n",
       "      <td>0.790456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiT-B_3</th>\n",
       "      <td>6542</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.638867</td>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.648116</td>\n",
       "      <td>1289</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>0.119596</td>\n",
       "      <td>0.132446</td>\n",
       "      <td>24143</td>\n",
       "      <td>30720</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.781282</td>\n",
       "      <td>0.790456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C3_count  C3_total   C3_frac   C3_ci_L   C3_ci_U  C2_count  C2_total  \\\n",
       "DiT-S_1      6627     10240  0.647168  0.637858  0.656366      1241     10240   \n",
       "DiT-S_2      6556     10240  0.640234  0.630887  0.649475      1137     10240   \n",
       "DiT-S_3      6629     10240  0.647363  0.638055  0.656560      1189     10240   \n",
       "DiT-B_1      6542     10240  0.638867  0.629513  0.648116      1289     10240   \n",
       "DiT-B_2      6542     10240  0.638867  0.629513  0.648116      1289     10240   \n",
       "DiT-B_3      6542     10240  0.638867  0.629513  0.648116      1289     10240   \n",
       "\n",
       "          C2_frac   C2_ci_L   C2_ci_U  valid_count  valid_total  valid_frac  \\\n",
       "DiT-S_1  0.121191  0.115014  0.127657        24229        30720    0.788704   \n",
       "DiT-S_2  0.111035  0.105097  0.117269        23925        30720    0.778809   \n",
       "DiT-S_3  0.116113  0.110054  0.122465        24107        30720    0.784733   \n",
       "DiT-B_1  0.125879  0.119596  0.132446        24143        30720    0.785905   \n",
       "DiT-B_2  0.125879  0.119596  0.132446        24143        30720    0.785905   \n",
       "DiT-B_3  0.125879  0.119596  0.132446        24143        30720    0.785905   \n",
       "\n",
       "         valid_ci_L  valid_ci_U  \n",
       "DiT-S_1    0.784103    0.793233  \n",
       "DiT-S_2    0.774132    0.783414  \n",
       "DiT-S_3    0.780101    0.789293  \n",
       "DiT-B_1    0.781282    0.790456  \n",
       "DiT-B_2    0.781282    0.790456  \n",
       "DiT-B_3    0.781282    0.790456  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df = pd.DataFrame.from_dict(perf_dict, orient=\"index\")\n",
    "perf_df.to_csv(join(outdir, \"DiT_S_B012_10k_sample_performance_stats.csv\"))\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_match_frac</th>\n",
       "      <th>sample_match_frac</th>\n",
       "      <th>C3_rule_match_frac</th>\n",
       "      <th>C2_rule_match_frac</th>\n",
       "      <th>rule_match_frac</th>\n",
       "      <th>rule_intersect_frac</th>\n",
       "      <th>rule_intersect_w0_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1 vs S2</th>\n",
       "      <td>0.764732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804980</td>\n",
       "      <td>0.832910</td>\n",
       "      <td>0.706380</td>\n",
       "      <td>0.627311</td>\n",
       "      <td>0.776139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2 vs S3</th>\n",
       "      <td>0.767107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817285</td>\n",
       "      <td>0.839941</td>\n",
       "      <td>0.718978</td>\n",
       "      <td>0.634408</td>\n",
       "      <td>0.787598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1 vs S3</th>\n",
       "      <td>0.766687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808105</td>\n",
       "      <td>0.831445</td>\n",
       "      <td>0.713379</td>\n",
       "      <td>0.635775</td>\n",
       "      <td>0.783822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1 vs B2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2 vs B3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1 vs B3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1 vs B1</th>\n",
       "      <td>0.708475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750293</td>\n",
       "      <td>0.811328</td>\n",
       "      <td>0.632845</td>\n",
       "      <td>0.576888</td>\n",
       "      <td>0.707943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2 vs B2</th>\n",
       "      <td>0.698261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755566</td>\n",
       "      <td>0.813379</td>\n",
       "      <td>0.634896</td>\n",
       "      <td>0.574805</td>\n",
       "      <td>0.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3 vs B3</th>\n",
       "      <td>0.701137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.808398</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.577604</td>\n",
       "      <td>0.711100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entry_match_frac  sample_match_frac  C3_rule_match_frac  \\\n",
       "S1 vs S2          0.764732                0.0            0.804980   \n",
       "S2 vs S3          0.767107                0.0            0.817285   \n",
       "S1 vs S3          0.766687                0.0            0.808105   \n",
       "B1 vs B2          1.000000                1.0            1.000000   \n",
       "B2 vs B3          1.000000                1.0            1.000000   \n",
       "B1 vs B3          1.000000                1.0            1.000000   \n",
       "S1 vs B1          0.708475                0.0            0.750293   \n",
       "S2 vs B2          0.698261                0.0            0.755566   \n",
       "S3 vs B3          0.701137                0.0            0.753906   \n",
       "\n",
       "          C2_rule_match_frac  rule_match_frac  rule_intersect_frac  \\\n",
       "S1 vs S2            0.832910         0.706380             0.627311   \n",
       "S2 vs S3            0.839941         0.718978             0.634408   \n",
       "S1 vs S3            0.831445         0.713379             0.635775   \n",
       "B1 vs B2            1.000000         1.000000             0.785905   \n",
       "B2 vs B3            1.000000         1.000000             0.785905   \n",
       "B1 vs B3            1.000000         1.000000             0.785905   \n",
       "S1 vs B1            0.811328         0.632845             0.576888   \n",
       "S2 vs B2            0.813379         0.634896             0.574805   \n",
       "S3 vs B3            0.808398         0.633008             0.577604   \n",
       "\n",
       "          rule_intersect_w0_frac  \n",
       "S1 vs S2                0.776139  \n",
       "S2 vs S3                0.787598  \n",
       "S1 vs S3                0.783822  \n",
       "B1 vs B2                1.000000  \n",
       "B2 vs B3                1.000000  \n",
       "B1 vs B3                1.000000  \n",
       "S1 vs B1                0.707943  \n",
       "S2 vs B2                0.711361  \n",
       "S3 vs B3                0.711100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only disply coumns with name containing \"frac\"\n",
    "display(df.filter(regex='frac'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_S12 = eval_sample_match(samples_S1, samples_S2)\n",
    "stats_dict_B12 = eval_sample_match(samples_B1, samples_B2)\n",
    "stats_dict_S12\n",
    "stats_dict_B12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.71 (1762913/2488320)\n",
      "Sample C3 rule match frac: 0.750 (7683/10240)\n",
      "Sample C2 rule match frac: 0.811 (8308/10240)\n",
      "Row all rule match frac: 0.633 (19441/30720)\n",
      "Row any rule overlap frac: 0.577 (17722/30720)\n",
      "Row any rule overlap with empty frac: 0.708 (21748/30720)\n",
      "sample match frac: 0.00 (0/10240)\n",
      "entry match frac: 0.70 (1737498/2488320)\n",
      "Sample C3 rule match frac: 0.756 (7737/10240)\n",
      "Sample C2 rule match frac: 0.813 (8329/10240)\n",
      "Row all rule match frac: 0.635 (19504/30720)\n",
      "Row any rule overlap frac: 0.575 (17658/30720)\n",
      "Row any rule overlap with empty frac: 0.711 (21853/30720)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entry_match_frac': tensor(0.6983),\n",
       " 'entry_match_cnt': tensor(1737498),\n",
       " 'entry_match_total': 2488320,\n",
       " 'sample_match_frac': tensor(0.),\n",
       " 'sample_match_cnt': tensor(0),\n",
       " 'sample_match_total': 10240,\n",
       " 'C3_rule_match_frac': 0.75556640625,\n",
       " 'C3_rule_match_cnt': 7737,\n",
       " 'C3_rule_match_total': 10240,\n",
       " 'C2_rule_match_frac': 0.81337890625,\n",
       " 'C2_rule_match_cnt': 8329,\n",
       " 'C2_rule_match_total': 10240,\n",
       " 'rule_match_frac': 0.6348958333333333,\n",
       " 'rule_match_cnt': 19504,\n",
       " 'rule_match_total': 30720,\n",
       " 'rule_intersect_frac': 0.5748046875,\n",
       " 'rule_intersect_cnt': 17658,\n",
       " 'rule_intersect_total': 30720,\n",
       " 'rule_intersect_w0_frac': 0.7113606770833333,\n",
       " 'rule_intersect_w0_cnt': 21853,\n",
       " 'rule_intersect_w0_total': 30720}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict_SB1 = eval_sample_match(samples_S1, samples_B1)\n",
    "stats_dict_SB2 = eval_sample_match(samples_S2, samples_B2)\n",
    "stats_dict_SB1\n",
    "stats_dict_SB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large scale running sampling for valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1600',\n",
       " '111-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601',\n",
       " '113-RAVEN10_abstract-uncond-DiT_S_1-stream0_16M_heldout0_rep_20241114-1601',\n",
       " '110-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1600',\n",
       " '111-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601',\n",
       " '112-RAVEN10_abstract-uncond-DiT_B_1-stream0_16M_heldout0_rep_20241114-1601']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9b6d35cd4d4f30b5a6f7189b8269cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_DiT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m samples \u001b[38;5;241m=\u001b[39m ((samples\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m*\u001b[39m dataset_Xstd) \u001b[38;5;241m+\u001b[39m dataset_Xmean)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     13\u001b[0m r3_list, r2_list, rule_col \u001b[38;5;241m=\u001b[39m infer_rule_from_sample_batch(samples)\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/gaussian_diffusion.py:618\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample_loop\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03mGenerate samples from the model using DDIM.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03mSame usage as p_sample_loop().\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    617\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mddim_sample_loop_progressive(\n\u001b[1;32m    619\u001b[0m     model,\n\u001b[1;32m    620\u001b[0m     shape,\n\u001b[1;32m    621\u001b[0m     noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    622\u001b[0m     clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised,\n\u001b[1;32m    623\u001b[0m     denoised_fn\u001b[38;5;241m=\u001b[39mdenoised_fn,\n\u001b[1;32m    624\u001b[0m     cond_fn\u001b[38;5;241m=\u001b[39mcond_fn,\n\u001b[1;32m    625\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    626\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[1;32m    628\u001b[0m     eta\u001b[38;5;241m=\u001b[39meta,\n\u001b[1;32m    629\u001b[0m ):\n\u001b[1;32m    630\u001b[0m     final \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/gaussian_diffusion.py:669\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample_loop_progressive\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[0m\n\u001b[1;32m    667\u001b[0m t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor([i] \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 669\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddim_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m out\n\u001b[1;32m    680\u001b[0m     img \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/gaussian_diffusion.py:528\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_sample\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs, eta)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mddim_sample\u001b[39m(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    515\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    523\u001b[0m ):\n\u001b[1;32m    524\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    Sample x_{t-1} from the model using DDIM.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    Same usage as p_sample().\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cond_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    537\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcondition_score(cond_fn, out, x, t, model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs)\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/respace.py:92\u001b[0m, in \u001b[0;36mSpacedDiffusion.p_mean_variance\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/gaussian_diffusion.py:288\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model_output\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (B, C \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    287\u001b[0m model_output, model_var_values \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39msplit(model_output, C, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m min_log \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_into_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_log_variance_clipped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m max_log \u001b[38;5;241m=\u001b[39m _extract_into_tensor(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbetas), t, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# The model_var_values is [-1, 1] for [min_var, max_var].\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/DiT/diffusion/gaussian_diffusion.py:870\u001b[0m, in \u001b[0;36m_extract_into_tensor\u001b[0;34m(arr, timesteps, broadcast_shape)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_into_tensor\u001b[39m(arr, timesteps, broadcast_shape):\n\u001b[1;32m    862\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;124;03m    Extract values from a 1-D numpy array for a batch of indices.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m    :param arr: the 1-D numpy array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 870\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[timesteps]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(broadcast_shape):\n\u001b[1;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10240\n",
    "RND_SEED = 42\n",
    "for expname in expnames[3:6]:\n",
    "    model_DiT = load_DiT_model(expname, 1000000, use_ema=True, \n",
    "                               cfg=\"DiT_S_1\" if \"DiT_S_1\" in expname else \"DiT_B_1\")\n",
    "    noise = th.randn(batch_size, 3, 9, 9, device=\"cuda\", generator=th.Generator(device=\"cuda\").manual_seed(RND_SEED))\n",
    "    y = th.zeros(batch_size, dtype=torch.int, device=\"cuda\")\n",
    "    model_kwargs = dict(y=y)\n",
    "    with th.no_grad():\n",
    "        samples = diffusion_eval.ddim_sample_loop(model_DiT, noise=noise, shape=(batch_size, 3, 9, 9), \n",
    "                                                  clip_denoised=False, device=\"cuda\", model_kwargs=model_kwargs, progress=True)\n",
    "    samples = ((samples.detach() * dataset_Xstd) + dataset_Xmean).cpu()\n",
    "    r3_list, r2_list, rule_col = infer_rule_from_sample_batch(samples)\n",
    "    C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(r3_list, r2_list, rule_col, verbose=True)\n",
    "    compute_confidence_interval(total, C3_count, confidence=0.95, verbose=True)\n",
    "    th.save(samples, join(outdir, f\"samples_{expname}.pth\"))\n",
    "    th.save({\"c3\": r3_list, \"c2\": r2_list, \"rule\": rule_col,\n",
    "             \"C3_count\": C3_count, \"C2_count\": C2_count, \"anyvalid_count\": anyvalid_count, \"total\": total\n",
    "             }, join(outdir, f\"eval_samples_{expname}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
