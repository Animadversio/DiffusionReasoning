{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate RAVEN dataset for diffusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np \n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Dataset: 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_list = [[20,20], [20,60], [20,100], \n",
    "#             [60,20], [60,60], [60,100], \n",
    "#             [100,20], [100,60], [100,100]]\n",
    "offset = 0\n",
    "pos_list = [[x + offset, y + offset] for x in [0, 40, 80] for y in [0, 40, 80]]\n",
    "d_PGM = torch.load('PGM_shape_size_color_normalized.pt') # torch.Size([7, 10, 10, 40, 40])\n",
    "\n",
    "def load_PGM_inputs(attr): \n",
    "    \"\"\"attr: (3, 9, 3), (num_panel, num_pos, num_attr)\"\"\"\n",
    "    inputs = -0.6891*torch.ones((3, 120 + 2*offset, 120 + 2*offset))\n",
    "    for i_panel in range(3): \n",
    "        for i_pos in range(9): \n",
    "            if attr[i_panel, i_pos, 0] != -1: \n",
    "                i_shape, i_size, i_color = attr[i_panel, i_pos]\n",
    "                x0, y0 = pos_list[i_pos]\n",
    "                inputs[i_panel, x0:(x0+40), y0:(y0+40)] = d_PGM[int(i_shape), int(i_size), int(i_color)]\n",
    "    return inputs \n",
    "\n",
    "class dataset_PGM_single(Dataset): \n",
    "    def __init__(self, attr_list): \n",
    "        \"\"\"attr_list: [num_samples, 3, 9, 3]\"\"\"\n",
    "        self.attr_list = attr_list  \n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.attr_list)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"attr: [3, 9, 3]\"\"\"\n",
    "        attr = self.attr_list[idx] \n",
    "        inputs = load_PGM_inputs(attr)\n",
    "        return inputs, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 10000, 3, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.load('train_inputs.pt') # [35, 10000, 3, 9, 3]\n",
    "print(train_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: \n",
    "i_class = 4\n",
    "dataset_class0 = dataset_PGM_single(train_inputs[i_class]) \n",
    "load_class0 = DataLoader(dataset_class0, batch_size=256, shuffle=False, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/holylabs/LABS/kempner_fellows/Users/binxuwang\n"
     ]
    }
   ],
   "source": [
    "!echo $WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2020-BigGAN\u001b[0m/         cifar10.zip         Imagenet64_val.zip    \u001b[01;34mMat_Statistics\u001b[0m/\n",
      "2020-BigGAN.zip      ffhq-64x64.zip      \u001b[01;34mimagenet-valid\u001b[0m/       \u001b[01;34mStimuli\u001b[0m/\n",
      "2021-EvolDecomp.zip  GAN_sample_fid.zip  img_align_celeba.zip  \u001b[01;34mstl10_binary\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls $WORK_DIR/Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/Github/DiffusionReasoning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:08, 48.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:01, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:01, 54.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:01, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:01, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:03, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:03, 52.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:02, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3333it [01:01, 54.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rootdir = r\"/n/home12/binxuwang/Datasets/RAVEN_Datasets/PGM\"\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "# Fix random seed for generator\n",
    "for i_class in range(train_inputs.shape[0]):\n",
    "    if i_class == 10:\n",
    "        break\n",
    "    os.makedirs(join(rootdir,f'rule{i_class}'), exist_ok=True)\n",
    "    rule_dir = join(rootdir,f'rule{i_class}')\n",
    "    dataset_class0 = dataset_PGM_single(train_inputs[i_class]) \n",
    "    set_seed(42)\n",
    "    load_class0 = DataLoader(dataset_class0, batch_size=3, shuffle=True, pin_memory=True, drop_last=True) \n",
    "    for i_batch, (inputs, row_ids) in tqdm(enumerate(load_class0)):\n",
    "        # print(inputs.shape)\n",
    "        # print(row_ids)\n",
    "        inputs = 1 - inputs / (-0.6891)\n",
    "        mtg = make_grid(inputs.reshape(-1, 1, 120 + 2*offset, 120 + 2*offset), nrow=3, padding=1, pad_value=1)\n",
    "        mtg_rsz = torchvision.transforms.functional.resize(mtg, (256, 256))\n",
    "        save_image(mtg, join(rule_dir, f'mtg_{row_ids[0]}_{row_ids[1]}_{row_ids[2]}.png'), )\n",
    "        # plt.imshow(mtg_rsz.permute(1, 2, 0))\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        # raise Exception\n",
    "    print(f'rule {i_class} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mdataset_PGM_abstract\u001b[39;00m(\u001b[43mDataset\u001b[49m): \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cmb_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3333\u001b[39m, train_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"attr_list: [num_samples, 3, 9, 3]\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 122, 364])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "inputs = next(iter(load_class0))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "mtg1 = make_grid(inputs[2,][:,None] / -0.6891, nrow=3, padding=0, pad_value=1)\n",
    "mtg2 = make_grid(inputs[4,][:,None] / -0.6891, nrow=3, padding=0, pad_value=1)\n",
    "mtg3 = make_grid(inputs[10,][:,None] / -0.6891, nrow=3, padding=0, pad_value=1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(torchvision.transforms.Resize((192, 192))(\n",
    "           torch.cat([mtg1, mtg2, mtg3], dim=1),).permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Attribute Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  0,  1,  2,  3,  4,  5,  6])\n",
      "tensor([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
      "tensor([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[i_class][:,:,:,0].to(int).unique())\n",
    "print(train_inputs[i_class][:,:,:,1].to(int).unique())\n",
    "print(train_inputs[i_class][:,:,:,2].to(int).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_PGM_abstract(attr): \n",
    "    \"\"\"attr: (3, 9, 3), (num_panel, num_pos, num_attr)\"\"\"\n",
    "    attr = attr.to(int)\n",
    "    attr = torch.cat(tuple(attr.view(3, 3, 3, 3)), dim=1) # [3, 3, 3, 3] -> [3, 9, 3]\n",
    "    inputs = attr.permute(2, 0, 1) # num_attr, num_row=3, num_col (n panel x 3)\n",
    "    return inputs \n",
    "\n",
    "class dataset_PGM_abstract_single(Dataset): \n",
    "    def __init__(self, attr_list): \n",
    "        \"\"\"attr_list: [num_samples, 3, 9, 3]\"\"\"\n",
    "        self.attr_list = attr_list  \n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.attr_list)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"attr: [3, 9, 3]\"\"\"\n",
    "        attr = self.attr_list[idx] \n",
    "        inputs = load_PGM_abstract(attr)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "train_attrs = torch.load('/n/home12/binxuwang/Github/DiffusionReasoning/train_inputs.pt') # [35, 10000, 3, 9, 3]\n",
    "n_classes = train_attrs.shape[0]\n",
    "n_samples = train_attrs.shape[1]\n",
    "labels = torch.arange(0, n_classes).unsqueeze(1).expand(n_classes, n_samples)\n",
    "train_attrs = train_attrs.to(int)\n",
    "train_row_img = einops.rearrange(train_attrs, 'c s pnl (H W) att -> c s att H (pnl W)', H=3, W=3, att=3, pnl=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "# Create an infinite iterator from the dataloader\n",
    "\n",
    "dataloader = DataLoader(range(10), batch_size=3, shuffle=True, drop_last=True)\n",
    "# dataloader_cycle = itertools.cycle(dataloader)\n",
    "# Iterate over the dataloader\n",
    "tuples = []\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    tuples.append(batch)\n",
    "    # raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/35 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m         tuple_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mrange\u001b[39m(n_samples), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([iclass]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_class), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[1;32m     19\u001b[0m X_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(X_class)\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmb_per_class = 10000\n",
    "X = []\n",
    "y = []\n",
    "row_ids = []\n",
    "for iclass in trange(n_classes):\n",
    "    tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "    X_class = []\n",
    "    row_ids_cls = []\n",
    "    while True:\n",
    "        try:\n",
    "            batch = next(iter(tuple_loader))\n",
    "            row_ids_cls.append(batch)\n",
    "            if len(row_ids_cls) == cmb_per_class:\n",
    "                break\n",
    "        except StopIteration:\n",
    "            tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "    raise Exception\n",
    "    y_class = torch.tensor([iclass]*len(X_class), dtype=torch.int)\n",
    "    X_class = torch.stack(X_class)\n",
    "    row_ids_cls = torch.stack(row_ids_cls)\n",
    "    y.append(y_class)\n",
    "    X.append(X_class)\n",
    "    row_ids.append(row_ids_cls)\n",
    "X = torch.cat(X, dim=0)\n",
    "y = torch.cat(y, dim=0)\n",
    "row_ids = torch.cat(row_ids, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7863, 1287, 1122],\n",
       "        [9583,  201, 7632],\n",
       "        [9221, 3243, 9831],\n",
       "        ...,\n",
       "        [6937, 6762, 1933],\n",
       "        [5194, 1758, 6915],\n",
       "        [3969, 2907, 8533]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(row_ids_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_panels(train_row_img, cmb_per_class=3333):\n",
    "    n_classes = train_row_img.shape[0]\n",
    "    n_samples = train_row_img.shape[1]\n",
    "    X = []\n",
    "    y = []\n",
    "    row_ids = []\n",
    "    for iclass in trange(n_classes):\n",
    "        tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "        X_class = []\n",
    "        row_ids_cls = []\n",
    "        while True:\n",
    "            try:\n",
    "                batch = next(iter(tuple_loader))\n",
    "                rows = train_row_img[iclass][batch]\n",
    "                mtg = torch.cat(tuple(rows), dim=1)\n",
    "                X_class.append(mtg)\n",
    "                row_ids_cls.append(batch)\n",
    "                if len(X_class) == cmb_per_class:\n",
    "                    break\n",
    "            except StopIteration:\n",
    "                tuple_loader = DataLoader(range(n_samples), batch_size=3, shuffle=True, drop_last=True)\n",
    "\n",
    "        y_class = torch.tensor([iclass]*len(X_class), dtype=torch.int)\n",
    "        X_class = torch.stack(X_class)\n",
    "        row_ids_cls = torch.stack(row_ids_cls)\n",
    "        y.append(y_class)\n",
    "        X.append(X_class)\n",
    "        row_ids.append(row_ids_cls)\n",
    "    X = torch.cat(X, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    row_ids = torch.cat(row_ids, dim=0)\n",
    "    return X, y, row_ids\n",
    "\n",
    "\n",
    "class dataset_PGM_abstract(Dataset): \n",
    "    def __init__(self, cmb_per_class=3333, train_attrs=None, device=\"cpu\", onehot=False): \n",
    "        \"\"\"attr_list: [num_samples, 3, 9, 3]\"\"\"\n",
    "        if train_attrs is None:\n",
    "            train_attrs = torch.load('/n/home12/binxuwang/Github/DiffusionReasoning/train_inputs.pt') # [35, 10000, 3, 9, 3]\n",
    "        n_classes = train_attrs.shape[0] # 35\n",
    "        n_samples = train_attrs.shape[1] # 10k\n",
    "        self.labels = torch.arange(0, n_classes).unsqueeze(1).expand(n_classes, n_samples)\n",
    "        train_attrs = train_attrs.to(int)\n",
    "        self.train_row_img = einops.rearrange(train_attrs, 'c s pnl (H W) attr -> c s attr H (pnl W)', H=3, W=3, attr=3, pnl=3)\n",
    "        self.X, self.y, self.row_ids = _sample_panels(self.train_row_img, cmb_per_class)\n",
    "        self.X = self.X.to(device) # [35 * cmb_per_class, 3, 9, 9]\n",
    "        if onehot is True:\n",
    "            O1 = torch.eye(7, 7, dtype=int)\n",
    "            O2 = torch.eye(10, 10, dtype=int)\n",
    "            O3 = torch.eye(10, 10, dtype=int)\n",
    "            X_onehot = torch.cat([O1[self.X[:, 0], :], O2[self.X[:, 1], :], O3[self.X[:, 2], :], ], dim=-1)\n",
    "            print(X_onehot.shape)\n",
    "            self.X = einops.rearrange(X_onehot, 'b h w C -> b C h w')\n",
    "            print(self.X.shape)\n",
    "            self.Xmean = torch.tensor([0.5, ]).view(1, 1, 1, 1)\n",
    "            self.Xstd = torch.tensor([0.5, ]).view(1, 1, 1, 1)\n",
    "            self.X = (self.X.float() - self.Xmean) / self.Xstd\n",
    "        else:\n",
    "            self.Xmean = torch.tensor([1.5, 2.5, 2.5]).view(1, 3, 1, 1).to(device)\n",
    "            self.Xstd = torch.tensor([2.5, 3.5, 3.5]).view(1, 3, 1, 1).to(device)\n",
    "            self.X = (self.X - self.Xmean) / self.Xstd\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"attr: [3, 9, 3]\"\"\"\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def dict(self):\n",
    "        return {'row_ids': self.row_ids, 'y': self.y}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:35<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_PGM_abstract(cmb_per_class=3333, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:00<00:00, 312.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 9, 9, 27])\n",
      "torch.Size([350, 27, 9, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_PGM_abstract(cmb_per_class=10, onehot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4295, 2.3996, 2.4022])\n",
      "tensor([2.4291, 3.4340, 3.4326])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.X.float().mean(dim=(0,2,3)))\n",
    "print(dataset.X.float().std(dim=(0,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_PGM_abstract(cmb_per_class=3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350000, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.row_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 10000, 3, 9, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attrs.shape # [35, 10000, 3, 9, 3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 10000, 3, 3, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.rearrange(train_attrs, 'c s pnl (H W) att -> c s att H (pnl W)', H=3, W=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 10000, 3, 3, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_row_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_attrs = train_attrs.view(n_classes * n_samples, 3, 9, 3) # 3 panels, 9 positions, 3 attributes\n",
    "train_attrs.permute(0, 3, 1, 2).shape\n",
    "train_attrs = train_attrs.view(n_classes * n_samples, 3, 3, 3, 3) # [n_classes * n_samples, 9, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_abstr = dataset_PGM_abstract_single(train_inputs[i_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1,  4,  4,  1,  1,  1, -1,  3, -1],\n",
       "         [ 4,  4,  4,  1,  1,  1, -1, -1, -1],\n",
       "         [-1, -1,  4,  1,  1,  1, -1, -1,  3]],\n",
       "\n",
       "        [[-1,  6,  5,  5,  6,  2, -1,  7, -1],\n",
       "         [ 5,  3,  2,  0,  5,  0, -1, -1, -1],\n",
       "         [-1, -1,  0,  3,  7,  4, -1, -1,  5]],\n",
       "\n",
       "        [[-1,  0,  0,  2,  2,  2, -1,  4, -1],\n",
       "         [ 0,  0,  0,  2,  2,  2, -1, -1, -1],\n",
       "         [-1, -1,  0,  2,  2,  2, -1, -1,  7]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset_abstr[1].shape)\n",
    "dataset_abstr[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
