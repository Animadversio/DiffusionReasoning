{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import einops\n",
    "# Import necessary libraries\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "from tqdm import tqdm, trange\n",
    "# from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "# Initialize the GPT-2 model and tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_config(GPT2Config())\n",
    "# model = GPT2LMHeadModel.from_config(GPT2Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration\n",
    "config = GPT2Config(\n",
    "    vocab_size=27,\n",
    "    n_positions=128,\n",
    "    n_ctx=1024,\n",
    "    n_embd=768,\n",
    "    n_layer=12,\n",
    "    n_head=12,\n",
    "    activation_function='gelu_new',\n",
    "    resid_pdrop=0.1,\n",
    "    embd_pdrop=0.1,\n",
    "    attn_pdrop=0.1,\n",
    "    layer_norm_epsilon=1e-5,\n",
    "    initializer_range=0.02,\n",
    "    summary_type='cls_index',\n",
    "    summary_use_proj=True,\n",
    "    summary_activation=None,\n",
    "    summary_proj_to_labels=True,\n",
    "    summary_first_dropout=0.1,\n",
    "    bos_token_id=50256,\n",
    "    eos_token_id=50256,\n",
    "    gradient_checkpointing=False,\n",
    ")\n",
    "# Create the model\n",
    "model = GPT2Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 12000, 3, 9, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/n/home12/binxuwang/Github/DiffusionReasoning/'\n",
    "attr_all = np.load(data_dir+'attr_all.npy')\n",
    "print(attr_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/einops/parsing.py:136: RuntimeWarning: It is discouraged to use axes names that are keywords: class\n",
      "  warnings.warn(\"It is discouraged to use axes names that are keywords: {}\".format(name), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_ids(attr_seq_tsr, ):\n",
    "    \"\"\" Add 1 to all attribute values, such that -1 becomes 0. \n",
    "    then the index is valid as token. \"\"\"\n",
    "    attr_seq_tsr_pps = attr_seq_tsr.clone() + 1\n",
    "    return attr_seq_tsr_pps\n",
    "\n",
    "attr_all_rows = torch.tensor(attr_all)\n",
    "attr_tsr = einops.rearrange(attr_all_rows,  'class (B R) p (h w) attr -> class B attr (R h) (p w)', h=3,w=3,p=3,R=3)\n",
    "attr_seq_tsr = einops.rearrange(attr_tsr,  'class B attr (R h) (p w) -> (class B) (R p h w) attr', h=3,w=3,p=3,R=3)\n",
    "attr_seq_tsr_pps = preprocess_ids(attr_seq_tsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepWordEmbed(nn.Module):\n",
    "    def __init__(self, embed_dims=(7,10,10), embed_size=256):\n",
    "        super(SepWordEmbed, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(embed_dims[0]+1, embed_size)\n",
    "        self.embedding2 = nn.Embedding(embed_dims[1]+1, embed_size)\n",
    "        self.embedding3 = nn.Embedding(embed_dims[2]+1, embed_size)\n",
    "\n",
    "    def forward(self, attr_seq_tsr):\n",
    "        # split the attr_seq_tsr into three parts along the last dimension\n",
    "        # attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3 = torch.split(attr_seq_tsr, [1,1,1], dim=-1)\n",
    "        attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3 = attr_seq_tsr[...,0], attr_seq_tsr[...,1], attr_seq_tsr[...,2]\n",
    "        # attr_seq_embed = self.embedding1(attr_seq_tsr_1) + self.embedding2(attr_seq_tsr_2) + self.embedding3(attr_seq_tsr_3)\n",
    "        attr_seq_embed = th.concat([self.embedding1(attr_seq_tsr_1), \n",
    "                                    self.embedding2(attr_seq_tsr_2), \n",
    "                                    self.embedding3(attr_seq_tsr_3)], dim=-1)\n",
    "        return attr_seq_embed\n",
    "    \n",
    "class SepLMhead(nn.Module):\n",
    "    def __init__(self, embed_dims=(7,10,10), embed_size=256):\n",
    "        super(SepLMhead, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.lmhead1 = nn.Linear(embed_size, embed_dims[0]+1)\n",
    "        self.lmhead2 = nn.Linear(embed_size, embed_dims[1]+1)\n",
    "        self.lmhead3 = nn.Linear(embed_size, embed_dims[2]+1)\n",
    "        \n",
    "    def forward(self, attr_seq_embed):\n",
    "        embed1, embed2, embed3 = torch.split(attr_seq_embed, [self.embed_size,self.embed_size,self.embed_size], dim=-1)\n",
    "        attr_seq_tsr_1 = self.lmhead1(embed1)\n",
    "        attr_seq_tsr_2 = self.lmhead2(embed2)\n",
    "        attr_seq_tsr_3 = self.lmhead3(embed3)\n",
    "        return attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3\n",
    "        \n",
    "\n",
    "class MultiIdxGPT2Model(nn.Module):\n",
    "    def __init__(self, attribute_dims=(7,10,10), vocab_size=0, max_length=128, n_embd=768, n_class=0):\n",
    "        super().__init__()\n",
    "        self.sep_word_embed = SepWordEmbed(attribute_dims, embed_size=n_embd//3)\n",
    "        # Combine embeddings\n",
    "        combined_embedding_size = n_embd  # Adjust based on your combination strategy\n",
    "        config = GPT2Config(vocab_size=vocab_size, n_positions=max_length, n_embd=combined_embedding_size)\n",
    "        # config = GPT2Config(\n",
    "        #     vocab_size=27,\n",
    "        #     n_positions=128,\n",
    "        #     n_ctx=128,\n",
    "        #     n_embd=768,\n",
    "        #     n_layer=12,\n",
    "        #     n_head=12,\n",
    "        #     activation_function='gelu_new',\n",
    "        #     resid_pdrop=0.1,\n",
    "        #     embd_pdrop=0.1,\n",
    "        #     attn_pdrop=0.1,\n",
    "        #     layer_norm_epsilon=1e-5,\n",
    "        #     initializer_range=0.02,\n",
    "        #     summary_type='cls_index',\n",
    "        #     summary_use_proj=True,\n",
    "        #     summary_activation=None,\n",
    "        #     summary_proj_to_labels=True,\n",
    "        #     summary_first_dropout=0.1,\n",
    "        #     bos_token_id=50256,\n",
    "        #     eos_token_id=50256,\n",
    "        #     gradient_checkpointing=False,\n",
    "        # )\n",
    "        self.gpt2 = GPT2Model(config)\n",
    "        self.multi_lmhead = SepLMhead(attribute_dims, embed_size=n_embd//3)\n",
    "        self.context_embed = nn.Embedding(1+n_class, n_embd)\n",
    "\n",
    "    def forward(self, input_ids, y=None):\n",
    "        # input_ids is expected to be a list of three tensors [attr1, attr2, attr3]\n",
    "        if y is None:\n",
    "            y = torch.zeros(input_ids.shape[0], dtype=th.long).to(input_ids[0].device)\n",
    "        ctx_vec = self.context_embed(y)\n",
    "        combined_embedding = self.sep_word_embed(input_ids)\n",
    "        combined_embedding = torch.concat([ctx_vec[:,None,:], combined_embedding,], dim=1)\n",
    "        outputs = self.gpt2(inputs_embeds=combined_embedding)\n",
    "        logits_attr1, logits_attr2, logits_attr3 = self.multi_lmhead(outputs.last_hidden_state)\n",
    "        return outputs, logits_attr1, logits_attr2, logits_attr3\n",
    "    \n",
    "\n",
    "def multi_attr_loss(outputs, targets, loss_fn=F.cross_entropy, ):\n",
    "    logits1, logits2, logits3 = outputs[0], outputs[1], outputs[2]\n",
    "    loss1 = loss_fn(logits1.permute(0,2,1), targets[..., 0])\n",
    "    loss2 = loss_fn(logits2.permute(0,2,1), targets[..., 1])\n",
    "    loss3 = loss_fn(logits3.permute(0,2,1), targets[..., 2])\n",
    "    return loss1 + loss2 + loss3\n",
    "\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/e34da3ee3c9d2d628fdbeb60cee45c4f8f32945a/src/transformers/models/gpt2/modeling_gpt2.py#L1338C13-L1339C1\n",
    "# loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "def multi_attr_loss_vec(outputs, targets, loss_fn=F.cross_entropy, ):\n",
    "    logits1, logits2, logits3 = outputs[0], outputs[1], outputs[2]\n",
    "    loss1 = loss_fn(logits1.reshape(-1, logits1.size(-1)), targets[..., 0].view(-1))\n",
    "    loss2 = loss_fn(logits2.reshape(-1, logits2.size(-1)), targets[..., 1].view(-1))\n",
    "    loss3 = loss_fn(logits3.reshape(-1, logits3.size(-1)), targets[..., 2].view(-1))\n",
    "    return loss1 + loss2 + loss3\n",
    "\n",
    "def next_token_loss(outputs, targets, loss_fn=F.cross_entropy):\n",
    "    logits1, logits2, logits3 = outputs[0], outputs[1], outputs[2]\n",
    "    loss1 = loss_fn(logits1[:, :-1, :].permute(0,2,1), targets[:, 1:, 0])\n",
    "    loss2 = loss_fn(logits2[:, :-1, :].permute(0,2,1), targets[:, 1:, 1])\n",
    "    loss3 = loss_fn(logits3[:, :-1, :].permute(0,2,1), targets[:, 1:, 2])\n",
    "    return loss1 + loss2 + loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_raven = MultiIdxGPT2Model(attribute_dims=(7,10,10), vocab_size=27, max_length=82, n_embd=768, n_class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = attr_seq_tsr_pps[:30,].clone()\n",
    "outputs, logits_attr1, logits_attr2, logits_attr3 = gpt2_raven(inputs)\n",
    "loss = multi_attr_loss([logits_attr1[:,:-1], logits_attr2[:,:-1], logits_attr3[:,:-1]], inputs)\n",
    "# loss = next_token_loss((logits_attr1, logits_attr2, logits_attr3), inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(attr_seq_tsr_pps, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_next_token(model, prefix_inputs, max_length=81, strategy=\"greedy\", device=\"cuda\"):\n",
    "    prefix_inputs = prefix_inputs.to(device)\n",
    "    model.eval().to(device)\n",
    "    prefix_length = prefix_inputs.size(1)\n",
    "    for i in range(max_length - prefix_length):\n",
    "        outputs, logits1, logits2, logits3 = model(prefix_inputs)\n",
    "        if strategy == \"greedy\":\n",
    "            next_token1 = torch.argmax(logits1[:, -1, :], dim=-1, keepdim=True)\n",
    "            next_token2 = torch.argmax(logits2[:, -1, :], dim=-1, keepdim=True)\n",
    "            next_token3 = torch.argmax(logits3[:, -1, :], dim=-1, keepdim=True)\n",
    "        elif strategy == \"sample\":\n",
    "            next_token1 = torch.multinomial(F.softmax(logits1[:, -1, :], dim=-1), num_samples=1)\n",
    "            next_token2 = torch.multinomial(F.softmax(logits2[:, -1, :], dim=-1), num_samples=1)\n",
    "            next_token3 = torch.multinomial(F.softmax(logits3[:, -1, :], dim=-1), num_samples=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy\")\n",
    "        next_token = torch.cat([next_token1, next_token2, next_token3], dim=-1)\n",
    "        prefix_inputs = torch.cat([prefix_inputs, next_token[:,None,:]], dim=1)\n",
    "    return prefix_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/n/home12/binxuwang/Github/DiffusionReasoning/')\n",
    "from rule_new_utils import check_r3_r2_batch, infer_rule_from_sample_batch\n",
    "\n",
    "def seqtsr2imgtsr(seqtsr, h=3, w=3, p=3, R=3):\n",
    "    imgtsr = einops.rearrange(seqtsr, 'B (R p h w) attr -> B attr (R h) (p w)', h=h, w=w, p=p, R=R)\n",
    "    return imgtsr\n",
    "\n",
    "def seqtsr2attrtsr(seqtsr, h=3, w=3, p=3, R=3):\n",
    "    attrtsr = einops.rearrange(seqtsr, 'B (R p h w) attr -> B R p (h w) attr', h=h, w=w, p=p, R=R)\n",
    "    return attrtsr\n",
    "\n",
    "def compute_rule_statistics(r3_list, r2_list, rule_col):\n",
    "    r3_count = sum([len(x) > 0 for x in r3_list])\n",
    "    r2_count = sum([len(x) > 0 for x in r2_list])\n",
    "    rule_flatten = np.array(rule_col, dtype=object).flatten() # [3 * 1024]\n",
    "    anyvalid_count = sum([len(x) > 0 for x in rule_flatten])\n",
    "    total = len(r3_list)\n",
    "    return r3_count, r2_count, anyvalid_count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def completion_eval(eval_samples, model, device='cuda', num_mask=9, strategy=\"greedy\", batch_size=512):\n",
    "    eval_samples = eval_samples.to(device)\n",
    "    eval_complete = []\n",
    "    for idx in trange(0, eval_samples.size(0), batch_size):\n",
    "        eval_batch = eval_samples[idx:idx+batch_size]\n",
    "        eval_complete_batch = sample_next_token(model, eval_batch[:,:-num_mask,:], \n",
    "                                          max_length=81, strategy=strategy, device=device).cpu()\n",
    "        eval_complete.append(eval_complete_batch)\n",
    "    eval_complete = torch.cat(eval_complete, dim=0)\n",
    "    # eval_complete = sample_next_token(model, eval_samples[:,:-num_mask,:], \n",
    "    #                                   max_length=81, strategy=strategy, device=device).cpu()\n",
    "    # eval_complete_attr = seqtsr2attrtsr(eval_complete, h=3, w=3, p=3, R=3)\n",
    "    eval_complete = eval_complete - 1\n",
    "    eval_complete_img = seqtsr2imgtsr(eval_complete, h=3, w=3, p=3, R=3)\n",
    "    C3_list, C2_list, rule_col_list = infer_rule_from_sample_batch(eval_complete_img)\n",
    "    C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(C3_list, C2_list, rule_col_list)\n",
    "    # final_row = np.array(rule_col_list, dtype=object)[:,-1]\n",
    "    # anyvalid_count = sum([len(x) > 0 for x in final_row])\n",
    "    print(f\"Completion: C3: {C3_count / total:.3f} [{C3_count}/{total}],  valid: {anyvalid_count / total / 3:.3f} [{anyvalid_count}/{total*3}]\")\n",
    "    return eval_complete, C3_list, C2_list, rule_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_all_rows = torch.tensor(attr_all)\n",
    "attr_img_tsr = einops.rearrange(attr_all_rows,  'class (B R) p (h w) attr -> class B attr (R h) (p w)', h=3,w=3,p=3,R=3)\n",
    "attr_img_tsr_train, attr_img_tsr_val = attr_img_tsr[:, :3950], attr_img_tsr[:, 3950:]\n",
    "attr_seq_tsr_train = einops.rearrange(attr_img_tsr_train,  'class B attr (R h) (p w) -> (class B) (R p h w) attr', h=3,w=3,p=3,R=3)\n",
    "attr_seq_tsr_val = einops.rearrange(attr_img_tsr_val,  'class B attr (R h) (p w) -> (class B) (R p h w) attr', h=3,w=3,p=3,R=3)\n",
    "attr_seq_tsr_train = preprocess_ids(attr_seq_tsr_train)\n",
    "attr_seq_tsr_val = preprocess_ids(attr_seq_tsr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 81, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_seq_tsr_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8b21ad20844d8da3559e49d129b4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 0/512,  valid: 1024/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a864d54e3d84412869fbb9617771009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 76/512,  valid: 1368/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da019998f09c4a44b708373bb21465ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 84/512,  valid: 1367/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193c235ee3f046f8997152b1194b7390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 121/512,  valid: 1395/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c779bb56e04113a251d8a2563770a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 163/512,  valid: 1425/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37f35ce6df544919a412d9543378cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 145/512,  valid: 1369/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0522d7c89f7143e7a0ec3e46727505b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 191/512,  valid: 1363/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07b64c4567649ceaaa7ba623d5ad9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 176/512,  valid: 1321/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe52ba6e6f49434191f8cb542b6c1542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 268/512,  valid: 1393/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bde38bba86c48aaa75d21a184fb71c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 244/512,  valid: 1372/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2629ecde8484f1a85a235e71684b24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 240/512,  valid: 1345/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adcbf1d25c14c42860b9be8f438543f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 292/512,  valid: 1392/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8265bbffca90408fb2ea0cc3a2b6e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 235/512,  valid: 1330/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a915c6c0aa942119319f5e1fdb39ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 283/512,  valid: 1370/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b66d8dea0e4284bb50c1f5e9c3565f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 291/512,  valid: 1375/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04af5ee521ef43eb8e312df27d092b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 341/512,  valid: 1409/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a1d3259a6346109c323f47d0173e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 296/512,  valid: 1368/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74beb953ddf143aab16c925fea1bd741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 330/512,  valid: 1409/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bde181ba07413bb6ce31ba3505afa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 336/512,  valid: 1398/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8223a5e64a8245778227806f0f7d0de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 312/512,  valid: 1368/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299053ce6e08433d8c9ac45c1520f9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 340/512,  valid: 1408/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4639e86e326f4b6cadf27c5f68311f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 330/512,  valid: 1392/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300c3ba4862245e7be916bfc142ebdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 336/512,  valid: 1388/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4b6bf653004eb1a129050f53901aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 349/512,  valid: 1409/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e29c117e3a4c2995b0cc5ef74f5cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 335/512,  valid: 1390/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930eca1ac5e142d2908b1ff37a08e056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 337/512,  valid: 1397/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f17e234fd304d239b863bad6e9b098a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 332/512,  valid: 1391/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b2a3a6636a43818c7804cf754eb867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 359/512,  valid: 1401/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dd5d8050e645628b7c71607fee050b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 355/512,  valid: 1413/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91159542a704453eb9d3bb6616d9a27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 377/512,  valid: 1434/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bdc1d6a8384786b6c2286f7917c2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 375/512,  valid: 1427/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3329050ca3e94e8fbebbf9ee6add2fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 387/512,  valid: 1441/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65843f65f054e79bbded6f99d1077fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 360/512,  valid: 1417/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ee0701e8304eeda5df01f6ac73c897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 383/512,  valid: 1430/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72656e42e1c4ce9ac5f0e9786d9880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 366/512,  valid: 1417/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e6be546e6b4f87a5ac5ae387b338de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 353/512,  valid: 1410/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cc561d32ff47b1b85ec99f79d293b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 366/512,  valid: 1425/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f8d9fd715147c389e03d6a6f3ef55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 399/512,  valid: 1443/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54bef66d7734f9fbd5d7ad69cdc0da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 387/512,  valid: 1446/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2468767d6ab94d7cb3c04ec664a638d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 390/512,  valid: 1451/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c52e2616cd04751afbe2751d6c97b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 371/512,  valid: 1425/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766780267c1f400c965981385aa9f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 373/512,  valid: 1427/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c08210bf9724343b26d38ebbd10c1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 383/512,  valid: 1429/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf270fa0c5944c2a60a75f473b96bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 364/512,  valid: 1416/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d547a344b6478faf5f981652101fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 384/512,  valid: 1431/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3cd34eb4b1f4ebc9c5b95497cb03ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 385/512,  valid: 1442/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0df5bb8dba145e28a5cbb9ed9ce5e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 384/512,  valid: 1435/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddbe22df8c246ca8cfcb8e615a51f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 361/512,  valid: 1419/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98920c684b474f8a9cd6ae18d9466dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 372/512,  valid: 1430/1536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6807a5bf42304822bd496c6196afb5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 376/512,  valid: 1428/1536\n"
     ]
    }
   ],
   "source": [
    "gpt2_raven = MultiIdxGPT2Model(attribute_dims=(7,10,10), vocab_size=27, max_length=83, n_embd=768, n_class=0)\n",
    "# train loop\n",
    "optimizer = AdamW(gpt2_raven.parameters(), lr=1e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n",
    "# dataset = torch.utils.data.TensorDataset(attr_seq_tsr_pps)\n",
    "data_loader = torch.utils.data.DataLoader(attr_seq_tsr_train, batch_size=64, shuffle=True)\n",
    "gpt2_raven.train().to('cuda')\n",
    "for epoch in range(50):\n",
    "    gpt2_raven.train()\n",
    "    pbar = tqdm(data_loader)\n",
    "    for inputs in pbar:\n",
    "        inputs = inputs.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, logits_attr1, logits_attr2, logits_attr3 = gpt2_raven(inputs, y=None)\n",
    "        # note the inputs were pre-pended in gpt2 to add context\n",
    "        loss = multi_attr_loss_vec([logits_attr1[:,:-1], logits_attr2[:,:-1], logits_attr3[:,:-1]], \n",
    "                                inputs)\n",
    "        # loss = next_token_loss((attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3), inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'Loss: {loss.item()}')\n",
    "        # print(loss.item())\n",
    "    \n",
    "    rnd_idx = np.random.choice(len(attr_seq_tsr_val), 512)\n",
    "    gpt2_raven.eval()\n",
    "    eval_samples = attr_seq_tsr_val[rnd_idx,:,:]\n",
    "    eval_complete, C3_list, C2_list, rule_col_list = completion_eval(eval_samples, gpt2_raven, num_mask=9, device='cuda', strategy=\"greedy\")\n",
    "    torch.save({\"eval_complete\": eval_complete, \"C3_list\": C3_list, \"C2_list\": C2_list, \"rule_col_list\": rule_col_list}, f\"eval_epoch{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(gpt2_raven.state_dict(), 'gpt2_raven_fixed_new.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eca4604eded44de8e5e7384ec05d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 0/512,  valid: 0/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eaea3198a24ba4a79ada5230e20476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 12/512,  valid: 135/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdd34b1978f49f4918c533e8e51c7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 32/512,  valid: 344/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f2df9e24644135b603b8bc8faebed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 35/512,  valid: 364/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ebea8082ed477a8c46f44feb46da10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 28/512,  valid: 336/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3910f2443c48ff9c122b0d8d06bfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 26/512,  valid: 318/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc4a368024d4f21b6efcd4ca29f7dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 26/512,  valid: 321/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e538d8803ded481fa74f09fb062afdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 29/512,  valid: 330/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6619b23df3c249f994e30113487ff5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 24/512,  valid: 320/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919197798a154ebe888ea7a39d15bc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 33/512,  valid: 292/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa744eb79e9e45d7bcb4caa1af9bb6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 34/512,  valid: 288/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb6951e511c45b79b50061f3728298c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 28/512,  valid: 280/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3eac6adec754fb49978443c7a469363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 26/512,  valid: 277/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401a9b23aaa84c20863c4be43e87ddfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 33/512,  valid: 288/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787cce32541647c9be33c85be202e06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 35/512,  valid: 294/512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa92b08de3e4c17be992dbc30f25d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# loss = next_token_loss((attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3), inputs)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(loss.item())\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/transformers/optimization.py:486\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    484\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[1;32m    485\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m--> 486\u001b[0m denom \u001b[38;5;241m=\u001b[39m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# No bias correction for Bert\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpt2_raven = MultiIdxGPT2Model(attribute_dims=(7,10,10), vocab_size=27, max_length=83, n_embd=768, n_class=0)\n",
    "# train loop\n",
    "optimizer = AdamW(gpt2_raven.parameters(), lr=1e-4)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=1000)\n",
    "# dataset = torch.utils.data.TensorDataset(attr_seq_tsr_pps)\n",
    "data_loader = torch.utils.data.DataLoader(attr_seq_tsr_train, batch_size=64, shuffle=True)\n",
    "gpt2_raven.train().to('cuda')\n",
    "for epoch in range(50):\n",
    "    gpt2_raven.train()\n",
    "    pbar = tqdm(data_loader)\n",
    "    for inputs in pbar:\n",
    "        inputs = inputs.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, logits_attr1, logits_attr2, logits_attr3 = gpt2_raven(inputs)\n",
    "        loss = multi_attr_loss([logits_attr1[:,:-1], logits_attr2[:,:-1], logits_attr3[:,:-1]], inputs)\n",
    "        # loss = next_token_loss((attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3), inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'Loss: {loss.item()}')\n",
    "        # print(loss.item())\n",
    "    \n",
    "    rnd_idx = np.random.choice(len(attr_seq_tsr_val), 512)\n",
    "    gpt2_raven.eval()\n",
    "    eval_samples = attr_seq_tsr_val[rnd_idx,:,:]\n",
    "    eval_complete, C3_list, C2_list, rule_col_list = completion_eval(eval_samples, gpt2_raven, num_mask=9, device='cuda', strategy=\"greedy\")\n",
    "    torch.save({\"eval_complete\": eval_complete, \"C3_list\": C3_list, \"C2_list\": C2_list, \"rule_col_list\": rule_col_list}, f\"eval_epoch{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(gpt2_raven.state_dict(), 'gpt2_raven.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_raven = MultiIdxGPT2Model(attribute_dims=(7,10,10), vocab_size=27, max_length=83, n_embd=768, n_class=0)\n",
    "gpt2_raven.load_state_dict(th.load('gpt2_raven.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208, 82, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187c6750efae4b139f3e688a69c24aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.216092293532256e-08\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(attr_seq_tsr_val, batch_size=256, shuffle=True)\n",
    "gpt2_raven.eval().cuda()\n",
    "pbar = tqdm(val_loader)\n",
    "loss_sum = []\n",
    "for inputs in pbar:\n",
    "    inputs = inputs.cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs, logits_attr1, logits_attr2, logits_attr3 = gpt2_raven(inputs)\n",
    "        loss = multi_attr_loss_vec([logits_attr1[:,:-1], logits_attr2[:,:-1], logits_attr3[:,:-1]], inputs)\n",
    "    # loss = next_token_loss((attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3), inputs)\n",
    "    pbar.set_description(f'Loss: {loss.item()}')\n",
    "    # print(loss.item())\n",
    "    loss_sum.append(loss.item())\n",
    "print(np.mean(loss_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8e0a91c3504d10bb6a916942eddaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.312208572333388e-11\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(attr_seq_tsr_val, batch_size=256, shuffle=True)\n",
    "gpt2_raven.eval().cuda()\n",
    "pbar = tqdm(val_loader)\n",
    "loss_sum = []\n",
    "for inputs in pbar:\n",
    "    inputs = inputs.cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs, logits_attr1, logits_attr2, logits_attr3 = gpt2_raven(inputs)\n",
    "        loss = multi_attr_loss([logits_attr1[:,:-1], logits_attr2[:,:-1], logits_attr3[:,:-1]], inputs)\n",
    "    # loss = next_token_loss((attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3), inputs)\n",
    "    pbar.set_description(f'Loss: {loss.item()}')\n",
    "    # print(loss.item())\n",
    "    loss_sum.append(loss.item())\n",
    "print(np.mean(loss_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4639, device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logits_attr1.argmax(-1)[:,1:] == inputs[:, :, 0]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_loss((logits_attr1[:,1:], logits_attr2[:,1:], logits_attr3[:,1:]), inputs[:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 0/20,  valid: 10/20\n"
     ]
    }
   ],
   "source": [
    "eval_samples = attr_seq_tsr_pps[10020:10040]\n",
    "eval_complete, C3_list, C2_list, rule_col_list = completion_eval(eval_samples, gpt2_raven, num_mask=54, device='cuda', strategy=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion: C3: 0/50,  valid: 109/150\n"
     ]
    }
   ],
   "source": [
    "eval_samples = attr_seq_tsr_pps[:50]\n",
    "eval_complete = sample_next_token(gpt2_raven, eval_samples[:, :-9, :], max_length=81, \n",
    "                                  strategy=\"sample\", device=\"cuda\").cpu() #sample\n",
    "img_tsr_complete = seqtsr2imgtsr(eval_complete, )\n",
    "C3_list, C2_list, rule_col_list = infer_rule_from_sample_batch(img_tsr_complete-1)\n",
    "C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(C3_list, C2_list, rule_col_list)\n",
    "print(f\"Completion: C3: {C3_count}/{total},  valid: {anyvalid_count}/{total*3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3_count, C2_count, anyvalid_count, total = compute_rule_statistics(C3_list, C2_list, rule_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 81, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt2_raven.context_embed(torch.zeros(2, dtype=th.long)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 81, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_seq_tsr_pps[:30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 81, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_raven.sep_word_embed(attr_seq_tsr_pps[:30]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, attr_seq_tsr_1, attr_seq_tsr_2, attr_seq_tsr_3 = gpt2_raven(attr_seq_tsr_pps[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 81, 11])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_seq_tsr_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 81, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_seq_tsr_pps[:30,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 81, 256])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1(attr_seq_tsr_pps[:5,:,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4000, 3, 9, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_tsr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and validation datasets\n",
    "# train_dataset = TextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"train.txt\",\n",
    "#     block_size=128\n",
    "# )\n",
    "# valid_dataset = TextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=\"valid.txt\",\n",
    "#     block_size=128\n",
    "# )\n",
    "\n",
    "# Define a data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,\n",
    ")\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", # The output directory\n",
    "    overwrite_output_dir=True, # Overwrite the content of the output directory\n",
    "    num_train_epochs=3, # Number of training epochs\n",
    "    per_device_train_batch_size=32, # Batch size for training\n",
    "    per_device_eval_batch_size=64, # Batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations\n",
    "    save_steps=800, # Number of updates steps before two checkpoint saves\n",
    "    warmup_steps=500, # Number of warmup steps for learning rate scheduler\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
